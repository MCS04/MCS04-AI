{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QUANWN3rpfC9"
      },
      "source": [
        "# 0. Setup Paths"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "146BB11JpfDA"
      },
      "outputs": [],
      "source": [
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "42hJEdo_pfDB"
      },
      "outputs": [],
      "source": [
        "CUSTOM_MODEL_NAME = 'my_ssd_mobnet'\n",
        "PRETRAINED_MODEL_NAME = 'ssd_mobilenet_v2_fpnlite_640x640_coco17_tpu-8'\n",
        "PRETRAINED_MODEL_URL = 'http://download.tensorflow.org/models/object_detection/tf2/20200711/ssd_mobilenet_v2_fpnlite_640x640_coco17_tpu-8.tar.gz'\n",
        "TF_RECORD_SCRIPT_NAME = 'generate_tfrecord.py'\n",
        "LABEL_MAP_NAME = 'label_map.pbtxt'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "hbPhYVy_pfDB"
      },
      "outputs": [],
      "source": [
        "paths = {\n",
        "    'WORKSPACE_PATH': os.path.join('Tensorflow', 'workspace'),\n",
        "    'SCRIPTS_PATH': os.path.join('Tensorflow','scripts'),\n",
        "    'APIMODEL_PATH': os.path.join('Tensorflow','models'),\n",
        "    'ANNOTATION_PATH': os.path.join('Tensorflow', 'workspace','annotations'),\n",
        "    'IMAGE_PATH': os.path.join('Tensorflow', 'workspace','images'),\n",
        "    'IMAGE_TRAIN_PATH': os.path.join('Tensorflow', 'workspace','images', 'train'),\n",
        "    'IMAGE_VALIDATE_PATH': os.path.join('Tensorflow', 'workspace','images', 'valid'),\n",
        "    'IMAGE_TEST_PATH': os.path.join('Tensorflow', 'workspace','images', 'test'),\n",
        "    'MODEL_PATH': os.path.join('Tensorflow', 'workspace','models'),\n",
        "    'PRETRAINED_MODEL_PATH': os.path.join('Tensorflow', 'workspace','pre-trained-models'),\n",
        "    'CHECKPOINT_PATH': os.path.join('Tensorflow', 'workspace','models',CUSTOM_MODEL_NAME),\n",
        "    'OUTPUT_PATH': os.path.join('Tensorflow', 'workspace','models',CUSTOM_MODEL_NAME, 'export'),\n",
        "    'INFERENCE_PATH': os.path.join('Tensorflow', 'workspace','models',CUSTOM_MODEL_NAME, 'inference'),\n",
        "    'TFJS_PATH':os.path.join('Tensorflow', 'workspace','models',CUSTOM_MODEL_NAME, 'tfjsexport'),\n",
        "    'TFLITE_PATH':os.path.join('Tensorflow', 'workspace','models',CUSTOM_MODEL_NAME, 'tfliteexport'),\n",
        "    'PROTOC_PATH':os.path.join('Tensorflow','protoc'),\n",
        "    'ROBOFLOW_TRAIN_PATH':os.path.join('Bird-Nest-7', 'train'),\n",
        "    'ROBOFLOW_VALIDATE_PATH':os.path.join('Bird-Nest-7', 'valid'),\n",
        "    'ROBOFLOW_TEST_PATH':os.path.join('Bird-Nest-7', 'test')\n",
        " }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "LwhWZMI0pfDC"
      },
      "outputs": [],
      "source": [
        "files = {\n",
        "    'PIPELINE_CONFIG':os.path.join('Tensorflow', 'workspace','models', CUSTOM_MODEL_NAME, 'pipeline.config'),\n",
        "    'TF_RECORD_SCRIPT': os.path.join(paths['SCRIPTS_PATH'], TF_RECORD_SCRIPT_NAME),\n",
        "    'LABELMAP': os.path.join(paths['ANNOTATION_PATH'], LABEL_MAP_NAME)\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "HR-TfDGrpfDC"
      },
      "outputs": [],
      "source": [
        "for path in paths.values():\n",
        "    if not os.path.exists(path):\n",
        "        if os.name == 'posix':\n",
        "            !mkdir -p {path}\n",
        "        if os.name == 'nt':\n",
        "            !mkdir {path}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OLU-rs_ipfDE"
      },
      "source": [
        "# 1. Download TF Models Pretrained Models from Tensorflow Model Zoo and Install TFOD"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u-8UWGw0ajWU"
      },
      "outputs": [],
      "source": [
        "# https://www.tensorflow.org/install/source_windows"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "K-Cmz2edpfDE",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "if os.name=='nt':\n",
        "    !pip install wget\n",
        "    import wget"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "iA1DIq5OpfDE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3bf62948-f4f0-4438-b937-23abff9ed973"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'Tensorflow/models'...\n",
            "remote: Enumerating objects: 87643, done.\u001b[K\n",
            "remote: Counting objects: 100% (1397/1397), done.\u001b[K\n",
            "remote: Compressing objects: 100% (574/574), done.\u001b[K\n",
            "remote: Total 87643 (delta 870), reused 1295 (delta 808), pack-reused 86246\u001b[K\n",
            "Receiving objects: 100% (87643/87643), 599.33 MiB | 24.24 MiB/s, done.\n",
            "Resolving deltas: 100% (62744/62744), done.\n"
          ]
        }
      ],
      "source": [
        "if not os.path.exists(os.path.join(paths['APIMODEL_PATH'], 'research', 'object_detection')):\n",
        "    !git clone https://github.com/tensorflow/models {paths['APIMODEL_PATH']}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "rJjMHbnDs3Tv",
        "outputId": "9a840cbe-77aa-4508-9c47-3420e28c57dc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "protobuf-compiler is already the newest version (3.12.4-1ubuntu7.22.04.1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 18 not upgraded.\n",
            "Processing /content/Tensorflow/models/research\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting avro-python3 (from object-detection==0.1)\n",
            "  Downloading avro-python3-1.10.2.tar.gz (38 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting apache-beam (from object-detection==0.1)\n",
            "  Downloading apache_beam-2.50.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (14.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.7/14.7 MB\u001b[0m \u001b[31m85.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pillow in /usr/local/lib/python3.10/dist-packages (from object-detection==0.1) (9.4.0)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.10/dist-packages (from object-detection==0.1) (4.9.3)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from object-detection==0.1) (3.7.1)\n",
            "Requirement already satisfied: Cython in /usr/local/lib/python3.10/dist-packages (from object-detection==0.1) (3.0.2)\n",
            "Requirement already satisfied: contextlib2 in /usr/local/lib/python3.10/dist-packages (from object-detection==0.1) (21.6.0)\n",
            "Requirement already satisfied: tf-slim in /usr/local/lib/python3.10/dist-packages (from object-detection==0.1) (1.1.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from object-detection==0.1) (1.16.0)\n",
            "Requirement already satisfied: pycocotools in /usr/local/lib/python3.10/dist-packages (from object-detection==0.1) (2.0.7)\n",
            "Collecting lvis (from object-detection==0.1)\n",
            "  Downloading lvis-0.5.3-py3-none-any.whl (14 kB)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from object-detection==0.1) (1.11.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from object-detection==0.1) (1.5.3)\n",
            "Collecting tf-models-official>=2.5.1 (from object-detection==0.1)\n",
            "  Downloading tf_models_official-2.13.2-py2.py3-none-any.whl (2.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.6/2.6 MB\u001b[0m \u001b[31m98.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tensorflow_io (from object-detection==0.1)\n",
            "  Downloading tensorflow_io-0.34.0-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (28.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m28.8/28.8 MB\u001b[0m \u001b[31m59.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: keras in /usr/local/lib/python3.10/dist-packages (from object-detection==0.1) (2.13.1)\n",
            "Collecting pyparsing==2.4.7 (from object-detection==0.1)\n",
            "  Downloading pyparsing-2.4.7-py2.py3-none-any.whl (67 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.8/67.8 kB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting sacrebleu<=2.2.0 (from object-detection==0.1)\n",
            "  Downloading sacrebleu-2.2.0-py3-none-any.whl (116 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.6/116.6 kB\u001b[0m \u001b[31m16.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting portalocker (from sacrebleu<=2.2.0->object-detection==0.1)\n",
            "  Downloading portalocker-2.8.2-py3-none-any.whl (17 kB)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.10/dist-packages (from sacrebleu<=2.2.0->object-detection==0.1) (2023.6.3)\n",
            "Requirement already satisfied: tabulate>=0.8.9 in /usr/local/lib/python3.10/dist-packages (from sacrebleu<=2.2.0->object-detection==0.1) (0.9.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from sacrebleu<=2.2.0->object-detection==0.1) (1.23.5)\n",
            "Collecting colorama (from sacrebleu<=2.2.0->object-detection==0.1)\n",
            "  Downloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
            "Requirement already satisfied: gin-config in /usr/local/lib/python3.10/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (0.5.0)\n",
            "Requirement already satisfied: google-api-python-client>=1.6.7 in /usr/local/lib/python3.10/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (2.84.0)\n",
            "Collecting immutabledict (from tf-models-official>=2.5.1->object-detection==0.1)\n",
            "  Downloading immutabledict-3.0.0-py3-none-any.whl (4.0 kB)\n",
            "Requirement already satisfied: kaggle>=1.3.9 in /usr/local/lib/python3.10/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (1.5.16)\n",
            "Requirement already satisfied: oauth2client in /usr/local/lib/python3.10/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (4.1.3)\n",
            "Requirement already satisfied: opencv-python-headless in /usr/local/lib/python3.10/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (4.8.0.76)\n",
            "Requirement already satisfied: psutil>=5.4.3 in /usr/local/lib/python3.10/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (5.9.5)\n",
            "Requirement already satisfied: py-cpuinfo>=3.3.0 in /usr/local/lib/python3.10/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (9.0.0)\n",
            "Requirement already satisfied: pyyaml>=6.0.0 in /usr/local/lib/python3.10/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (6.0.1)\n",
            "Collecting sentencepiece (from tf-models-official>=2.5.1->object-detection==0.1)\n",
            "  Downloading sentencepiece-0.1.99-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m76.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting seqeval (from tf-models-official>=2.5.1->object-detection==0.1)\n",
            "  Downloading seqeval-1.2.2.tar.gz (43 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.6/43.6 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: tensorflow-datasets in /usr/local/lib/python3.10/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (4.9.2)\n",
            "Requirement already satisfied: tensorflow-hub>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (0.14.0)\n",
            "Collecting tensorflow-model-optimization>=0.4.1 (from tf-models-official>=2.5.1->object-detection==0.1)\n",
            "  Downloading tensorflow_model_optimization-0.7.5-py2.py3-none-any.whl (241 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m241.2/241.2 kB\u001b[0m \u001b[31m29.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tensorflow-text~=2.13.0 (from tf-models-official>=2.5.1->object-detection==0.1)\n",
            "  Downloading tensorflow_text-2.13.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (6.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.5/6.5 MB\u001b[0m \u001b[31m96.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tensorflow~=2.13.0 in /usr/local/lib/python3.10/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (2.13.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->object-detection==0.1) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->object-detection==0.1) (2023.3.post1)\n",
            "Requirement already satisfied: absl-py>=0.2.2 in /usr/local/lib/python3.10/dist-packages (from tf-slim->object-detection==0.1) (1.4.0)\n",
            "Collecting crcmod<2.0,>=1.7 (from apache-beam->object-detection==0.1)\n",
            "  Downloading crcmod-1.7.tar.gz (89 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m89.7/89.7 kB\u001b[0m \u001b[31m10.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting orjson<4.0 (from apache-beam->object-detection==0.1)\n",
            "  Downloading orjson-3.9.7-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (138 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m138.7/138.7 kB\u001b[0m \u001b[31m18.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting dill<0.3.2,>=0.3.1.1 (from apache-beam->object-detection==0.1)\n",
            "  Downloading dill-0.3.1.1.tar.gz (151 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m152.0/152.0 kB\u001b[0m \u001b[31m19.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: cloudpickle~=2.2.1 in /usr/local/lib/python3.10/dist-packages (from apache-beam->object-detection==0.1) (2.2.1)\n",
            "Collecting fastavro<2,>=0.23.6 (from apache-beam->object-detection==0.1)\n",
            "  Downloading fastavro-1.8.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.7/2.7 MB\u001b[0m \u001b[31m88.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting fasteners<1.0,>=0.3 (from apache-beam->object-detection==0.1)\n",
            "  Downloading fasteners-0.19-py3-none-any.whl (18 kB)\n",
            "Requirement already satisfied: grpcio!=1.48.0,<2,>=1.33.1 in /usr/local/lib/python3.10/dist-packages (from apache-beam->object-detection==0.1) (1.57.0)\n",
            "Collecting hdfs<3.0.0,>=2.1.0 (from apache-beam->object-detection==0.1)\n",
            "  Downloading hdfs-2.7.2.tar.gz (43 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.4/43.4 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: httplib2<0.23.0,>=0.8 in /usr/local/lib/python3.10/dist-packages (from apache-beam->object-detection==0.1) (0.22.0)\n",
            "Collecting objsize<0.7.0,>=0.6.1 (from apache-beam->object-detection==0.1)\n",
            "  Downloading objsize-0.6.1-py3-none-any.whl (9.3 kB)\n",
            "Collecting pymongo<5.0.0,>=3.8.0 (from apache-beam->object-detection==0.1)\n",
            "  Downloading pymongo-4.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (671 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m671.3/671.3 kB\u001b[0m \u001b[31m56.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: proto-plus<2,>=1.7.1 in /usr/local/lib/python3.10/dist-packages (from apache-beam->object-detection==0.1) (1.22.3)\n",
            "Requirement already satisfied: protobuf<4.24.0,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from apache-beam->object-detection==0.1) (3.20.3)\n",
            "Requirement already satisfied: pydot<2,>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from apache-beam->object-detection==0.1) (1.4.2)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.24.0 in /usr/local/lib/python3.10/dist-packages (from apache-beam->object-detection==0.1) (2.31.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.0 in /usr/local/lib/python3.10/dist-packages (from apache-beam->object-detection==0.1) (4.5.0)\n",
            "Collecting zstandard<1,>=0.18.0 (from apache-beam->object-detection==0.1)\n",
            "  Downloading zstandard-0.21.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.7/2.7 MB\u001b[0m \u001b[31m73.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pyarrow<12.0.0,>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from apache-beam->object-detection==0.1) (9.0.0)\n",
            "Requirement already satisfied: cycler>=0.10.0 in /usr/local/lib/python3.10/dist-packages (from lvis->object-detection==0.1) (0.11.0)\n",
            "Requirement already satisfied: kiwisolver>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from lvis->object-detection==0.1) (1.4.5)\n",
            "Requirement already satisfied: opencv-python>=4.1.0.25 in /usr/local/lib/python3.10/dist-packages (from lvis->object-detection==0.1) (4.8.0.76)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->object-detection==0.1) (1.1.0)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->object-detection==0.1) (4.42.1)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->object-detection==0.1) (23.1)\n",
            "Collecting tensorflow-io-gcs-filesystem==0.34.0 (from tensorflow_io->object-detection==0.1)\n",
            "  Downloading tensorflow_io_gcs_filesystem-0.34.0-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (2.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m94.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: google-auth<3.0.0dev,>=1.19.0 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (2.17.3)\n",
            "Requirement already satisfied: google-auth-httplib2>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (0.1.0)\n",
            "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (2.11.1)\n",
            "Requirement already satisfied: uritemplate<5,>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (4.1.1)\n",
            "Collecting docopt (from hdfs<3.0.0,>=2.1.0->apache-beam->object-detection==0.1)\n",
            "  Downloading docopt-0.6.2.tar.gz (25 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from kaggle>=1.3.9->tf-models-official>=2.5.1->object-detection==0.1) (2023.7.22)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from kaggle>=1.3.9->tf-models-official>=2.5.1->object-detection==0.1) (4.66.1)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.10/dist-packages (from kaggle>=1.3.9->tf-models-official>=2.5.1->object-detection==0.1) (8.0.1)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.10/dist-packages (from kaggle>=1.3.9->tf-models-official>=2.5.1->object-detection==0.1) (2.0.4)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.10/dist-packages (from kaggle>=1.3.9->tf-models-official>=2.5.1->object-detection==0.1) (6.0.0)\n",
            "Collecting dnspython<3.0.0,>=1.16.0 (from pymongo<5.0.0,>=3.8.0->apache-beam->object-detection==0.1)\n",
            "  Downloading dnspython-2.4.2-py3-none-any.whl (300 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m300.4/300.4 kB\u001b[0m \u001b[31m33.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.24.0->apache-beam->object-detection==0.1) (3.2.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.24.0->apache-beam->object-detection==0.1) (3.4)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.13.0->tf-models-official>=2.5.1->object-detection==0.1) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=23.1.21 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.13.0->tf-models-official>=2.5.1->object-detection==0.1) (23.5.26)\n",
            "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.13.0->tf-models-official>=2.5.1->object-detection==0.1) (0.4.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.13.0->tf-models-official>=2.5.1->object-detection==0.1) (0.2.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.13.0->tf-models-official>=2.5.1->object-detection==0.1) (3.9.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.13.0->tf-models-official>=2.5.1->object-detection==0.1) (16.0.6)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.13.0->tf-models-official>=2.5.1->object-detection==0.1) (3.3.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.13.0->tf-models-official>=2.5.1->object-detection==0.1) (67.7.2)\n",
            "Requirement already satisfied: tensorboard<2.14,>=2.13 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.13.0->tf-models-official>=2.5.1->object-detection==0.1) (2.13.0)\n",
            "Requirement already satisfied: tensorflow-estimator<2.14,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.13.0->tf-models-official>=2.5.1->object-detection==0.1) (2.13.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.13.0->tf-models-official>=2.5.1->object-detection==0.1) (2.3.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.13.0->tf-models-official>=2.5.1->object-detection==0.1) (1.15.0)\n",
            "Requirement already satisfied: dm-tree~=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow-model-optimization>=0.4.1->tf-models-official>=2.5.1->object-detection==0.1) (0.1.8)\n",
            "Requirement already satisfied: pyasn1>=0.1.7 in /usr/local/lib/python3.10/dist-packages (from oauth2client->tf-models-official>=2.5.1->object-detection==0.1) (0.5.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.0.5 in /usr/local/lib/python3.10/dist-packages (from oauth2client->tf-models-official>=2.5.1->object-detection==0.1) (0.3.0)\n",
            "Requirement already satisfied: rsa>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from oauth2client->tf-models-official>=2.5.1->object-detection==0.1) (4.9)\n",
            "Requirement already satisfied: scikit-learn>=0.21.3 in /usr/local/lib/python3.10/dist-packages (from seqeval->tf-models-official>=2.5.1->object-detection==0.1) (1.2.2)\n",
            "Requirement already satisfied: array-record in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets->tf-models-official>=2.5.1->object-detection==0.1) (0.4.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets->tf-models-official>=2.5.1->object-detection==0.1) (8.1.7)\n",
            "Requirement already satisfied: etils[enp,epath]>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets->tf-models-official>=2.5.1->object-detection==0.1) (1.4.1)\n",
            "Requirement already satisfied: promise in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets->tf-models-official>=2.5.1->object-detection==0.1) (2.3)\n",
            "Requirement already satisfied: tensorflow-metadata in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets->tf-models-official>=2.5.1->object-detection==0.1) (1.14.0)\n",
            "Requirement already satisfied: toml in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets->tf-models-official>=2.5.1->object-detection==0.1) (0.10.2)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow~=2.13.0->tf-models-official>=2.5.1->object-detection==0.1) (0.41.2)\n",
            "Requirement already satisfied: importlib_resources in /usr/local/lib/python3.10/dist-packages (from etils[enp,epath]>=0.9.0->tensorflow-datasets->tf-models-official>=2.5.1->object-detection==0.1) (6.0.1)\n",
            "Requirement already satisfied: zipp in /usr/local/lib/python3.10/dist-packages (from etils[enp,epath]>=0.9.0->tensorflow-datasets->tf-models-official>=2.5.1->object-detection==0.1) (3.16.2)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (1.60.0)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3.0.0dev,>=1.19.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (5.3.1)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.21.3->seqeval->tf-models-official>=2.5.1->object-detection==0.1) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.21.3->seqeval->tf-models-official>=2.5.1->object-detection==0.1) (3.2.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.14,>=2.13->tensorflow~=2.13.0->tf-models-official>=2.5.1->object-detection==0.1) (1.0.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.14,>=2.13->tensorflow~=2.13.0->tf-models-official>=2.5.1->object-detection==0.1) (3.4.4)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.14,>=2.13->tensorflow~=2.13.0->tf-models-official>=2.5.1->object-detection==0.1) (0.7.1)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.14,>=2.13->tensorflow~=2.13.0->tf-models-official>=2.5.1->object-detection==0.1) (2.3.7)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.10/dist-packages (from bleach->kaggle>=1.3.9->tf-models-official>=2.5.1->object-detection==0.1) (0.5.1)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.10/dist-packages (from python-slugify->kaggle>=1.3.9->tf-models-official>=2.5.1->object-detection==0.1) (1.3)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.14,>=2.13->tensorflow~=2.13.0->tf-models-official>=2.5.1->object-detection==0.1) (1.3.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.14,>=2.13->tensorflow~=2.13.0->tf-models-official>=2.5.1->object-detection==0.1) (2.1.3)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.14,>=2.13->tensorflow~=2.13.0->tf-models-official>=2.5.1->object-detection==0.1) (3.2.2)\n",
            "Building wheels for collected packages: object-detection, avro-python3, crcmod, dill, hdfs, seqeval, docopt\n",
            "  Building wheel for object-detection (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for object-detection: filename=object_detection-0.1-py3-none-any.whl size=1697354 sha256=d0025e9d29e94e8c12c434f374890885fee9213c347bcae03c9658a1514c8260\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-eny802lk/wheels/fb/c9/43/709f88e66b36649c7a29812ca4f6236f31caed949aabc3e335\n",
            "  Building wheel for avro-python3 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for avro-python3: filename=avro_python3-1.10.2-py3-none-any.whl size=43991 sha256=2c54ea8a122e0fbff5e5e3e6f2269dc1547857f98a642d96cd043b35608345e5\n",
            "  Stored in directory: /root/.cache/pip/wheels/bc/85/62/6cdd81c56f923946b401cecff38055b94c9b766927f7d8ca82\n",
            "  Building wheel for crcmod (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for crcmod: filename=crcmod-1.7-cp310-cp310-linux_x86_64.whl size=31405 sha256=fb5da8e223b4d34f2e296598d227eb8365393db95feedc95cd99d04fd4b0b50e\n",
            "  Stored in directory: /root/.cache/pip/wheels/85/4c/07/72215c529bd59d67e3dac29711d7aba1b692f543c808ba9e86\n",
            "  Building wheel for dill (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for dill: filename=dill-0.3.1.1-py3-none-any.whl size=78542 sha256=a1ec8e593089b748de5494e1d9a68c7b5cc0546d9a8b6a3515ea363be2f466b4\n",
            "  Stored in directory: /root/.cache/pip/wheels/ea/e2/86/64980d90e297e7bf2ce588c2b96e818f5399c515c4bb8a7e4f\n",
            "  Building wheel for hdfs (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for hdfs: filename=hdfs-2.7.2-py3-none-any.whl size=34168 sha256=8a51f2a29a9f21cb6303f3a877313ba089377280ed81beaec3bc1c3f932f55b0\n",
            "  Stored in directory: /root/.cache/pip/wheels/ab/39/8e/e1905de9af8ae74911cd3e53e721995cd230816f63776e5825\n",
            "  Building wheel for seqeval (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for seqeval: filename=seqeval-1.2.2-py3-none-any.whl size=16162 sha256=b0d15aa279cfce8f425555bf1a04d0d19c81ffffaa9210c648a47b1657a3ed5e\n",
            "  Stored in directory: /root/.cache/pip/wheels/1a/67/4a/ad4082dd7dfc30f2abfe4d80a2ed5926a506eb8a972b4767fa\n",
            "  Building wheel for docopt (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for docopt: filename=docopt-0.6.2-py2.py3-none-any.whl size=13705 sha256=9ded3df61c17a1bc53225a64f613a08e7c4f785bd1f7e2064b1e962d49693ad9\n",
            "  Stored in directory: /root/.cache/pip/wheels/fc/ab/d4/5da2067ac95b36618c629a5f93f809425700506f72c9732fac\n",
            "Successfully built object-detection avro-python3 crcmod dill hdfs seqeval docopt\n",
            "Installing collected packages: sentencepiece, docopt, crcmod, zstandard, tensorflow-model-optimization, tensorflow-io-gcs-filesystem, pyparsing, portalocker, orjson, objsize, immutabledict, fasteners, fastavro, dnspython, dill, colorama, avro-python3, tensorflow_io, sacrebleu, pymongo, hdfs, seqeval, lvis, apache-beam, tensorflow-text, tf-models-official, object-detection\n",
            "  Attempting uninstall: tensorflow-io-gcs-filesystem\n",
            "    Found existing installation: tensorflow-io-gcs-filesystem 0.33.0\n",
            "    Uninstalling tensorflow-io-gcs-filesystem-0.33.0:\n",
            "      Successfully uninstalled tensorflow-io-gcs-filesystem-0.33.0\n",
            "  Attempting uninstall: pyparsing\n",
            "    Found existing installation: pyparsing 3.1.1\n",
            "    Uninstalling pyparsing-3.1.1:\n",
            "      Successfully uninstalled pyparsing-3.1.1\n",
            "Successfully installed apache-beam-2.50.0 avro-python3-1.10.2 colorama-0.4.6 crcmod-1.7 dill-0.3.1.1 dnspython-2.4.2 docopt-0.6.2 fastavro-1.8.3 fasteners-0.19 hdfs-2.7.2 immutabledict-3.0.0 lvis-0.5.3 object-detection-0.1 objsize-0.6.1 orjson-3.9.7 portalocker-2.8.2 pymongo-4.5.0 pyparsing-2.4.7 sacrebleu-2.2.0 sentencepiece-0.1.99 seqeval-1.2.2 tensorflow-io-gcs-filesystem-0.34.0 tensorflow-model-optimization-0.7.5 tensorflow-text-2.13.0 tensorflow_io-0.34.0 tf-models-official-2.13.2 zstandard-0.21.0\n"
          ]
        }
      ],
      "source": [
        "# Install Tensorflow Object Detection\n",
        "if os.name=='posix':\n",
        "    !apt-get install protobuf-compiler\n",
        "    !cd Tensorflow/models/research && protoc object_detection/protos/*.proto --python_out=. && cp object_detection/packages/tf2/setup.py . && python -m pip install .\n",
        "\n",
        "if os.name=='nt':\n",
        "    url=\"https://github.com/protocolbuffers/protobuf/releases/download/v3.15.6/protoc-3.15.6-win64.zip\"\n",
        "    wget.download(url)\n",
        "    !move protoc-3.15.6-win64.zip {paths['PROTOC_PATH']}\n",
        "    !cd {paths['PROTOC_PATH']} && tar -xf protoc-3.15.6-win64.zip\n",
        "    os.environ['PATH'] += os.pathsep + os.path.abspath(os.path.join(paths['PROTOC_PATH'], 'bin'))\n",
        "    !cd Tensorflow/models/research && protoc object_detection/protos/*.proto --python_out=. && copy object_detection\\\\packages\\\\tf2\\\\setup.py setup.py && python setup.py build && python setup.py install\n",
        "    !cd Tensorflow/models/research/slim && pip install -e ."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "id": "dcc5MerWajWW"
      },
      "outputs": [],
      "source": [
        "VERIFICATION_SCRIPT = os.path.join(paths['APIMODEL_PATH'], 'research', 'object_detection', 'builders', 'model_builder_tf2_test.py')\n",
        "# Verify Installation\n",
        "!python {VERIFICATION_SCRIPT}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "BhyyztLLajWW"
      },
      "outputs": [],
      "source": [
        "!pip install tensorflow --upgrade"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "I0hrkPC1ajWW"
      },
      "outputs": [],
      "source": [
        "!pip uninstall protobuf matplotlib -y\n",
        "!pip install protobuf matplotlib==3.2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "CGpqQ5sRajWW"
      },
      "outputs": [],
      "source": [
        "import object_detection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "id": "LOu5SZXNajWW"
      },
      "outputs": [],
      "source": [
        "!pip list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "csofht2npfDE",
        "outputId": "60e88650-e8dc-49f4-bc9b-1137c39cfddd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-09-24 15:48:37--  http://download.tensorflow.org/models/object_detection/tf2/20200711/ssd_mobilenet_v2_fpnlite_640x640_coco17_tpu-8.tar.gz\n",
            "Resolving download.tensorflow.org (download.tensorflow.org)... 173.194.174.207, 74.125.23.207, 74.125.203.207, ...\n",
            "Connecting to download.tensorflow.org (download.tensorflow.org)|173.194.174.207|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 20518283 (20M) [application/x-tar]\n",
            "Saving to: ‘ssd_mobilenet_v2_fpnlite_640x640_coco17_tpu-8.tar.gz’\n",
            "\n",
            "ssd_mobilenet_v2_fp 100%[===================>]  19.57M  76.2MB/s    in 0.3s    \n",
            "\n",
            "2023-09-24 15:48:38 (76.2 MB/s) - ‘ssd_mobilenet_v2_fpnlite_640x640_coco17_tpu-8.tar.gz’ saved [20518283/20518283]\n",
            "\n",
            "ssd_mobilenet_v2_fpnlite_640x640_coco17_tpu-8/\n",
            "ssd_mobilenet_v2_fpnlite_640x640_coco17_tpu-8/checkpoint/\n",
            "ssd_mobilenet_v2_fpnlite_640x640_coco17_tpu-8/checkpoint/ckpt-0.data-00000-of-00001\n",
            "ssd_mobilenet_v2_fpnlite_640x640_coco17_tpu-8/checkpoint/checkpoint\n",
            "ssd_mobilenet_v2_fpnlite_640x640_coco17_tpu-8/checkpoint/ckpt-0.index\n",
            "ssd_mobilenet_v2_fpnlite_640x640_coco17_tpu-8/pipeline.config\n",
            "ssd_mobilenet_v2_fpnlite_640x640_coco17_tpu-8/saved_model/\n",
            "ssd_mobilenet_v2_fpnlite_640x640_coco17_tpu-8/saved_model/saved_model.pb\n",
            "ssd_mobilenet_v2_fpnlite_640x640_coco17_tpu-8/saved_model/variables/\n",
            "ssd_mobilenet_v2_fpnlite_640x640_coco17_tpu-8/saved_model/variables/variables.data-00000-of-00001\n",
            "ssd_mobilenet_v2_fpnlite_640x640_coco17_tpu-8/saved_model/variables/variables.index\n"
          ]
        }
      ],
      "source": [
        "if os.name =='posix':\n",
        "    !wget {PRETRAINED_MODEL_URL}\n",
        "    !mv {PRETRAINED_MODEL_NAME+'.tar.gz'} {paths['PRETRAINED_MODEL_PATH']}\n",
        "    !cd {paths['PRETRAINED_MODEL_PATH']} && tar -zxvf {PRETRAINED_MODEL_NAME+'.tar.gz'}\n",
        "if os.name == 'nt':\n",
        "    wget.download(PRETRAINED_MODEL_URL)\n",
        "    !move {PRETRAINED_MODEL_NAME+'.tar.gz'} {paths['PRETRAINED_MODEL_PATH']}\n",
        "    !cd {paths['PRETRAINED_MODEL_PATH']} && tar -zxvf {PRETRAINED_MODEL_NAME+'.tar.gz'}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M5KJTnkfpfDC"
      },
      "source": [
        "# 2. Create Label Map"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "p1BVDWo7pfDC"
      },
      "outputs": [],
      "source": [
        "labels = [{'name':'0', 'id':1, 'display_name': '0'}, {'name':'1', 'id':2, 'display_name': '1'}, {'name':'2', 'id':3, 'display_name': '2'}]\n",
        "\n",
        "with open(files['LABELMAP'], 'w') as f:\n",
        "    for label in labels:\n",
        "        f.write('item { \\n')\n",
        "        f.write('\\tname:\\'{}\\'\\n'.format(label['name']))\n",
        "        f.write('\\tid:{}\\n'.format(label['id']))\n",
        "        f.write('\\tdisplay_name:\\'{}\\'\\n'.format(label['display_name']))\n",
        "        f.write('}\\n')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C88zyVELpfDC"
      },
      "source": [
        "# 3. Download images and TF records from Roboflow"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!rm -r Bird-Nest-7"
      ],
      "metadata": {
        "id": "sCw4gssyPvGg"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install roboflow\n",
        "\n",
        "from roboflow import Roboflow\n",
        "rf = Roboflow(api_key=\"1woWfE1q4RoyHytXmktz\")\n",
        "project = rf.workspace(\"ebn\").project(\"bird-nest-exr6l\")\n",
        "dataset = project.version(7).download(\"tensorflow\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "ZSRueT1djHp3",
        "outputId": "9ba8b8d3-40de-4b16-ec34-5a46020ec6e7"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting roboflow\n",
            "  Downloading roboflow-1.1.7-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.8/58.8 kB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting certifi==2022.12.7 (from roboflow)\n",
            "  Downloading certifi-2022.12.7-py3-none-any.whl (155 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m155.3/155.3 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting chardet==4.0.0 (from roboflow)\n",
            "  Downloading chardet-4.0.0-py2.py3-none-any.whl (178 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m178.7/178.7 kB\u001b[0m \u001b[31m20.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting cycler==0.10.0 (from roboflow)\n",
            "  Downloading cycler-0.10.0-py2.py3-none-any.whl (6.5 kB)\n",
            "Collecting idna==2.10 (from roboflow)\n",
            "  Downloading idna-2.10-py2.py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.8/58.8 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.10/dist-packages (from roboflow) (1.4.5)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from roboflow) (3.7.1)\n",
            "Requirement already satisfied: numpy>=1.18.5 in /usr/local/lib/python3.10/dist-packages (from roboflow) (1.23.5)\n",
            "Collecting opencv-python-headless==4.8.0.74 (from roboflow)\n",
            "  Downloading opencv_python_headless-4.8.0.74-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (49.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.1/49.1 MB\u001b[0m \u001b[31m35.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: Pillow>=7.1.2 in /usr/local/lib/python3.10/dist-packages (from roboflow) (9.4.0)\n",
            "Requirement already satisfied: pyparsing==2.4.7 in /usr/local/lib/python3.10/dist-packages (from roboflow) (2.4.7)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.10/dist-packages (from roboflow) (2.8.2)\n",
            "Collecting python-dotenv (from roboflow)\n",
            "  Downloading python_dotenv-1.0.0-py3-none-any.whl (19 kB)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from roboflow) (2.31.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from roboflow) (1.16.0)\n",
            "Collecting supervision (from roboflow)\n",
            "  Downloading supervision-0.14.0-py3-none-any.whl (63 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.3/63.3 kB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: urllib3>=1.26.6 in /usr/local/lib/python3.10/dist-packages (from roboflow) (2.0.4)\n",
            "Requirement already satisfied: tqdm>=4.41.0 in /usr/local/lib/python3.10/dist-packages (from roboflow) (4.66.1)\n",
            "Requirement already satisfied: PyYAML>=5.3.1 in /usr/local/lib/python3.10/dist-packages (from roboflow) (6.0.1)\n",
            "Collecting requests-toolbelt (from roboflow)\n",
            "  Downloading requests_toolbelt-1.0.0-py2.py3-none-any.whl (54 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.5/54.5 kB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->roboflow) (1.1.0)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->roboflow) (4.42.1)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->roboflow) (23.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->roboflow) (3.2.0)\n",
            "Requirement already satisfied: scipy<2.0.0,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from supervision->roboflow) (1.11.2)\n",
            "Installing collected packages: python-dotenv, opencv-python-headless, idna, cycler, chardet, certifi, supervision, requests-toolbelt, roboflow\n",
            "  Attempting uninstall: opencv-python-headless\n",
            "    Found existing installation: opencv-python-headless 4.8.0.76\n",
            "    Uninstalling opencv-python-headless-4.8.0.76:\n",
            "      Successfully uninstalled opencv-python-headless-4.8.0.76\n",
            "  Attempting uninstall: idna\n",
            "    Found existing installation: idna 3.4\n",
            "    Uninstalling idna-3.4:\n",
            "      Successfully uninstalled idna-3.4\n",
            "  Attempting uninstall: cycler\n",
            "    Found existing installation: cycler 0.11.0\n",
            "    Uninstalling cycler-0.11.0:\n",
            "      Successfully uninstalled cycler-0.11.0\n",
            "  Attempting uninstall: chardet\n",
            "    Found existing installation: chardet 5.2.0\n",
            "    Uninstalling chardet-5.2.0:\n",
            "      Successfully uninstalled chardet-5.2.0\n",
            "  Attempting uninstall: certifi\n",
            "    Found existing installation: certifi 2023.7.22\n",
            "    Uninstalling certifi-2023.7.22:\n",
            "      Successfully uninstalled certifi-2023.7.22\n",
            "Successfully installed certifi-2022.12.7 chardet-4.0.0 cycler-0.10.0 idna-2.10 opencv-python-headless-4.8.0.74 python-dotenv-1.0.0 requests-toolbelt-1.0.0 roboflow-1.1.7 supervision-0.14.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "certifi",
                  "cycler"
                ]
              }
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loading Roboflow workspace...\n",
            "loading Roboflow project...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading Dataset Version Zip in Bird-Nest-7 to tensorflow:: 100%|██████████| 128691/128691 [00:07<00:00, 17930.30it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Extracting Dataset Version Zip to Bird-Nest-7 in tensorflow:: 100%|██████████| 1145/1145 [00:00<00:00, 3227.34it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "\n",
        "source_folders = [paths['ROBOFLOW_TRAIN_PATH'], paths['ROBOFLOW_VALIDATE_PATH'], paths['ROBOFLOW_TEST_PATH']]\n",
        "destination_folders = [os.path.join(paths['IMAGE_PATH'], 'train'), os.path.join(paths['IMAGE_PATH'], 'valid'), os.path.join(paths['IMAGE_PATH'], 'test')]\n",
        "\n",
        "for i in range(len(source_folders)):\n",
        "  source_folder = source_folders[i]\n",
        "  destination_folder = destination_folders[i]\n",
        "  # fetch all files\n",
        "  for file_name in os.listdir(source_folder):\n",
        "      # construct full file path\n",
        "      source = os.path.join(source_folder, file_name)\n",
        "      destination = os.path.join(destination_folder, file_name)\n",
        "      # move only files\n",
        "      if os.path.isfile(source):\n",
        "          shutil.move(source, destination)\n",
        "          print('Moved:', file_name)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TjGE1b9RoeuP",
        "outputId": "c256a577-b440-49b0-f9e9-f650a46e7802"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Moved: BrokenSmall-26-_bmp.rf.0aa53349a40110bcfef74950851d1518.jpg\n",
            "Moved: Yellow-4-_bmp.rf.696556a212cf81bfbce9aac3ffb244ae.jpg\n",
            "Moved: HeavyFeather-11-_bmp.rf.abe34dbd30c5f1246f12d710b51a7b8b.jpg\n",
            "Moved: SizeC-14-_bmp.rf.6eb4b004e630719717c500893d0a4258.jpg\n",
            "Moved: Ping-12-_bmp.rf.17c74e9e7da49df7495304856092f82a.jpg\n",
            "Moved: Triangular-13-_bmp.rf.4a267d9cccd3500b4881ac3d365745ba.jpg\n",
            "Moved: SizeB-9-_bmp.rf.57cc49e49e78c38999afd038bb8f0407.jpg\n",
            "Moved: DoubleColour-7-_bmp.rf.064f0a934eac64b930017d0613a22dd7.jpg\n",
            "Moved: SizeC-9-_bmp.rf.16ec29acd29ca5dcdcbb69c8be25b26b.jpg\n",
            "Moved: BrokenSmall-11-_bmp.rf.f3f639d8742567baf767d959cd65be0c.jpg\n",
            "Moved: BrokenSmall-32-_bmp.rf.d34cc261cdc28aeb1a039869ed528adf.jpg\n",
            "Moved: BrokenSmall-57-_bmp.rf.649e4396e093c04cc5743b18011e8527.jpg\n",
            "Moved: Yellow-18-_bmp.rf.101f1ccfe3cd8be7214820b027b89c8f.jpg\n",
            "Moved: Yellow-21-_bmp.rf.d0612300d05e93af2000ec91a0cc02f8.jpg\n",
            "Moved: LightFeather-14-_bmp.rf.d1732abbb5bc26767097cbcc532cd4ff.jpg\n",
            "Moved: DaYuenJiao-4-_bmp.rf.a5b97565f76947e425ce74db3976ee9b.jpg\n",
            "Moved: BrokenSmall-5-_bmp.rf.ccc5837721526d7837c6db233355cc3d.jpg\n",
            "Moved: Yellow-12-_bmp.rf.4b6e5c856d2230b9e8d76abbadddd048.jpg\n",
            "Moved: Strips-5-_bmp.rf.f39af8618934421a07d2aa1354744b23.jpg\n",
            "Moved: BrokenSmall-27-_bmp.rf.88bc3859e3541cf80396dc4484fd3b21.jpg\n",
            "Moved: Ping-2-_bmp.rf.3f43d5ef3dfbaec8b2bb60e3ef1262da.jpg\n",
            "Moved: Yellow-11-_bmp.rf.90c3db5969605b58bec3935c0ff2d8b2.jpg\n",
            "Moved: SizeA-1-_bmp.rf.39e64d72c0128251086467f127b47f9b.jpg\n",
            "Moved: Yellow-8-_bmp.rf.37e871ca4b2738909fc48a369c32c7cd.jpg\n",
            "Moved: Yellow-10-_bmp.rf.21b1a3b3a6b46eedf3e9bfc57afd87c4.jpg\n",
            "Moved: WhiteBeige-11-_bmp.rf.e2e54b5daa675352d55567736fb491f5.jpg\n",
            "Moved: Bone-12-_bmp.rf.eea6106456cc6cfc8467ad42df5f7e1d.jpg\n",
            "Moved: Grey-9-_bmp.rf.734fa9b661a748ea3fdb2f2ea15fd6e0.jpg\n",
            "Moved: SizeA-4-_bmp.rf.c70e8a9e18ae70bfa4b9a3349563c602.jpg\n",
            "Moved: BrokenSmall-54-_bmp.rf.407e71f749e51102d5e42ab42ad2abc2.jpg\n",
            "Moved: BrokenBig-5-_bmp.rf.191f8e183858d7eb9e24042f0ecc2286.jpg\n",
            "Moved: BrokenBig-17-_bmp.rf.6cf50bb24a6fe56bbbe222a0ce32d4a6.jpg\n",
            "Moved: SizeC-17-_bmp.rf.d442f5145b9a7fe19f6db6e63f42d0d9.jpg\n",
            "Moved: BrokenSmall-43-_bmp.rf.c6bfef0053fbeac382ca650e2f335722.jpg\n",
            "Moved: DaYuenJiao-1-_bmp.rf.b61d48830c6976c993e29760bb86c464.jpg\n",
            "Moved: WhiteBeige-15-_bmp.rf.033e2da8f980d2dd36d714bc7e7c6e08.jpg\n",
            "Moved: BrokenSmall-66-_bmp.rf.5af50e367735ed29d7e6e58450445354.jpg\n",
            "Moved: BrokenSmall-61-_bmp.rf.08ed635b42a3a5c50dac69f607b81721.jpg\n",
            "Moved: Bone-6-_bmp.rf.bf05d6dc19a2d68b03af4c940394447a.jpg\n",
            "Moved: LightFeather-10-_bmp.rf.56b16babad1ed014fec3bef7839fa18b.jpg\n",
            "Moved: DoubleColour-4-_bmp.rf.c4e5d751d52b1361e9da3ff0e45f4624.jpg\n",
            "Moved: BrokenSmall-29-_bmp.rf.00b1b6b023605be2e9ae5508ccffdcd6.jpg\n",
            "Moved: Grey-22-_bmp.rf.5e02bbed48ad61432256ee293d438aa4.jpg\n",
            "Moved: HeavyFeather-6-_bmp.rf.e935465aa2227a33210ce5657a7669e2.jpg\n",
            "Moved: Grey-19-_bmp.rf.1d285ce2c420d697dc3c60589da93679.jpg\n",
            "Moved: BrokenSmall-8-_bmp.rf.0cb3e1a8cea0ca2c2da4d9b601ae36b9.jpg\n",
            "Moved: Triangular-6-_bmp.rf.63ac94cb02e4b38814452b0cb0b127e9.jpg\n",
            "Moved: DaYuenJiao-5-_bmp.rf.711b4f2049ba5c46dfdd8385afbe9131.jpg\n",
            "Moved: ThickFlesh-5-_bmp.rf.179c58992727db8ea5e5da9486b61946.jpg\n",
            "Moved: White-15-_bmp.rf.1030827bcc217c415a7fe46e12e2f6b3.jpg\n",
            "Moved: Strips-4-_bmp.rf.b15489e7df40b71f3f67ab9d26744828.jpg\n",
            "Moved: Triangular-18-_bmp.rf.854d802481e6114cb8648a9648a9bfaa.jpg\n",
            "Moved: DaYuenJiao-18-_bmp.rf.3de6210fb0bd3f7b30ddba12d32806bd.jpg\n",
            "Moved: Beige-1-_bmp.rf.e80a1af62a16cf6ceafb59ec5ac64e01.jpg\n",
            "Moved: SizeC-2-_bmp.rf.2f5c48249312322e2c594c3994258847.jpg\n",
            "Moved: Yellow-11-_bmp.rf.62679d32a5513584e80a73de57db9896.jpg\n",
            "Moved: Ping-10-_bmp.rf.82e108b62ca30eeff48152647ba90ff2.jpg\n",
            "Moved: SizeC-4-_bmp.rf.c1ec154aad018b883a519fc850ed3bd5.jpg\n",
            "Moved: Mossy-10-_bmp.rf.260ec78ea9da850180b71bc566b48701.jpg\n",
            "Moved: Ping-11-_bmp.rf.ef8bd756f23965597916cd917d733751.jpg\n",
            "Moved: DaYuenJiao-4-_bmp.rf.4a35b5cffc14d995d129ddb75a792081.jpg\n",
            "Moved: BrokenSmall-58-_bmp.rf.d4ac6ba80d89b2cbc661163fbba3c545.jpg\n",
            "Moved: BrokenSmall-68-_bmp.rf.e156b001c167d3487dab6d114d284ac6.jpg\n",
            "Moved: Triangular-3-_bmp.rf.94944a298fc6f54932d98a999366d7c0.jpg\n",
            "Moved: DaYuenJiao-6-_bmp.rf.a006aa65fe4b6491b482af00e7dcfe85.jpg\n",
            "Moved: DaYuenJiao-12-_bmp.rf.c2bc20accf02bee5e4a008fa33b0abde.jpg\n",
            "Moved: BrokenSmall-5-_bmp.rf.914addea0c15a046e9edecb9f68ec5c4.jpg\n",
            "Moved: Triangular-4-_bmp.rf.04c32eee560c392306830e6c8dbbb739.jpg\n",
            "Moved: BrokenSmall-17-_bmp.rf.1dc4434151106a24f47078cbdef234c6.jpg\n",
            "Moved: BrokenSmall-6-_bmp.rf.4a33c49e7891102f4c1337ebaabc3873.jpg\n",
            "Moved: Triangular-5-_bmp.rf.4605fb79f84e9b563a38a685960c1b86.jpg\n",
            "Moved: ThickFlesh-11-_bmp.rf.60402669fd541d85b275fcde3370b16f.jpg\n",
            "Moved: BrokenSmall-65-_bmp.rf.d38e64958b8e054d6ca19ed74a3c3276.jpg\n",
            "Moved: BrokenSmall-11-_bmp.rf.641ca789602fca41f7988b87dd91dd87.jpg\n",
            "Moved: Beige-5-_bmp.rf.40832abf20fc1ffdb9b56fe11a1ad9c1.jpg\n",
            "Moved: SizeC-18-_bmp.rf.bbe0c76a8c76a9243f907109f63d9939.jpg\n",
            "Moved: SizeB-6-_bmp.rf.e7db95d78ad4f540dcf2621834b43d95.jpg\n",
            "Moved: Mossy-15-_bmp.rf.afac86a66666c3b5c3caf31e373e11bc.jpg\n",
            "Moved: Grey-22-_bmp.rf.31ea539aa3090d151156ca4c220c600c.jpg\n",
            "Moved: Ping-10-_bmp.rf.83bd9192155c3a9bc0841b876866cf77.jpg\n",
            "Moved: SizeB-15-_bmp.rf.f928a9bfb340a2131702fd913b5babac.jpg\n",
            "Moved: HeavyFeather-15-_bmp.rf.1364c975fae8ae7eebb92d9854f297ee.jpg\n",
            "Moved: SizeA-12-_bmp.rf.eedcc065d0ba33a30ffae8bfaff9ebcf.jpg\n",
            "Moved: Triangular-22-_bmp.rf.1ed492692d5e0b9afec76b2639e6d78d.jpg\n",
            "Moved: Yellow-13-_bmp.rf.cc7a6404ec72c320a1a6a73d79b2cbf4.jpg\n",
            "Moved: BrokenBig-13-_bmp.rf.9a8c57cc58dd73710bebec37f6acba30.jpg\n",
            "Moved: Yellow-19-_bmp.rf.87187c3e891cc8ed17af2a18bc330b27.jpg\n",
            "Moved: Beige-2-_bmp.rf.21693a624980115e3f90b6b104d0bcbf.jpg\n",
            "Moved: Yellow-21-_bmp.rf.fcbf968f0bb57331974c2f96280e6384.jpg\n",
            "Moved: Triangular-24-_bmp.rf.5c07f15dcb1196ceb7b74081b8c3e4b9.jpg\n",
            "Moved: LightFeather-7-_bmp.rf.049cc5eb588fca94a3cd3fdc29cdc652.jpg\n",
            "Moved: Mossy-8-_bmp.rf.136a4431a40f4c6c55820296ef552f86.jpg\n",
            "Moved: BrokenSmall-74-_bmp.rf.c7d68e42704b4843a3cba4902a5dfa6f.jpg\n",
            "Moved: Mossy-11-_bmp.rf.f34a5f51efd9ae70250ac2c73d4c10cb.jpg\n",
            "Moved: BrokenSmall-53-_bmp.rf.440c013f7f59e91af768e1d3de967727.jpg\n",
            "Moved: Bone-12-_bmp.rf.995c31f2452b6a357221837644943e7a.jpg\n",
            "Moved: White-11-_bmp.rf.bc92788da57a82b068eb0e231606e82f.jpg\n",
            "Moved: Yellow-8-_bmp.rf.30c2c210058b8c93dc1b905364ec6e8e.jpg\n",
            "Moved: SizeB-10-_bmp.rf.cad503e81395b9da392e9c7cbca7c137.jpg\n",
            "Moved: SizeA-10-_bmp.rf.1eb0e6a62833551d5dd56a30fa1276b8.jpg\n",
            "Moved: DaYuenJiao-9-_bmp.rf.929cc84aa75d97c94f5dcbdf6c875bbb.jpg\n",
            "Moved: DaYuenJiao-1-_bmp.rf.c89a051146742c8f472220f51291117b.jpg\n",
            "Moved: MedFeather-5-_bmp.rf.7468f330f4c147a487566a6c3e4f0853.jpg\n",
            "Moved: Beige-3-_bmp.rf.2941661aaa786454f570b512b00c0d18.jpg\n",
            "Moved: Beige-2-_bmp.rf.d5c9e6e91c690438265a8516293fdcf1.jpg\n",
            "Moved: DoubleColour-3-_bmp.rf.00d40b3b98ff20c11f80f4d27c7e413a.jpg\n",
            "Moved: Bone-2-_bmp.rf.5e1fe8e950d45334a7dcf997ee35e96c.jpg\n",
            "Moved: HeavyFeather-10-_bmp.rf.7858febbda1e6c908f97b50b8c1a9e44.jpg\n",
            "Moved: BrokenSmall-73-_bmp.rf.3498c4fd662e38a73c51cba5eae16786.jpg\n",
            "Moved: WhiteBeige-11-_bmp.rf.110b8caadaff1558f8497baa08631ecc.jpg\n",
            "Moved: BrokenSmall-6-_bmp.rf.2f2a242b0467a5f09f3ff1ecc7eee43f.jpg\n",
            "Moved: Grey-15-_bmp.rf.397b2bc0e1801ec11b3082839a622012.jpg\n",
            "Moved: White-16-_bmp.rf.0bfe6e6ed6a387b91618bb7df32a525f.jpg\n",
            "Moved: Beige-11-_bmp.rf.e4b88d9dc04f073314458e8540c62ec8.jpg\n",
            "Moved: Triangular-24-_bmp.rf.574510682bdfc09e979269c2bdf4a4c3.jpg\n",
            "Moved: BrokenBig-9-_bmp.rf.1a389b14c166e6b56ec13e26308860e9.jpg\n",
            "Moved: BrokenSmall-70-_bmp.rf.f48d876ff4eddcd979f54e1bd7830b29.jpg\n",
            "Moved: BrokenSmall-31-_bmp.rf.6f07563b980c6883c26825886b4ac2e8.jpg\n",
            "Moved: HeavyFeather-9-_bmp.rf.6648fdc30bd486d82171922100b65302.jpg\n",
            "Moved: BrokenBig-8-_bmp.rf.d755b4f9430d45992d19722e9d98165c.jpg\n",
            "Moved: BrokenSmall-56-_bmp.rf.e8bb87a4721920f798a2be2739981c07.jpg\n",
            "Moved: BrokenBig-8-_bmp.rf.8e3f9640bdb7291c9a894364b0d0f171.jpg\n",
            "Moved: Yellow-16-_bmp.rf.d43edd023cce84bd0c2f09744c4bb42c.jpg\n",
            "Moved: Yellow-21-_bmp.rf.4e9df978cac450b4661024bbf4a35393.jpg\n",
            "Moved: ThickFlesh-4-_bmp.rf.6fed4faf72a915929f74b827822543c2.jpg\n",
            "Moved: Triangular-8-_bmp.rf.eaf455a7b9fd0ee2c22477a3e9ec5f33.jpg\n",
            "Moved: Bone-12-_bmp.rf.ea9d0a2b1b60abc2ff9edc923226f3bc.jpg\n",
            "Moved: ThickFlesh-18-_bmp.rf.1414c3bdabdef91e26d15c62b34aa67e.jpg\n",
            "Moved: Mossy-6-_bmp.rf.4ee8973da1d47c4292374be3753a39ac.jpg\n",
            "Moved: Strips-9-_bmp.rf.783e4638feb0ea3a201f88c562b8f300.jpg\n",
            "Moved: BrokenSmall-50-_bmp.rf.169e0b40ba06a46e3d0c2fc0d5596558.jpg\n",
            "Moved: SizeC-3-_bmp.rf.f62ab60c7ad53301c3be6e75565a1a8e.jpg\n",
            "Moved: SizeB-15-_bmp.rf.b410652d0015b1713a98aa2d35d17e73.jpg\n",
            "Moved: Triangular-13-_bmp.rf.ece6f353394138d30e6b79ee7d58c0fb.jpg\n",
            "Moved: White-6-_bmp.rf.984cab2f59a55cbf6ff553f48d84c5d2.jpg\n",
            "Moved: White-3-_bmp.rf.3519c0b184bad1dfec106648bb3ba984.jpg\n",
            "Moved: BrokenSmall-57-_bmp.rf.e501497d3821cf16117e39c78cc4e610.jpg\n",
            "Moved: Yellow-7-_bmp.rf.6a879e9fc615dece58ce2db919ed354a.jpg\n",
            "Moved: Grey-7-_bmp.rf.c275627528cfa7547e2c757272234d9b.jpg\n",
            "Moved: MedFeather-5-_bmp.rf.7d1b90cd5b152546d154b5ffb062ed1f.jpg\n",
            "Moved: WhiteBeige-16-_bmp.rf.34a0b5786c189afa32d34573628eadec.jpg\n",
            "Moved: Yellow-13-_bmp.rf.16a0e46ddf99ff12cf727bc025101b16.jpg\n",
            "Moved: Mossy-5-_bmp.rf.dbf610df3a4ca9702cda2d805037d589.jpg\n",
            "Moved: Ping-6-_bmp.rf.23c424dcc27c29e8af74a7d7c18521b6.jpg\n",
            "Moved: MedFeather-16-_bmp.rf.3fe86b70c7cf7907d5a192493424f495.jpg\n",
            "Moved: BrokenSmall-7-_bmp.rf.648733b3d301f97a4a71fe5f5f67effb.jpg\n",
            "Moved: Strips-13-_bmp.rf.a726a73619e12b1d78cff4e500112939.jpg\n",
            "Moved: SizeB-3-_bmp.rf.27e341fc12f37216c9bc9f4219190e52.jpg\n",
            "Moved: DoubleColour-9-_bmp.rf.7df3353437281adfd07a174f7a39aa5c.jpg\n",
            "Moved: BrokenSmall-49-_bmp.rf.10c9bbea92190f35cef2439714682560.jpg\n",
            "Moved: Strips-18-_bmp.rf.bc10d9f3f443ff65068d1423495fac92.jpg\n",
            "Moved: Triangular-10-_bmp.rf.76e9b328d5c9a4b8c984aaf93969ed15.jpg\n",
            "Moved: Yellow-7-_bmp.rf.55ddba002b18b0dac1182ef6340414a2.jpg\n",
            "Moved: MedFeather-17-_bmp.rf.dad1b3be7510762131652f55b53c7a02.jpg\n",
            "Moved: BrokenSmall-66-_bmp.rf.230a261d42fdf6f9e9c57a685cd63b78.jpg\n",
            "Moved: Triangular-9-_bmp.rf.6150df2adea82710453786bc5c4cbf5c.jpg\n",
            "Moved: BrokenBig-3-_bmp.rf.c6f1d10047d887599e95078db2dcb4d3.jpg\n",
            "Moved: Yellow-6-_bmp.rf.5b032160c4879ce74ce0702cf3bf2b9c.jpg\n",
            "Moved: SizeC-18-_bmp.rf.a9afa1c49934748136528b536572af20.jpg\n",
            "Moved: Triangular-4-_bmp.rf.2c319b6f3bab984383f662f73353f946.jpg\n",
            "Moved: Ping-9-_bmp.rf.b41a5ff2848e083e67e714240777843f.jpg\n",
            "Moved: Bone-3-_bmp.rf.2f324dc97cf829b21f65d3c18f90cf95.jpg\n",
            "Moved: BrokenSmall-48-_bmp.rf.3ccdd4fa83af54b75dd31618b020c7c0.jpg\n",
            "Moved: BrokenSmall-30-_bmp.rf.502f807ec133715bcefae43cbce1e514.jpg\n",
            "Moved: BrokenSmall-32-_bmp.rf.c96dea9d8cb6ddb119e7be69ef5059cb.jpg\n",
            "Moved: BrokenSmall-37-_bmp.rf.8a2e2409f6b54eaf973be9671c4d8cce.jpg\n",
            "Moved: Bone-3-_bmp.rf.8fbf82e1ea423fbf775f954b607daf4e.jpg\n",
            "Moved: SizeA-15-_bmp.rf.86795d0f0d0f739d244daaedd8ccbffd.jpg\n",
            "Moved: Grey-2-_bmp.rf.613d5f3688e8e5f6e17e48fe57f963b5.jpg\n",
            "Moved: Triangular-2-_bmp.rf.a78c6869ac38120ed0dd7ffbee2dc96e.jpg\n",
            "Moved: ThickFlesh-16-_bmp.rf.4d0efbe8ffeeeb669caab49d07a76400.jpg\n",
            "Moved: BrokenSmall-31-_bmp.rf.43881ef765a3558ada45210a6f566d2f.jpg\n",
            "Moved: BrokenSmall-55-_bmp.rf.7a9f2d59c06fdbf2b610ef2d0370d46d.jpg\n",
            "Moved: SizeB-5-_bmp.rf.4c9f96205c43bd7ac9f051a53a62fb63.jpg\n",
            "Moved: SizeC-11-_bmp.rf.3415a424394a399b8045ed092b2d6e21.jpg\n",
            "Moved: WhiteBeige-15-_bmp.rf.fdbea3b0ab78a198b7cbef339ab02d87.jpg\n",
            "Moved: BrokenSmall-6-_bmp.rf.340b379730c98a76c0bf2e3be6703db4.jpg\n",
            "Moved: Beige-8-_bmp.rf.955a4b7410cdae6337ac981b3c8e4fce.jpg\n",
            "Moved: Strips-5-_bmp.rf.5584c8757c5bdc8a8cf3cb0fe732b33d.jpg\n",
            "Moved: Strips-4-_bmp.rf.ef0fcd129b9b01ccb71475e50d365e63.jpg\n",
            "Moved: ThickFlesh-15-_bmp.rf.6910e5faf828cc299fba48c71df3251c.jpg\n",
            "Moved: DoubleColour-12-_bmp.rf.2702830e629796218fdf08ef3f4b27f2.jpg\n",
            "Moved: LightFeather-18-_bmp.rf.0f46779cabf9049d52714a5e3302c629.jpg\n",
            "Moved: SizeC-14-_bmp.rf.faa28c762ecd3f09df856a4a30c3b72b.jpg\n",
            "Moved: SizeA-6-_bmp.rf.bfa0f7b34fc0d966cb3f3fb93d45f65e.jpg\n",
            "Moved: WhiteBeige-5-_bmp.rf.ad5e847ca208ae1e1dd2154f5379c0f3.jpg\n",
            "Moved: Triangular-9-_bmp.rf.76ea7d75a35282ae572a343181f4d6c4.jpg\n",
            "Moved: HeavyFeather-11-_bmp.rf.99e6a9b79b1d8104bf124e3fef8a9404.jpg\n",
            "Moved: Bone-11-_bmp.rf.1e04bd52e89f462f7298efd573553ebc.jpg\n",
            "Moved: Mossy-13-_bmp.rf.1c51f26269594097294e80e8d466bb19.jpg\n",
            "Moved: SizeC-15-_bmp.rf.4b0d213455c4268686ffbc12cab4ed09.jpg\n",
            "Moved: BrokenBig-7-_bmp.rf.399c4b7fe4ed59df82e57fa219e7b8ee.jpg\n",
            "Moved: Yellow-8-_bmp.rf.1a4ce6d0b93a8627511d4c6ab2904bb8.jpg\n",
            "Moved: Ping-14-_bmp.rf.d2d30d1d78ecf7eeb6449b0e2947be6b.jpg\n",
            "Moved: WhiteBeige-2-_bmp.rf.e407d0dd893b59fc3e7a67be2c05b4e4.jpg\n",
            "Moved: WhiteBeige-4-_bmp.rf.947812a8b0639417cf0d67733cf92393.jpg\n",
            "Moved: BrokenSmall-36-_bmp.rf.89dc7876a8a4f9c32fae73e4ca6f70f7.jpg\n",
            "Moved: SizeB-14-_bmp.rf.06d0e5896d41a1ed5b548ac1800fafcd.jpg\n",
            "Moved: Yellow-12-_bmp.rf.a058410441ba2ecb6392a6fe982a6f61.jpg\n",
            "Moved: ThickFlesh-2-_bmp.rf.554acbab39b29ef55e269a20e42b6949.jpg\n",
            "Moved: BrokenSmall-20-_bmp.rf.119e06f1a64b0157a3e93115f4138589.jpg\n",
            "Moved: HeavyFeather-8-_bmp.rf.34e3b5b008f274a2fff383f3bde69d3e.jpg\n",
            "Moved: Yellow-18-_bmp.rf.1a5898cf5d818bb8c3782a0fba340f41.jpg\n",
            "Moved: WhiteBeige-9-_bmp.rf.48ba76c78b3c8a33ff18b89ed409b8be.jpg\n",
            "Moved: BrokenSmall-43-_bmp.rf.5389138151fb6c8c798cbbff7546d7d6.jpg\n",
            "Moved: White-9-_bmp.rf.a2e7fdbe606638342a82ea29d372548b.jpg\n",
            "Moved: DoubleColour-13-_bmp.rf.f5e365cbceadf701de1cbd5a06fb8631.jpg\n",
            "Moved: MedFeather-13-_bmp.rf.0b64ca269928073e7f61bc98d82c0269.jpg\n",
            "Moved: Strips-10-_bmp.rf.eb0bba32889c80fc7d19093a2f5b4f68.jpg\n",
            "Moved: Triangular-2-_bmp.rf.8b65000c90e218996ef028d6bb23eaf2.jpg\n",
            "Moved: Grey-22-_bmp.rf.cc0f21daf9311100b76031729fcf6fe2.jpg\n",
            "Moved: WhiteBeige-3-_bmp.rf.7e7df3f83dbb4cc67d82a1e567b8b797.jpg\n",
            "Moved: SizeC-6-_bmp.rf.d2bd4d5ad9af5905de33bd0eda594e9c.jpg\n",
            "Moved: Bone-6-_bmp.rf.de9780123e426f6b3bc4bc7e96f69298.jpg\n",
            "Moved: White-17-_bmp.rf.91fb7e6e4f6cacb2abc4e5f0aa2d3e78.jpg\n",
            "Moved: SizeC-7-_bmp.rf.8fcd3530eda3de2f68626188efab43e6.jpg\n",
            "Moved: BrokenBig-11-_bmp.rf.21caae9fef809d1188afa85e9b9b6ef5.jpg\n",
            "Moved: Mossy-11-_bmp.rf.2eb2b95a70946e28151683072bbbb7bd.jpg\n",
            "Moved: BrokenSmall-51-_bmp.rf.7b9190ae19617348e7dae2ff7f7d03f5.jpg\n",
            "Moved: BrokenSmall-53-_bmp.rf.34e78866b25795c9f5f058d51806ad95.jpg\n",
            "Moved: WhiteBeige-13-_bmp.rf.02b4f35411b5a87224e90ca0be6aaee9.jpg\n",
            "Moved: BrokenSmall-45-_bmp.rf.2bc20a619375ec64939f8676815d6751.jpg\n",
            "Moved: BrokenSmall-5-_bmp.rf.21346e523146ea8d9f02d035cafa38dd.jpg\n",
            "Moved: Strips-13-_bmp.rf.3860c67c404264514903dcdd7703c093.jpg\n",
            "Moved: SizeA-10-_bmp.rf.cfae4b7e11a7c6b6eb35b0a19a61e897.jpg\n",
            "Moved: Ping-5-_bmp.rf.32f65bb9b4c538244678ddadaef31f27.jpg\n",
            "Moved: SizeC-1-_bmp.rf.cc3a47ccdd237b87931eed80fd20bafd.jpg\n",
            "Moved: BrokenSmall-18-_bmp.rf.33f0bc1694d1e4633423684d25698dbe.jpg\n",
            "Moved: Yellow-19-_bmp.rf.87681c0976b7b05650fc2a83416f7e1d.jpg\n",
            "Moved: MedFeather-4-_bmp.rf.6798d7d1a4536a4680f3f1473f731b08.jpg\n",
            "Moved: ThickFlesh-5-_bmp.rf.57caaa1fae7b9db4e684f5e49aa6c4b7.jpg\n",
            "Moved: WhiteBeige-15-_bmp.rf.28967ff2b8079984a10899d9546136fa.jpg\n",
            "Moved: MedFeather-5-_bmp.rf.3c9b38ff94b32433d525f5746ca5cd5d.jpg\n",
            "Moved: Yellow-12-_bmp.rf.9de9cd20a3335398f26dcdc5d57dcbe2.jpg\n",
            "Moved: SizeC-1-_bmp.rf.e24a6aea896f4e55017e7855ee4881c3.jpg\n",
            "Moved: SizeA-12-_bmp.rf.fad04fd5e870d712f04449aa75a6a6a4.jpg\n",
            "Moved: Mossy-6-_bmp.rf.b5f5a96b33a77dbdde436542f1ffd911.jpg\n",
            "Moved: SizeA-8-_bmp.rf.d717f01249068accd504340b83cba334.jpg\n",
            "Moved: BrokenSmall-59-_bmp.rf.e1aa59ea8957b64cd03bc023287adcc7.jpg\n",
            "Moved: Bone-7-_bmp.rf.bb54cf7c83d203d51a0a07f07b12f02b.jpg\n",
            "Moved: Triangular-4-_bmp.rf.d5d16a31e06219586015819d8ca874c9.jpg\n",
            "Moved: WhiteBeige-17-_bmp.rf.23b3a690527e336dac127b674c9d38d4.jpg\n",
            "Moved: SizeC-4-_bmp.rf.02eb9ea1ec70d223884b6ec7b58a8a4e.jpg\n",
            "Moved: DoubleColour-9-_bmp.rf.79d91d019b0a154a205448a3c271fb2a.jpg\n",
            "Moved: BrokenSmall-74-_bmp.rf.e00f2c1c564c25bb06cfa486842bd6a0.jpg\n",
            "Moved: SizeC-8-_bmp.rf.a0da8060c74370d648641a6502e907ff.jpg\n",
            "Moved: BrokenSmall-25-_bmp.rf.72288fd13cfd815b7283bcb8fa7869f7.jpg\n",
            "Moved: White-12-_bmp.rf.0bff1d9c50e879bd84f01b8c9aaf473e.jpg\n",
            "Moved: BrokenSmall-21-_bmp.rf.dd1c1dae5f83c0e17216bf4b5439314a.jpg\n",
            "Moved: DoubleColour-3-_bmp.rf.e676aba08eae164f63e16cf61f41c7ae.jpg\n",
            "Moved: HeavyFeather-15-_bmp.rf.8ea9eda8897e44ef4c3363e96528a055.jpg\n",
            "Moved: SizeB-13-_bmp.rf.241b79c1371b2f1645b464ee8791f601.jpg\n",
            "Moved: Triangular-21-_bmp.rf.4270553a02f7d219cd1964c39d071693.jpg\n",
            "Moved: Yellow-6-_bmp.rf.c78eaf7f3f5a1f5b73b084aab7780688.jpg\n",
            "Moved: SizeA-11-_bmp.rf.36c65c3fbfaefbd3aca1a9d9e194e773.jpg\n",
            "Moved: MedFeather-3-_bmp.rf.57db0b626f387dd434f51318cd8b3029.jpg\n",
            "Moved: BrokenSmall-71-_bmp.rf.56caf76c4547962e344947b040abebac.jpg\n",
            "Moved: SizeB-11-_bmp.rf.f9b018435be081d460eeed7fa8787885.jpg\n",
            "Moved: DoubleColour-8-_bmp.rf.ce8d8cdab598b51fb28023cd4a7dd124.jpg\n",
            "Moved: HeavyFeather-17-_bmp.rf.cfe425bfcd8dcc4619c3db08fb59b81e.jpg\n",
            "Moved: Triangular-1-_bmp.rf.9a02659f189328f81ae9ff7c6371668e.jpg\n",
            "Moved: ThickFlesh-11-_bmp.rf.b313119421c11604e71d8d2618bdb3e9.jpg\n",
            "Moved: White-4-_bmp.rf.dd30ace1661e3ffca85271f9e7384183.jpg\n",
            "Moved: Mossy-5-_bmp.rf.2c1812c94f0760a2a9f33631ccbd0cc2.jpg\n",
            "Moved: Beige-1-_bmp.rf.c16307a9ceba90388a1d065d96f5c303.jpg\n",
            "Moved: Mossy-4-_bmp.rf.c84fd5c1f0c467c81b19804708e3c806.jpg\n",
            "Moved: Strips-9-_bmp.rf.fb59f6de85620c1a81a4290b8249a6f1.jpg\n",
            "Moved: Strips-1-_bmp.rf.8a93b9ad3117a06ca7daa5b9c80c787f.jpg\n",
            "Moved: BrokenBig-12-_bmp.rf.d64d08f29e1a3608a893774c612947c0.jpg\n",
            "Moved: SizeB-1-_bmp.rf.f4ef5c50875b26bc793e5891864e6cbb.jpg\n",
            "Moved: Beige-12-_bmp.rf.993627c5ce161b062c29c9403f3c1fb1.jpg\n",
            "Moved: MedFeather-6-_bmp.rf.71d7a2baad09423e8e4600d7ee919567.jpg\n",
            "Moved: DoubleColour-10-_bmp.rf.80d481a7a92b4d79fe8df534e69e8b26.jpg\n",
            "Moved: Triangular-22-_bmp.rf.de4052bbe0e6bd3409d3aefd424b12ca.jpg\n",
            "Moved: DaYuenJiao-15-_bmp.rf.463fb32696634e9fe9e5bc1298168242.jpg\n",
            "Moved: DaYuenJiao-12-_bmp.rf.e31a860322f1be936743c29036398d44.jpg\n",
            "Moved: Ping-12-_bmp.rf.3293fdfefb42dab0caf51693d3558b7b.jpg\n",
            "Moved: DaYuenJiao-4-_bmp.rf.3811c4c630c2125c32b142d1f7bc4d0f.jpg\n",
            "Moved: DoubleColour-7-_bmp.rf.fbcf940f39156c9c587b8f854e0a19c0.jpg\n",
            "Moved: Beige-12-_bmp.rf.9b38e093452cfc6f887df3ef0c52faeb.jpg\n",
            "Moved: LightFeather-2-_bmp.rf.b4f2e43e7c4406eae5b3838dea79c96d.jpg\n",
            "Moved: SizeC-12-_bmp.rf.f8d95ad46d92a029f6a5cb6a2e8f978e.jpg\n",
            "Moved: BrokenSmall-50-_bmp.rf.738a81c3933609ca5f7b5d7f01d35311.jpg\n",
            "Moved: BrokenSmall-36-_bmp.rf.b6ca161e56b13b71208b177ca883b277.jpg\n",
            "Moved: ThickFlesh-2-_bmp.rf.4606718b655ec35ecbe78011f3cb2db2.jpg\n",
            "Moved: BrokenSmall-75-_bmp.rf.2f62b9ae9380d9feabdbcbc80a140719.jpg\n",
            "Moved: Beige-12-_bmp.rf.70d8e3315563bc5ee62190002fe4b731.jpg\n",
            "Moved: BrokenSmall-25-_bmp.rf.9b9b07a494d88e9e80d85bf9db4feae7.jpg\n",
            "Moved: MedFeather-7-_bmp.rf.932ac1f1a3a89e9dee484a0909629da1.jpg\n",
            "Moved: Grey-19-_bmp.rf.379f7e70bd60888153dac61c3d80b583.jpg\n",
            "Moved: Ping-3-_bmp.rf.d918ebfdebbc3ab133c163cc848e85ac.jpg\n",
            "Moved: Bone-1-_bmp.rf.e6d4344159998355aa7da2bbe4535c30.jpg\n",
            "Moved: HeavyFeather-13-_bmp.rf.ea557d644c9ea59bf09f0af7cb23d373.jpg\n",
            "Moved: MedFeather-7-_bmp.rf.c5b6ae671cf495420af2269ad4647aaf.jpg\n",
            "Moved: Ping-15-_bmp.rf.cf4f477e2317b8bd8eac8a8214478555.jpg\n",
            "Moved: BrokenSmall-34-_bmp.rf.a178712e2ed07519b57e6bebeaab94b1.jpg\n",
            "Moved: MedFeather-1-_bmp.rf.4fce86d8ac492102747626c485228328.jpg\n",
            "Moved: Mossy-15-_bmp.rf.cf6777601cf63ec6247bcb1fd0a46cb1.jpg\n",
            "Moved: BrokenSmall-13-_bmp.rf.c8f0c671e4a279162b44b669dd7d186c.jpg\n",
            "Moved: BrokenBig-2-_bmp.rf.21faf12ed505c19c3fbb40faba88bb73.jpg\n",
            "Moved: Bone-9-_bmp.rf.87dfb684ef886a3fa7db3a368f88c10c.jpg\n",
            "Moved: HeavyFeather-2-_bmp.rf.445de2c62a859d3f0755f4e83bf9d8e6.jpg\n",
            "Moved: DaYuenJiao-10-_bmp.rf.3d581b889b2c2c5cb5b848a57fdedfcf.jpg\n",
            "Moved: BrokenSmall-34-_bmp.rf.4933afb75a2c9b5397d7473402080a31.jpg\n",
            "Moved: BrokenBig-5-_bmp.rf.710ebe556c465b83f4f6d5a2f6d818b1.jpg\n",
            "Moved: LightFeather-9-_bmp.rf.bf0514184f12b781e462e743227ac3cf.jpg\n",
            "Moved: SizeB-10-_bmp.rf.559f7a336e3b78816ef9e4fa290caf04.jpg\n",
            "Moved: MedFeather-14-_bmp.rf.e1c5ba4e217ee641b6c59e52acd19c6b.jpg\n",
            "Moved: DaYuenJiao-2-_bmp.rf.fb4c2afd10f2687613ca14b0efc4a8a1.jpg\n",
            "Moved: Bone-11-_bmp.rf.5eabae61830a7bcd367b6b5ef67549b4.jpg\n",
            "Moved: Yellow-18-_bmp.rf.88e67eddc1fddf127fe587651ec61405.jpg\n",
            "Moved: SizeC-2-_bmp.rf.80915d2a1c56af78eb4a9d0ba00ff9ce.jpg\n",
            "Moved: Triangular-11-_bmp.rf.27ac7570805eeb31714cb1d139a71ec2.jpg\n",
            "Moved: Mossy-2-_bmp.rf.37b875ba26162b50fddd7dc0e19f138c.jpg\n",
            "Moved: Triangular-20-_bmp.rf.e0db54ce44eb992a876e9d557dd03142.jpg\n",
            "Moved: LightFeather-2-_bmp.rf.9cea636ac30984218835a3e399ed3ea3.jpg\n",
            "Moved: SizeA-3-_bmp.rf.3db757f4b5169f63f493c04885dcefe4.jpg\n",
            "Moved: SizeB-12-_bmp.rf.357c1e05f13b0a695e680d5ee32c3047.jpg\n",
            "Moved: Triangular-6-_bmp.rf.c43a7539995ac91173211e4248b11f38.jpg\n",
            "Moved: WhiteBeige-4-_bmp.rf.9b7cdacb86fd124ce81088c6918209b1.jpg\n",
            "Moved: Strips-17-_bmp.rf.da831285b7e00e6b06e76426fe85ee30.jpg\n",
            "Moved: LightFeather-19-_bmp.rf.85d2ec2a3112fb15f29af5e5546fa4df.jpg\n",
            "Moved: ThickFlesh-12-_bmp.rf.a9a45a566df7ed50e038f376041d030d.jpg\n",
            "Moved: Yellow-7-_bmp.rf.977dad9ce5836a3cb3f1ef6743b04fb9.jpg\n",
            "Moved: BrokenSmall-67-_bmp.rf.085d332e69f11796b37296133f4b32bc.jpg\n",
            "Moved: SizeB-11-_bmp.rf.cc20b524a2903e34e16f201ad0e370c3.jpg\n",
            "Moved: DaYuenJiao-6-_bmp.rf.35faaf2a9f25f44057ea4af22a2c0b72.jpg\n",
            "Moved: DoubleColour-8-_bmp.rf.4d6789a3591957c392396427cb9f56cd.jpg\n",
            "Moved: BrokenSmall-41-_bmp.rf.c4ea94498fe936421ff18bd9d162dfe3.jpg\n",
            "Moved: Triangular-13-_bmp.rf.ea74a323106892fb9f16caeaeb6cbb17.jpg\n",
            "Moved: DaYuenJiao-16-_bmp.rf.9bba86a8634280876aad5c0f8c7d1fa7.jpg\n",
            "Moved: Bone-4-_bmp.rf.f7289d9166af8822a9d0eeb59e4fae8f.jpg\n",
            "Moved: Bone-8-_bmp.rf.a713b21a94818c6ec3713ca3e3a9e3ab.jpg\n",
            "Moved: BrokenSmall-67-_bmp.rf.b3efa94298b683173d4666b6e792f178.jpg\n",
            "Moved: Mossy-10-_bmp.rf.e32ca0afb0c8f3297ec6cbeb9951ea74.jpg\n",
            "Moved: DoubleColour-6-_bmp.rf.487cf2aed5ea616e1b2f99d6bf067819.jpg\n",
            "Moved: Grey-24-_bmp.rf.cc2dd254113260a1de12d46956a1042f.jpg\n",
            "Moved: WhiteBeige-3-_bmp.rf.1a2e4f6b39d700294a52565e1abfa46d.jpg\n",
            "Moved: BrokenSmall-8-_bmp.rf.a860939223b885ec96cb47ef8d7ae2ea.jpg\n",
            "Moved: Beige-8-_bmp.rf.840fd4eaeb1adff21b16c7f12859aa0a.jpg\n",
            "Moved: DaYuenJiao-18-_bmp.rf.8cf389be488daf314b8e71e0edfe0997.jpg\n",
            "Moved: MedFeather-20-_bmp.rf.a72250d4d330bc3794e8572f82c1850e.jpg\n",
            "Moved: BrokenSmall-30-_bmp.rf.57a8eb80fa5d4dc30823a28100ee94b8.jpg\n",
            "Moved: White-3-_bmp.rf.9620cf3c60d35745c3181e986834bc91.jpg\n",
            "Moved: DoubleColour-14-_bmp.rf.9c7125d77ce23e4470575c2347997115.jpg\n",
            "Moved: SizeB-5-_bmp.rf.671e591dc8f1cedb51728778ee45f98e.jpg\n",
            "Moved: BrokenBig-9-_bmp.rf.7a7079abb4d8650b64b22c3e9bfc277d.jpg\n",
            "Moved: DaYuenJiao-11-_bmp.rf.bf5ab5587e1aa5e9b69c11ef6c056d87.jpg\n",
            "Moved: DoubleColour-7-_bmp.rf.915911b0a3d9bf29ce747bfaf2a129de.jpg\n",
            "Moved: Strips-18-_bmp.rf.4490b09d17026fd47fb53d78422b0c9d.jpg\n",
            "Moved: SizeB-7-_bmp.rf.963df17cdf89b67c4280768e9628361d.jpg\n",
            "Moved: Beige-11-_bmp.rf.9f9ccdb6b8d1e1910114c7723a7503ec.jpg\n",
            "Moved: BrokenBig-12-_bmp.rf.7dc69d3878d30401174fe2f25114cdb2.jpg\n",
            "Moved: Triangular-16-_bmp.rf.c192c29be673020b4a9efc155931e3a5.jpg\n",
            "Moved: MedFeather-16-_bmp.rf.deea2bc826335695d0b0bff2a5446cb8.jpg\n",
            "Moved: Triangular-19-_bmp.rf.046c92fd4ca1f86e77083599c5a642a3.jpg\n",
            "Moved: BrokenSmall-36-_bmp.rf.258c4c8e4c03e721bc3d3c2de0afe346.jpg\n",
            "Moved: BrokenSmall-71-_bmp.rf.026e0a74fd80e9847f1baa99e4c29dd2.jpg\n",
            "Moved: SizeA-9-_bmp.rf.4bb0d6fcd579efd49f34822329c46acb.jpg\n",
            "Moved: BrokenSmall-65-_bmp.rf.360fc4882ef0ab202d2fa747d3b82777.jpg\n",
            "Moved: ThickFlesh-8-_bmp.rf.505d5aeda9bdec4e1fc7f7cebdef631c.jpg\n",
            "Moved: Ping-12-_bmp.rf.435ceb3e15bf9e056215a752c2c83733.jpg\n",
            "Moved: DaYuenJiao-11-_bmp.rf.b8e0c71957f8f1d9a518edc89f1c12b7.jpg\n",
            "Moved: BrokenBig-2-_bmp.rf.034b8e1103fdc6fb49b487dc7545d8d4.jpg\n",
            "Moved: HeavyFeather-4-_bmp.rf.ecccdbf53adbea3dbfee9d1f6e0fad77.jpg\n",
            "Moved: WhiteBeige-16-_bmp.rf.0209f8eac52c72d8292f652cb8a6bfe3.jpg\n",
            "Moved: Ping-3-_bmp.rf.959c379c56259337518c3da0e48b8d8c.jpg\n",
            "Moved: BrokenBig-3-_bmp.rf.742ef2a34a4383f71908c2789b0e9355.jpg\n",
            "Moved: SizeA-14-_bmp.rf.8460bdc861659f0d3b1bf6a8093c7fa7.jpg\n",
            "Moved: Beige-3-_bmp.rf.87f0363c71680ecd0d09bcdee3c50d0e.jpg\n",
            "Moved: BrokenSmall-55-_bmp.rf.c8f45ae28d43a314f5a4e8495539e619.jpg\n",
            "Moved: Ping-5-_bmp.rf.7e105b9eca89419a1ccef35e9a808c20.jpg\n",
            "Moved: White-17-_bmp.rf.feee73f36b3bcbd981def634bc478cae.jpg\n",
            "Moved: DaYuenJiao-3-_bmp.rf.4c38f5f9e29fee36ca8b739f53ea7b50.jpg\n",
            "Moved: SizeC-8-_bmp.rf.b9c50e156c51fd0771847cd77390d5c0.jpg\n",
            "Moved: Ping-2-_bmp.rf.f4ed77994ecc52e26276fae23330cc26.jpg\n",
            "Moved: BrokenSmall-53-_bmp.rf.af9caae959316fbe661fd9a96a63120e.jpg\n",
            "Moved: SizeA-9-_bmp.rf.864aecbe8372859aa45a01da23f39e43.jpg\n",
            "Moved: ThickFlesh-8-_bmp.rf.8fd39fe918510c5d355ae9d54f1ad21b.jpg\n",
            "Moved: HeavyFeather-12-_bmp.rf.1c9ef81e6c2914dba9f4bf708b66beaa.jpg\n",
            "Moved: Ping-2-_bmp.rf.abb9a02b54b3b72f909fc675056672bf.jpg\n",
            "Moved: Beige-9-_bmp.rf.ed994c46457218e1e5dee3a70eba3c9c.jpg\n",
            "Moved: Beige-10-_bmp.rf.d21170a0c40ba436036d115fd7c3f3ef.jpg\n",
            "Moved: Ping-6-_bmp.rf.540b34c9c86b16105ca46101d2047c4e.jpg\n",
            "Moved: Yellow-5-_bmp.rf.cd483250c60daa79c6c2a2705c3b71e4.jpg\n",
            "Moved: ThickFlesh-11-_bmp.rf.2fad5d5c60e5234ca5907d48e289c82d.jpg\n",
            "Moved: WhiteBeige-16-_bmp.rf.a8f6f4963126e3a942020ce016d993d1.jpg\n",
            "Moved: Strips-16-_bmp.rf.ab15cbccc97b5aa6292f9e7e76298d13.jpg\n",
            "Moved: Mossy-7-_bmp.rf.8e74918b50ce38233e58f82ec691e19e.jpg\n",
            "Moved: White-7-_bmp.rf.958a5ac044b8294cc34e988fdf873ef3.jpg\n",
            "Moved: BrokenSmall-41-_bmp.rf.da86b41e5af1219b026b844e15902773.jpg\n",
            "Moved: BrokenSmall-70-_bmp.rf.dbc80948b75e318b4ddeaacc6383dbce.jpg\n",
            "Moved: BrokenSmall-52-_bmp.rf.5c48014b1d50b3c734716bc7cf89db4c.jpg\n",
            "Moved: ThickFlesh-10-_bmp.rf.c7ab42c174f017abd2a4a2ebc65874a5.jpg\n",
            "Moved: Yellow-5-_bmp.rf.bdc5dcba3c10699d1e92c5e9171add1c.jpg\n",
            "Moved: SizeA-15-_bmp.rf.286f153deac9a814d17d99d7ba04b1ce.jpg\n",
            "Moved: SizeC-17-_bmp.rf.9873372230f339ab79c8b2e020b48aad.jpg\n",
            "Moved: BrokenSmall-26-_bmp.rf.5e152a56452771d27ee246cbfd60065e.jpg\n",
            "Moved: DoubleColour-15-_bmp.rf.e8f142a3afd3786d251eea212b33d7ee.jpg\n",
            "Moved: BrokenSmall-40-_bmp.rf.9291d5b6db619440864f7074f082709f.jpg\n",
            "Moved: WhiteBeige-8-_bmp.rf.089dc74a553da57ee83a3020d2d5a71e.jpg\n",
            "Moved: HeavyFeather-6-_bmp.rf.4b9010646cf068e61177bb1f90c5dea6.jpg\n",
            "Moved: Grey-4-_bmp.rf.da88351a92672c970e6143620a8372ad.jpg\n",
            "Moved: SizeA-11-_bmp.rf.4fe2e50cee6b8ed82822879d7c2e9310.jpg\n",
            "Moved: Grey-5-_bmp.rf.e207527d27a370863949af45dfd0d6a6.jpg\n",
            "Moved: Ping-16-_bmp.rf.37e0f0995fce7966ec57b1989082fd51.jpg\n",
            "Moved: SizeB-11-_bmp.rf.5ce990de95687837226118a46fae540a.jpg\n",
            "Moved: Bone-8-_bmp.rf.a8e14ae7079096cddf40bea266d14130.jpg\n",
            "Moved: BrokenSmall-27-_bmp.rf.65ddb2651a52f3ffb59929ce63831a9b.jpg\n",
            "Moved: Yellow-4-_bmp.rf.43a6e8e8fc2912111b3c6160e5e98392.jpg\n",
            "Moved: BrokenSmall-46-_bmp.rf.ec6755da5e2384258864b7bd1597448c.jpg\n",
            "Moved: DaYuenJiao-7-_bmp.rf.42bcdb3e691792853ab3016852dac00c.jpg\n",
            "Moved: DoubleColour-13-_bmp.rf.eeed736ece3214d8c0795c47c6baab74.jpg\n",
            "Moved: BrokenSmall-7-_bmp.rf.8d79f140151e4948eb6baf1a79a94398.jpg\n",
            "Moved: Yellow-1-_bmp.rf.1e86aec87d5fbb0ecd0ee8bfc9a64846.jpg\n",
            "Moved: HeavyFeather-9-_bmp.rf.70c11f60a4fa797d622551ac434e1ae8.jpg\n",
            "Moved: Bone-11-_bmp.rf.9a57b87bb80a11abed667c9c3a055951.jpg\n",
            "Moved: MedFeather-15-_bmp.rf.206629139c28657340e513a70a919b5e.jpg\n",
            "Moved: WhiteBeige-8-_bmp.rf.117d4315f225a0832ff8235f71ab52eb.jpg\n",
            "Moved: Yellow-15-_bmp.rf.651ec2ac90497c08402bcd31cf61e120.jpg\n",
            "Moved: Strips-3-_bmp.rf.c2a00d74e462205cb69b3e82a981d8ee.jpg\n",
            "Moved: Yellow-5-_bmp.rf.729b90b298c4edb206e276f9559aa201.jpg\n",
            "Moved: BrokenSmall-71-_bmp.rf.9e4a0dd821427117b7c0f3da9c0a6fc4.jpg\n",
            "Moved: DaYuenJiao-18-_bmp.rf.e17952b1d57bc94d1361746e251eb893.jpg\n",
            "Moved: BrokenSmall-76-_bmp.rf.157d35d2cb106a2a54fd8ab1d023eb48.jpg\n",
            "Moved: Mossy-7-_bmp.rf.00f9d1dfefd26beffe0b96b7246f038c.jpg\n",
            "Moved: DoubleColour-8-_bmp.rf.9bddd05cfb5ce871a55235069e860e50.jpg\n",
            "Moved: Grey-5-_bmp.rf.1a8c5171d76eeb25437d2492da50a471.jpg\n",
            "Moved: LightFeather-9-_bmp.rf.77bde295fdc4746f23ad491a59d59a58.jpg\n",
            "Moved: Strips-17-_bmp.rf.25e97c22a43fe577d87d21e1b4573273.jpg\n",
            "Moved: Bone-9-_bmp.rf.34068b6a66ad901406649a2f6b4a5a2c.jpg\n",
            "Moved: SizeA-7-_bmp.rf.450b9af5848a3d027260052459764f70.jpg\n",
            "Moved: LightFeather-19-_bmp.rf.38b4ca49eb67489355bae9fc297ab343.jpg\n",
            "Moved: HeavyFeather-13-_bmp.rf.10ba8eac239dbc5bfc523d02a12724bf.jpg\n",
            "Moved: Triangular-8-_bmp.rf.537360240fbbbc9009211d8ad732bcac.jpg\n",
            "Moved: Mossy-9-_bmp.rf.d5571d25b52b4f3e0516f0d64fb2b842.jpg\n",
            "Moved: BrokenSmall-22-_bmp.rf.fe3951df62fa0a1754fa5d0b68572be3.jpg\n",
            "Moved: BrokenSmall-63-_bmp.rf.a312ae826539903c0da3460be3d64c9c.jpg\n",
            "Moved: MedFeather-17-_bmp.rf.709167ee38745c3f3962cf4793b15759.jpg\n",
            "Moved: WhiteBeige-2-_bmp.rf.ad92a50fb54e482776677974e81dd05a.jpg\n",
            "Moved: BrokenSmall-69-_bmp.rf.5c4d22fb968c28da57d41ecccabd3b40.jpg\n",
            "Moved: LightFeather-8-_bmp.rf.a53e38078f75bcb4a8b86a97e1ea49d3.jpg\n",
            "Moved: SizeC-9-_bmp.rf.9a793f399e8b8ddfa98f57380cbbd14e.jpg\n",
            "Moved: SizeC-11-_bmp.rf.630fcebac01254237b41fa67ea9e443d.jpg\n",
            "Moved: DaYuenJiao-6-_bmp.rf.2782b420d7f2233e0f043c48bba1a686.jpg\n",
            "Moved: White-6-_bmp.rf.f84490010da04c30ecd7c7fc7857edc1.jpg\n",
            "Moved: ThickFlesh-12-_bmp.rf.e4e5e7c5d7fb9bfd738eab080fae94d9.jpg\n",
            "Moved: LightFeather-5-_bmp.rf.f7553986563fa735b1b3a4ed2c0a6fc7.jpg\n",
            "Moved: Mossy-16-_bmp.rf.c4994718c1988856ddde8da8f94c04b0.jpg\n",
            "Moved: SizeA-3-_bmp.rf.0961fa1b5f525832c5e84cffed1fd4a0.jpg\n",
            "Moved: SizeC-6-_bmp.rf.b9487ad23ca4f24d66a52879749c9723.jpg\n",
            "Moved: SizeA-13-_bmp.rf.a33baa39ec701e0c5087afc3f099b0a9.jpg\n",
            "Moved: Strips-14-_bmp.rf.1191cf23e945edc467be585e9164654a.jpg\n",
            "Moved: LightFeather-10-_bmp.rf.91270d890337bc180c82bf4444b2a661.jpg\n",
            "Moved: White-18-_bmp.rf.fee4ca575bfebc992f8bd3fb486d255e.jpg\n",
            "Moved: BrokenSmall-35-_bmp.rf.2b42839a197103eeaef9d50c72c13584.jpg\n",
            "Moved: SizeB-7-_bmp.rf.f2bb696659f9ef566eeae63e703be719.jpg\n",
            "Moved: Strips-12-_bmp.rf.d18459ea16d9166b31c2ac12304f3cac.jpg\n",
            "Moved: ThickFlesh-4-_bmp.rf.3c30ac520c9eb8a6d55eba25fcf309eb.jpg\n",
            "Moved: Ping-6-_bmp.rf.4bbeaa58f5f90d4c8bebcbd120cfac5f.jpg\n",
            "Moved: White-13-_bmp.rf.199a881b780b85e4107e4d8d04a2517a.jpg\n",
            "Moved: SizeC-16-_bmp.rf.aeb7f575015491bfda163c1a61a6c5f2.jpg\n",
            "Moved: LightFeather-18-_bmp.rf.d40eefc65d9f8f65f3e5325ba68ff3ba.jpg\n",
            "Moved: Triangular-11-_bmp.rf.bd16d8a9857a89c9fda637ec28513744.jpg\n",
            "Moved: ThickFlesh-10-_bmp.rf.b228eac3442dc62e9006565e0b79bac4.jpg\n",
            "Moved: BrokenSmall-59-_bmp.rf.5bb2ed6cd5b31c9da4ed413e0804e0d9.jpg\n",
            "Moved: Grey-20-_bmp.rf.f2becdb2fc9627942940e01e78ef3683.jpg\n",
            "Moved: Bone-1-_bmp.rf.22cfb840bba7c59a22d23482c7c61f05.jpg\n",
            "Moved: Yellow-15-_bmp.rf.8ae85eeb6c053725d6d2fcc38aae792e.jpg\n",
            "Moved: ThickFlesh-16-_bmp.rf.a808ec232a5a655a783b2ba28f13321b.jpg\n",
            "Moved: HeavyFeather-14-_bmp.rf.83b3499affdb032684674fc3591040b3.jpg\n",
            "Moved: Grey-7-_bmp.rf.83ad1a68ee1930f7ec879e8251f321b9.jpg\n",
            "Moved: DoubleColour-2-_bmp.rf.d2c91b77871f763ca5c2acc8b59a5585.jpg\n",
            "Moved: Beige-9-_bmp.rf.a18510b73d676c4e54d4c0072a84e81b.jpg\n",
            "Moved: Bone-7-_bmp.rf.c975d3d7a0071146a7469cb44d7bb840.jpg\n",
            "Moved: Ping-15-_bmp.rf.8dac9b265f8646886ff216fc2e6499fa.jpg\n",
            "Moved: White-12-_bmp.rf.8c23028db61a9dbc2eaf516f6a960e52.jpg\n",
            "Moved: BrokenSmall-26-_bmp.rf.4618ea858d2111b6ff4f0d1ea453ef9f.jpg\n",
            "Moved: Ping-11-_bmp.rf.c8e09cbca7cdeb5946a8ef061b8cabf9.jpg\n",
            "Moved: SizeC-6-_bmp.rf.0be6abec828dc94d2a3d0b959f0e2216.jpg\n",
            "Moved: BrokenSmall-68-_bmp.rf.109d53845d01f3dc76ee591a5732ee82.jpg\n",
            "Moved: Triangular-21-_bmp.rf.ff60d9e79f6fc1fcbf476beb425b45df.jpg\n",
            "Moved: White-18-_bmp.rf.a5673774ded9b17a8c1cd4d83eddfb71.jpg\n",
            "Moved: Bone-2-_bmp.rf.835d743c698389fa8911b0d3bc215696.jpg\n",
            "Moved: Grey-12-_bmp.rf.991026983258368abe8fdc43fe3ee95f.jpg\n",
            "Moved: Grey-24-_bmp.rf.3830d795f3d8ca15edce06631601d8a8.jpg\n",
            "Moved: WhiteBeige-10-_bmp.rf.ae8ba958ced52906db30a09f63055348.jpg\n",
            "Moved: Grey-7-_bmp.rf.90ced18c8cfc53b1381cb506b84417d3.jpg\n",
            "Moved: DaYuenJiao-10-_bmp.rf.6dc2987536f4d254e98e63386296b995.jpg\n",
            "Moved: Triangular-3-_bmp.rf.f91bd0a273d694260124e986a3150319.jpg\n",
            "Moved: LightFeather-14-_bmp.rf.200640a9326ee27388dcd9f6249577c9.jpg\n",
            "Moved: WhiteBeige-14-_bmp.rf.4f42e8e078ebb055a7feb8e3a12f4e3f.jpg\n",
            "Moved: Yellow-20-_bmp.rf.3f2f8d91fffe04f0641a29c6e0c18d9c.jpg\n",
            "Moved: Grey-20-_bmp.rf.755da4ee65d32e7135760334b63f5fd2.jpg\n",
            "Moved: Beige-5-_bmp.rf.cfed1568e4233251aaef8896bcb11c6d.jpg\n",
            "Moved: Yellow-4-_bmp.rf.513431a800d3fffc9c167e3f393859b8.jpg\n",
            "Moved: DaYuenJiao-7-_bmp.rf.26f102e0ed1743d96bb787fd7f73ce51.jpg\n",
            "Moved: LightFeather-19-_bmp.rf.231f9bbf8156ef1b7ff900f28f94ce96.jpg\n",
            "Moved: BrokenBig-1-_bmp.rf.8996a83df0916ddf6ac7176bd1c441fc.jpg\n",
            "Moved: WhiteBeige-9-_bmp.rf.f1acd4a90f8a2ae7e3bba34602c6b918.jpg\n",
            "Moved: Strips-7-_bmp.rf.c63f4e0e8a8c58b2ac3940426fd475c1.jpg\n",
            "Moved: Strips-7-_bmp.rf.8af95ff1249cb805dbce0f2d127aebd4.jpg\n",
            "Moved: Triangular-8-_bmp.rf.190c6f5a4117216d1d5a1a3cb204bfab.jpg\n",
            "Moved: SizeC-12-_bmp.rf.38774cff03a2f22d256b218218836ddb.jpg\n",
            "Moved: White-17-_bmp.rf.2c0f1794696a3756649ba4143f2d47c8.jpg\n",
            "Moved: MedFeather-4-_bmp.rf.12e19f192aa5960698f251d10412511a.jpg\n",
            "Moved: Strips-1-_bmp.rf.d3d54a10233ef44219426661175ed652.jpg\n",
            "Moved: Strips-14-_bmp.rf.46a125a83e3ce0954778103c4c6ddb65.jpg\n",
            "Moved: Mossy-11-_bmp.rf.fa3768ecdce6236b9f5e584262c8a7df.jpg\n",
            "Moved: White-6-_bmp.rf.61aed7e08483b4e64e9f567640ce91d5.jpg\n",
            "Moved: Beige-2-_bmp.rf.1094d059068b4cb1ab486c439b129c5b.jpg\n",
            "Moved: Beige-6-_bmp.rf.30d201bae40307505d824b3decec1711.jpg\n",
            "Moved: MedFeather-3-_bmp.rf.2196b892a4aefd8638fb18f35e2c90f2.jpg\n",
            "Moved: BrokenBig-17-_bmp.rf.7cb2908c8101e75c3e9052e7af383134.jpg\n",
            "Moved: LightFeather-3-_bmp.rf.c8b5b3cd6b2974060277a6b6e9f80905.jpg\n",
            "Moved: Strips-5-_bmp.rf.87b78dc23918ecc47e111b4f327db6df.jpg\n",
            "Moved: SizeC-15-_bmp.rf.a2a9d32d9ee8b86f048a5e3aa75f443e.jpg\n",
            "Moved: WhiteBeige-7-_bmp.rf.baf9f0cbfce943af0c3767ca4d6ce66e.jpg\n",
            "Moved: Yellow-16-_bmp.rf.7be4c69dd690478bead9935e4ce7368a.jpg\n",
            "Moved: SizeB-2-_bmp.rf.80967b25cf3d961bef78bd9ed5f9eb51.jpg\n",
            "Moved: Mossy-2-_bmp.rf.07e3441dd2c10e9fb05c6a6cac77c66d.jpg\n",
            "Moved: Beige-13-_bmp.rf.8a274404076bf303f8deafa09b83016f.jpg\n",
            "Moved: SizeB-12-_bmp.rf.3f3193e6911936045386049f0b956aa1.jpg\n",
            "Moved: BrokenSmall-67-_bmp.rf.388b918feaf45b95738cc263b950ec08.jpg\n",
            "Moved: DoubleColour-4-_bmp.rf.770061fa611382e2b78aa8ea91746d80.jpg\n",
            "Moved: DaYuenJiao-3-_bmp.rf.46fa94c38043c3eb472442759d6e2914.jpg\n",
            "Moved: Bone-6-_bmp.rf.7f792a6f4e98b6b39d1f4788744d95b6.jpg\n",
            "Moved: LightFeather-5-_bmp.rf.3dfcb6f26ab981222354207dc8ecef2e.jpg\n",
            "Moved: Beige-11-_bmp.rf.539d709dbb4bea76a94df87a24e66058.jpg\n",
            "Moved: Grey-23-_bmp.rf.3fdc4a2fe2103b5a6d97955300acee19.jpg\n",
            "Moved: DoubleColour-10-_bmp.rf.b6469aff05608c96a30a07a27ca3b42e.jpg\n",
            "Moved: Strips-13-_bmp.rf.7f43e4ef84f155cbb9eb5fd513ce8d24.jpg\n",
            "Moved: BrokenSmall-44-_bmp.rf.3d25183cdcf6aac0f636abaef294a1a7.jpg\n",
            "Moved: BrokenBig-7-_bmp.rf.04f79e499e57854e827a01e065bed84e.jpg\n",
            "Moved: Mossy-13-_bmp.rf.1c917a056110c7d77493bbc10b14518f.jpg\n",
            "Moved: Shredded-2-_bmp.rf.6e61e9c544524b9cef0c618f78b5fb77.jpg\n",
            "Moved: Grey-4-_bmp.rf.15a36aaa256dda04a36747307ca1b146.jpg\n",
            "Moved: Triangular-16-_bmp.rf.66e11fbfdbe54501469eb16ca42c9736.jpg\n",
            "Moved: SizeC-9-_bmp.rf.a9543185a022470217469f92a3e0be47.jpg\n",
            "Moved: Triangular-19-_bmp.rf.7a50f369d8b72c168674ab6edd286b38.jpg\n",
            "Moved: Triangular-15-_bmp.rf.980440daefe1da2539a70dc11cfe634b.jpg\n",
            "Moved: WhiteBeige-11-_bmp.rf.f014cc2d852c1596d30daa4e38ac45b5.jpg\n",
            "Moved: BrokenSmall-50-_bmp.rf.84cee3429bf406f0d458d8372772c62b.jpg\n",
            "Moved: SizeA-14-_bmp.rf.b80fff0d4a7c5b445bc86d10adf9fd00.jpg\n",
            "Moved: White-15-_bmp.rf.236eccc64185b5c193203d1a69c0821e.jpg\n",
            "Moved: MedFeather-19-_bmp.rf.4b5d991abc6ce990e1d33d8cbc9babf5.jpg\n",
            "Moved: SizeA-14-_bmp.rf.8567acbc24011ec88a8d3710a68b8ec1.jpg\n",
            "Moved: SizeC-12-_bmp.rf.4f904b225b0b8d6207626185c84fcff7.jpg\n",
            "Moved: White-3-_bmp.rf.32c6b3e3113e2ce12bf15a3910a361d0.jpg\n",
            "Moved: Grey-18-_bmp.rf.78baf7b1669d83fa83db9405ccabe706.jpg\n",
            "Moved: BrokenSmall-45-_bmp.rf.9dd079cddb3c7aeb0bc04d4c35aa1b8d.jpg\n",
            "Moved: SizeA-6-_bmp.rf.1660894cf224ef7fae9ed54c1e1ae977.jpg\n",
            "Moved: BrokenSmall-55-_bmp.rf.266fa2608255bea039e699850197990f.jpg\n",
            "Moved: BrokenSmall-64-_bmp.rf.ecf896f92430f30f22248499c93d5700.jpg\n",
            "Moved: SizeB-3-_bmp.rf.3e86c1ee02efece7e30103f49ce5d6ba.jpg\n",
            "Moved: SizeB-1-_bmp.rf.138b47ab55af2023a768e13239d6cc09.jpg\n",
            "Moved: BrokenSmall-63-_bmp.rf.6d2c72e2d72d81bb3db28a95647d2f22.jpg\n",
            "Moved: DaYuenJiao-5-_bmp.rf.38ce04d04ee5ef491399d89b3c876ae1.jpg\n",
            "Moved: Grey-6-_bmp.rf.2b1eaa9ba04da6bb969f8de39980919d.jpg\n",
            "Moved: BrokenSmall-34-_bmp.rf.46b91168afddd33d01dd4a88aac4c693.jpg\n",
            "Moved: BrokenBig-1-_bmp.rf.79ceea0265eec72f55902174e83acb35.jpg\n",
            "Moved: BrokenBig-15-_bmp.rf.e265d4003a33ad5ced03862adb24d087.jpg\n",
            "Moved: SizeA-6-_bmp.rf.301fc392670f1af57d62b92a3f6cefa1.jpg\n",
            "Moved: White-2-_bmp.rf.70bac761aad39a0485282932a5856d06.jpg\n",
            "Moved: Beige-9-_bmp.rf.ebe7e39a51b11f3a6bac3d7268a16e22.jpg\n",
            "Moved: LightFeather-2-_bmp.rf.e560b0693248b308cc4f1634ba8686b9.jpg\n",
            "Moved: SizeA-2-_bmp.rf.66050863695e2f4c204e4d3e4f6396f8.jpg\n",
            "Moved: SizeB-14-_bmp.rf.7b968cff5dc7fac6a4068c24550b3357.jpg\n",
            "Moved: Strips-8-_bmp.rf.e15ec2e74ca1a1a3a943dc6ea6b9717f.jpg\n",
            "Moved: Beige-7-_bmp.rf.7776c964561cd7091aa6fd500b3e7b98.jpg\n",
            "Moved: BrokenSmall-37-_bmp.rf.b8b626c94e457fe19c7974eae490ece5.jpg\n",
            "Moved: MedFeather-6-_bmp.rf.b18b673fe5279a5f092b90ac73193db2.jpg\n",
            "Moved: Strips-15-_bmp.rf.48898f65ed64a1d214523a6ca39f9e00.jpg\n",
            "Moved: MedFeather-1-_bmp.rf.ae6e8051a1d1cea755faeb01e43daedd.jpg\n",
            "Moved: Triangular-20-_bmp.rf.496d059b30e8d51f8f38186455125c33.jpg\n",
            "Moved: DaYuenJiao-8-_bmp.rf.0f0de616c36ad536bb339954da8c3cb7.jpg\n",
            "Moved: BrokenSmall-49-_bmp.rf.ff5ea777b15fa2cf463e4659dd49bdac.jpg\n",
            "Moved: BrokenSmall-17-_bmp.rf.4075a4cafe673d9a4bb59564a6750cb7.jpg\n",
            "Moved: DaYuenJiao-2-_bmp.rf.04ad13b68bc591c537acc7113dc85172.jpg\n",
            "Moved: Beige-2-_bmp.rf.a70f325cd839b6c866ccb09baf00c012.jpg\n",
            "Moved: SizeB-1-_bmp.rf.dbe8899c6c0b9e2234525f36f28673ae.jpg\n",
            "Moved: White-9-_bmp.rf.903fd9cdbe0a42bf7187d5a933852662.jpg\n",
            "Moved: BrokenSmall-35-_bmp.rf.69e8c4c4a0be6192503e862ee946a0a0.jpg\n",
            "Moved: Strips-1-_bmp.rf.d8f5c4468b16b3ac4fc76e93a3121af8.jpg\n",
            "Moved: SizeB-7-_bmp.rf.e8179d64838c0416b944838b067fa9fb.jpg\n",
            "Moved: Bone-8-_bmp.rf.2597a47088db3f6ff0c2bf4b1658d6f4.jpg\n",
            "Moved: White-4-_bmp.rf.e9c5475e77a2d294dbb031fb77987274.jpg\n",
            "Moved: Strips-3-_bmp.rf.dc680a8a699a937ec6664160a81c4e00.jpg\n",
            "Moved: LightFeather-16-_bmp.rf.257d7812eb747f271bc5dc92fcb6264a.jpg\n",
            "Moved: MedFeather-4-_bmp.rf.fb35d0ad676ffe883049f591e1015ffe.jpg\n",
            "Moved: Strips-12-_bmp.rf.4d189469b7be280d2c22798162593aff.jpg\n",
            "Moved: White-15-_bmp.rf.4774714e6c42c2ace2f9920f9a7d92ed.jpg\n",
            "Moved: HeavyFeather-11-_bmp.rf.4da77e5c0189da33931faf38730aadcd.jpg\n",
            "Moved: White-7-_bmp.rf.f9e15859c9a0d5969c0e4f39dc6b91e0.jpg\n",
            "Moved: ThickFlesh-2-_bmp.rf.aeec9a2bf6c388f5214c9016828591ea.jpg\n",
            "Moved: SizeC-4-_bmp.rf.cbe60c660326036c51c6f1e085db70bf.jpg\n",
            "Moved: ThickFlesh-9-_bmp.rf.668b3805daefda8e4a2b2524e07dceba.jpg\n",
            "Moved: Grey-1-_bmp.rf.27ac41bb9f80e23848127b670fb2d290.jpg\n",
            "Moved: SizeA-3-_bmp.rf.fd0255d1927810b7d4123a1ffb8d679a.jpg\n",
            "Moved: Grey-19-_bmp.rf.6c545752fbd482dfee33cc915a07e2b1.jpg\n",
            "Moved: Triangular-2-_bmp.rf.735552dc51c0b08e89ec524391a88072.jpg\n",
            "Moved: HeavyFeather-4-_bmp.rf.0e73ee715ed16bac6217c0b9b918de33.jpg\n",
            "Moved: Grey-11-_bmp.rf.af71590328e989dd75d0ecacca3b3390.jpg\n",
            "Moved: Triangular-22-_bmp.rf.60fcd87fa6dd33d944fcfdc35b4139e0.jpg\n",
            "Moved: MedFeather-7-_bmp.rf.c8db16c8077ff596fb03bf9c08a4f89f.jpg\n",
            "Moved: SizeB-2-_bmp.rf.5f7b0fec2d119887db75f70d7d95c3e8.jpg\n",
            "Moved: Triangular-9-_bmp.rf.aa454221466d73d72fb7bfd934d5d0c7.jpg\n",
            "Moved: BrokenSmall-75-_bmp.rf.b0fae04ede59e348ab7085e6bd461a84.jpg\n",
            "Moved: SizeC-5-_bmp.rf.4cec3c23a5fc95bace7ffc79f124cac5.jpg\n",
            "Moved: DoubleColour-10-_bmp.rf.6737fbd6808f7fdef361548a9c4021c9.jpg\n",
            "Moved: LightFeather-16-_bmp.rf.d89b500518cff77f1161fb3f3d486443.jpg\n",
            "Moved: Strips-12-_bmp.rf.d132dd53aed6a9ed3898e0eaac21c51f.jpg\n",
            "Moved: Yellow-16-_bmp.rf.71e0e830dd63331128f80dd82e5bc829.jpg\n",
            "Moved: Bone-4-_bmp.rf.883c85bd9479bd49d8a2d267333ef3e6.jpg\n",
            "Moved: DaYuenJiao-16-_bmp.rf.76876a8f6f27f571c25a94d70d09f281.jpg\n",
            "Moved: BrokenSmall-7-_bmp.rf.775b97910b787e31cbe44dabe36defdc.jpg\n",
            "Moved: MedFeather-6-_bmp.rf.612eb36e614e06416819a0833ca1e504.jpg\n",
            "Moved: Strips-9-_bmp.rf.77945a29e35c3bea73b320dbf03d030f.jpg\n",
            "Moved: Ping-17-_bmp.rf.5b78a9916d56b1559092900a8e0a69f4.jpg\n",
            "Moved: SizeC-3-_bmp.rf.8d7c3240d47c5ff155e385ec94f6dd99.jpg\n",
            "Moved: Beige-6-_bmp.rf.38063ecc3299dd70f6d1ce51f9a4f74f.jpg\n",
            "Moved: Yellow-17-_bmp.rf.b3d55463a2313b69cfa431644df6f58b.jpg\n",
            "Moved: BrokenSmall-2-_bmp.rf.52364f598aa7db3603876ea41690fad4.jpg\n",
            "Moved: Triangular-5-_bmp.rf.0a7712e8f3d3b364ecac9eed7899aa09.jpg\n",
            "Moved: Strips-15-_bmp.rf.24870aa5bb4157a025f6533aa2ab10ac.jpg\n",
            "Moved: SizeB-6-_bmp.rf.8f5bc0144c6b7cc9db0f48cb61a8f16d.jpg\n",
            "Moved: MedFeather-9-_bmp.rf.90e9f4bfcd0b6c4a0897c598bc6492b8.jpg\n",
            "Moved: BrokenSmall-30-_bmp.rf.36d1f3f4059f26adae4a9cce86ee32ea.jpg\n",
            "Moved: DoubleColour-9-_bmp.rf.72baf0a42f60be6ff397be6874a5ea10.jpg\n",
            "Moved: MedFeather-14-_bmp.rf.880a77e8a7a4494cb416ac3b2a3afaa0.jpg\n",
            "Moved: White-8-_bmp.rf.530b11798f522a13c7e4fd465fac9f04.jpg\n",
            "Moved: White-13-_bmp.rf.8b0b6005d523ab52833f0c60810a7fe1.jpg\n",
            "Moved: BrokenSmall-51-_bmp.rf.a07934d8e8c150b6440a196432381d80.jpg\n",
            "Moved: Grey-9-_bmp.rf.9b6c3351a6f7d4b2d1bc1ca68ff9b046.jpg\n",
            "Moved: Grey-21-_bmp.rf.931f174a26668353712420a9de7cd84d.jpg\n",
            "Moved: SizeC-15-_bmp.rf.e85949424fb0b0310338858d915a387d.jpg\n",
            "Moved: White-13-_bmp.rf.7cf41cf6ccf370df3926e1f3d7313c67.jpg\n",
            "Moved: Grey-2-_bmp.rf.9cf630d3140ae661643b283ba9b56cfd.jpg\n",
            "Moved: BrokenBig-7-_bmp.rf.de798a062f72f063b9399614297c2a10.jpg\n",
            "Moved: ThickFlesh-9-_bmp.rf.6fb23a1b22b7934f55fcd864bd1a075f.jpg\n",
            "Moved: Yellow-1-_bmp.rf.f44cea02909ffde7dea641b775aea7c2.jpg\n",
            "Moved: SizeA-4-_bmp.rf.3b24a9c19be81f2e095a03b674c12f30.jpg\n",
            "Moved: WhiteBeige-10-_bmp.rf.c5c874dfc8b15fb060786b1ef071103e.jpg\n",
            "Moved: SizeC-13-_bmp.rf.b1d946c3d1c533fb9e9910a99d2e5361.jpg\n",
            "Moved: Yellow-15-_bmp.rf.c0062941091e1c02bef27674c700b5cd.jpg\n",
            "Moved: Triangular-1-_bmp.rf.e564a013f245e8a7f3b828f0533b91ee.jpg\n",
            "Moved: BrokenSmall-40-_bmp.rf.cabd7d6d8e1524167b5fe4197e4b71d8.jpg\n",
            "Moved: BrokenSmall-25-_bmp.rf.b7b36375e91706efe552e5dba16c8cf8.jpg\n",
            "Moved: Strips-10-_bmp.rf.c9c7a6eb20e33777a46c8657e429c930.jpg\n",
            "Moved: Grey-12-_bmp.rf.4e3dd02d92856a3507d5383fafc86c08.jpg\n",
            "Moved: Yellow-20-_bmp.rf.71b0ef05af38c7533cd13756e7a3fe4f.jpg\n",
            "Moved: MedFeather-19-_bmp.rf.9fe1463161753ae0b47c3b3496713a19.jpg\n",
            "Moved: Grey-3-_bmp.rf.367e86178088595f48013d1c603435e1.jpg\n",
            "Moved: BrokenSmall-38-_bmp.rf.f9e5f55e960224b104010806789677d1.jpg\n",
            "Moved: BrokenBig-3-_bmp.rf.370a1e6ae92bb88bce850e806024272f.jpg\n",
            "Moved: Strips-16-_bmp.rf.5bb12be02ba7b7455ad218a24e658ffe.jpg\n",
            "Moved: SizeC-5-_bmp.rf.e0bd591688b86a524ef2fb1da2db2691.jpg\n",
            "Moved: BrokenSmall-57-_bmp.rf.d85595c7b490ba76572606438d360297.jpg\n",
            "Moved: SizeC-5-_bmp.rf.f957a2b24bf660e46c7413354bd30062.jpg\n",
            "Moved: Triangular-18-_bmp.rf.1761e50103dc4152ee239d555ba28946.jpg\n",
            "Moved: Beige-6-_bmp.rf.411295fb4b5e5e976fb3851c9e3ff86d.jpg\n",
            "Moved: Grey-18-_bmp.rf.819e4fd364aa0b260f2c89654d38acb7.jpg\n",
            "Moved: BrokenSmall-44-_bmp.rf.8a12978a79ccad5dbd9530e2c7938c62.jpg\n",
            "Moved: White-1-_bmp.rf.c2dac6d8da35f1580cae34c7bd1f4f7e.jpg\n",
            "Moved: BrokenSmall-48-_bmp.rf.a46685d8757788f916fc2024bcf74032.jpg\n",
            "Moved: ThickFlesh-18-_bmp.rf.de92785e4f762c77c70b37ac14c6f275.jpg\n",
            "Moved: Strips-15-_bmp.rf.ef73d47dc9565c9cda20f466f603c8d9.jpg\n",
            "Moved: DaYuenJiao-16-_bmp.rf.6cc8e6edfa810286d5a87600dfae81a0.jpg\n",
            "Moved: Beige-13-_bmp.rf.5bea743df30c81a51cefdba9ab42e268.jpg\n",
            "Moved: MedFeather-17-_bmp.rf.767e0b58058c8484d3f79bf6d4a4b2b7.jpg\n",
            "Moved: Triangular-17-_bmp.rf.fad853453b9873c20ff1f66e33cae389.jpg\n",
            "Moved: Shredded-2-_bmp.rf.8b7b4c449874fa5e6fe1deb25647b31d.jpg\n",
            "Moved: Mossy-10-_bmp.rf.cc307f46b2f2f70327ac6cefd800673e.jpg\n",
            "Moved: MedFeather-15-_bmp.rf.17b454feab16e17d5dce21ee97c215e0.jpg\n",
            "Moved: MedFeather-1-_bmp.rf.a338c75c2e29b5495e47197589cac7c6.jpg\n",
            "Moved: MedFeather-9-_bmp.rf.7cabbc2d621f3e38ad834dd8f2a8d74c.jpg\n",
            "Moved: DoubleColour-2-_bmp.rf.af8224df451f60403b13931bdf93f05b.jpg\n",
            "Moved: BrokenSmall-46-_bmp.rf.d04df1397677d940ce9889949ae80ebe.jpg\n",
            "Moved: Mossy-4-_bmp.rf.57bc698b66045999999985f61ec12382.jpg\n",
            "Moved: Bone-10-_bmp.rf.572ce577bb2d1beacaea1c31346bf7bf.jpg\n",
            "Moved: LightFeather-8-_bmp.rf.6aadfc6b2210137c20441a02eb10eb35.jpg\n",
            "Moved: Ping-14-_bmp.rf.8dc055ec5e5011da7c1b4d18bf386199.jpg\n",
            "Moved: White-11-_bmp.rf.15102b1d6be513252e34386a5dc185a2.jpg\n",
            "Moved: DaYuenJiao-5-_bmp.rf.f9c43a2a45df449791632fbd1b95a259.jpg\n",
            "Moved: HeavyFeather-13-_bmp.rf.9b31a11fda49010d021b10740e7950e1.jpg\n",
            "Moved: HeavyFeather-8-_bmp.rf.4f2abb8f5d67692d42e2536d7dbe472e.jpg\n",
            "Moved: Mossy-16-_bmp.rf.75071f5d5f684f18b96667575c6aef55.jpg\n",
            "Moved: SizeB-5-_bmp.rf.9bca5ff166bde57e06ca8b7525972957.jpg\n",
            "Moved: Triangular-19-_bmp.rf.8307f30e114a539a323d24b6d0b8a267.jpg\n",
            "Moved: SizeC-3-_bmp.rf.21bbdc7879158ad8d95500063a398059.jpg\n",
            "Moved: Strips-16-_bmp.rf.b52f5fb7236490fda5ff1c0e036483ee.jpg\n",
            "Moved: Triangular-18-_bmp.rf.45838a976bebdee54f9a0ec2febcf369.jpg\n",
            "Moved: WhiteBeige-17-_bmp.rf.a9c073437557e58bebe50e887c566b98.jpg\n",
            "Moved: BrokenSmall-68-_bmp.rf.3c2e8d6c3d05a3c8a3feacf9c1e634c4.jpg\n",
            "Moved: White-16-_bmp.rf.c61af0332df60ab40f2845cc6f692b9c.jpg\n",
            "Moved: Yellow-17-_bmp.rf.9395aa30a694d10db192d4bababaff84.jpg\n",
            "Moved: HeavyFeather-15-_bmp.rf.5a89a8cfc867229853555c63aa8cd5f4.jpg\n",
            "Moved: SizeB-15-_bmp.rf.01ad6e5eedb27d6f6f2518178ff9dea7.jpg\n",
            "Moved: White-12-_bmp.rf.3b3f61496d6e14c017f9159c7d31cff8.jpg\n",
            "Moved: Triangular-21-_bmp.rf.4509a0e1d86573dfb1e7990080133e2d.jpg\n",
            "Moved: Ping-14-_bmp.rf.581cdc0ff8bec355713dd88cfd5b6c51.jpg\n",
            "Moved: BrokenSmall-24-_bmp.rf.d4fbb5c5a33cd45810028f1f4a49d3ef.jpg\n",
            "Moved: Triangular-15-_bmp.rf.44bdaf5c684fa627b81910f38351dd3f.jpg\n",
            "Moved: Triangular-5-_bmp.rf.40a713b9ed4b725114fa6ee80d8feac9.jpg\n",
            "Moved: SizeA-11-_bmp.rf.76b0b54f47a566ad5c14edf12607a038.jpg\n",
            "Moved: Strips-14-_bmp.rf.ff265c59e389501b67e7d43a70728340.jpg\n",
            "Moved: BrokenSmall-48-_bmp.rf.d47988d2d4622abe01961b04f4634cdb.jpg\n",
            "Moved: Ping-16-_bmp.rf.2af772ce913f5cba58321929468fa21f.jpg\n",
            "Moved: BrokenSmall-39-_bmp.rf.6d6c3d7d43d258248dee878f32abcabd.jpg\n",
            "Moved: Ping-5-_bmp.rf.b8468d24b3f957e41624869d2ce1e88d.jpg\n",
            "Moved: Triangular-11-_bmp.rf.2b8c2832d856fd860fe3c5522dc94633.jpg\n",
            "Moved: BrokenSmall-27-_bmp.rf.c1a1a743aec13d7fbfa00b29cd93850a.jpg\n",
            "Moved: SizeC-14-_bmp.rf.5166c92a9820240808482a93392b8937.jpg\n",
            "Moved: DaYuenJiao-10-_bmp.rf.b5f4411d76aec339a57f0b6a77970ae1.jpg\n",
            "Moved: Grey-23-_bmp.rf.eb7b2a496c02c5b1d04a68e6b5ee6675.jpg\n",
            "Moved: Triangular-6-_bmp.rf.de52bc7b2091992c12cd6e9fdf87e041.jpg\n",
            "Moved: Triangular-17-_bmp.rf.a9d66a5bab3e47664a6b52624a22c07f.jpg\n",
            "Moved: BrokenBig-13-_bmp.rf.131c047c967c811c51c3b17ee545bdfc.jpg\n",
            "Moved: HeavyFeather-12-_bmp.rf.203fc1d839d6a49f2d037379ab81fe10.jpg\n",
            "Moved: Grey-20-_bmp.rf.f41efbd7fc598d1a7b05c25661f44917.jpg\n",
            "Moved: Bone-13-_bmp.rf.2da88bfb18d0629b4d04a274016551a8.jpg\n",
            "Moved: BrokenSmall-17-_bmp.rf.772fae68656d681e81cd7be855f3e5ad.jpg\n",
            "Moved: BrokenSmall-35-_bmp.rf.e47acebe0967fde9103502adc36bc220.jpg\n",
            "Moved: Grey-3-_bmp.rf.57a4bfb5ddfcc72c7f1a48ee0907c6a5.jpg\n",
            "Moved: Beige-7-_bmp.rf.ca52c6bc86aff7bcfcaccf762b079b37.jpg\n",
            "Moved: DaYuenJiao-8-_bmp.rf.d10b427dcf263b17adc76b3070bb212a.jpg\n",
            "Moved: Beige-1-_bmp.rf.f5c501ea0593863c5a14f3a92d85f919.jpg\n",
            "Moved: Yellow-10-_bmp.rf.cfc2da2dbcb91e45e5e79d47f91dd9e3.jpg\n",
            "Moved: HeavyFeather-10-_bmp.rf.60f06691dfd59123540c138bfa8d1fb5.jpg\n",
            "Moved: SizeC-17-_bmp.rf.d840ce6f24ad5d37296b71c4fd929add.jpg\n",
            "Moved: Ping-3-_bmp.rf.c6b8843ca0ceaa0d4e354609d63f946e.jpg\n",
            "Moved: BrokenSmall-38-_bmp.rf.42d9bda462f330bfcb08c553514976cf.jpg\n",
            "Moved: Triangular-3-_bmp.rf.14e4e30d87beb6131a266b1dce46af32.jpg\n",
            "Moved: SizeA-7-_bmp.rf.16dda06f3c05aa68e6c017ff8f8cb099.jpg\n",
            "Moved: Beige-13-_bmp.rf.2e7b74e18f4e3e4f2dd2dc5c614b1cd5.jpg\n",
            "Moved: SizeB-8-_bmp.rf.70e94c7fc0234630274d1b649949b0eb.jpg\n",
            "Moved: Yellow-19-_bmp.rf.657bc072bf33500b16a181a35f24bcf1.jpg\n",
            "Moved: Beige-1-_bmp.rf.404140e41a1c8765410d12443985e5c1.jpg\n",
            "Moved: BrokenSmall-56-_bmp.rf.9be916186a9abb358cc6093c58452850.jpg\n",
            "Moved: Mossy-16-_bmp.rf.eff2c9d6c6a8a82ca92d3c411ac82af6.jpg\n",
            "Moved: BrokenSmall-20-_bmp.rf.56e871546ebd17a96c431119aa6eef4b.jpg\n",
            "Moved: HeavyFeather-14-_bmp.rf.f900e4f016aa98994a06086594140f43.jpg\n",
            "Moved: Bone-2-_bmp.rf.ad5d48cc10c8eb5d0a2563e4c6c96c5f.jpg\n",
            "Moved: BrokenSmall-8-_bmp.rf.48d5a47abd9288a981ccbd9b71553f35.jpg\n",
            "Moved: BrokenSmall-61-_bmp.rf.af181e4d03b483055be9e64fc73f4eb8.jpg\n",
            "Moved: DoubleColour-2-_bmp.rf.07fa1dd486ac74b38960e5e3ad74b537.jpg\n",
            "Moved: Mossy-15-_bmp.rf.769a12f27a521a138e5b1f671faf5ddc.jpg\n",
            "Moved: Yellow-13-_bmp.rf.0b25606dd47dffb17390ab22be06bc72.jpg\n",
            "Moved: BrokenSmall-22-_bmp.rf.4230e54e982db2f467bd88000d0755c7.jpg\n",
            "Moved: Grey-1-_bmp.rf.c7ed245cf13fff704f7bac941015d62d.jpg\n",
            "Moved: WhiteBeige-8-_bmp.rf.0a0baf8575c3474ebc1ad0232050bba1.jpg\n",
            "Moved: SizeA-4-_bmp.rf.6e0312a7d7a1aa6201ca61f977e6ff6b.jpg\n",
            "Moved: Beige-10-_bmp.rf.94e2dee505ad1154510b0a62a36a1043.jpg\n",
            "Moved: BrokenSmall-65-_bmp.rf.9c56583afaf593a0d512548d391fd7f1.jpg\n",
            "Moved: SizeC-18-_bmp.rf.c40406a29817344e4a98ce7b1a08bac2.jpg\n",
            "Moved: Strips-4-_bmp.rf.92e90f6d7f40777267cac5c278b350ce.jpg\n",
            "Moved: ThickFlesh-18-_bmp.rf.affd4a8f6bf278cb3fcd5fccb70dcfc9.jpg\n",
            "Moved: Grey-23-_bmp.rf.8430215fd410b85a864f2a5c4ad2ac4b.jpg\n",
            "Moved: Ping-9-_bmp.rf.3631bd7c6975b37172c015a9b38548e1.jpg\n",
            "Moved: LightFeather-3-_bmp.rf.3f8924cded171b2b5b5c3ef2c0fa5b81.jpg\n",
            "Moved: MedFeather-3-_bmp.rf.d8285a686d10b910523b1d243063bd1f.jpg\n",
            "Moved: WhiteBeige-2-_bmp.rf.88d059d7a6dbeef1b979352fb579b1f2.jpg\n",
            "Moved: MedFeather-16-_bmp.rf.d7534864527c64869d6985bf5a774a9a.jpg\n",
            "Moved: Beige-7-_bmp.rf.469b5cb253ab7537d3ffcc513debb857.jpg\n",
            "Moved: DaYuenJiao-8-_bmp.rf.cc89ea6d31319e53c78d00a180ee872d.jpg\n",
            "Moved: BrokenSmall-9-_bmp.rf.843852563b291412b90957939a72eebc.jpg\n",
            "Moved: ThickFlesh-10-_bmp.rf.3d30850640af56501356d50bfba66e80.jpg\n",
            "Moved: SizeB-10-_bmp.rf.a6249996d6ed7471d891d17841fe9a68.jpg\n",
            "Moved: BrokenSmall-54-_bmp.rf.7fde73423c03a561a0674788428cfa06.jpg\n",
            "Moved: DoubleColour-13-_bmp.rf.4961b0e8b5e458f85a734062151db36e.jpg\n",
            "Moved: Grey-24-_bmp.rf.15610a010ec771f3841ca925ff7e7c80.jpg\n",
            "Moved: WhiteBeige-13-_bmp.rf.9b5ad845de37c3f34a51edb1d8070847.jpg\n",
            "Moved: HeavyFeather-2-_bmp.rf.41baf238397913bf62501f8fc2970388.jpg\n",
            "Moved: SizeA-8-_bmp.rf.9692ad7f00c364dcf947088b43aea3d0.jpg\n",
            "Moved: Triangular-10-_bmp.rf.28dfbdb514b749691742f402e0a5c63c.jpg\n",
            "Moved: WhiteBeige-5-_bmp.rf.df58465d06c65eaf13e1904c74dc7d55.jpg\n",
            "Moved: BrokenBig-8-_bmp.rf.6dbcf25c5145bce9f0a072cf578c9bba.jpg\n",
            "Moved: BrokenSmall-18-_bmp.rf.59f6a910b2aad71c3eb4e50bf0bb6ff7.jpg\n",
            "Moved: BrokenSmall-21-_bmp.rf.a45c3e68f054e8fe6ba14b4ff73cf5ac.jpg\n",
            "Moved: ThickFlesh-16-_bmp.rf.6a2e04459dcaee5a448e89066e761307.jpg\n",
            "Moved: BrokenSmall-52-_bmp.rf.3175db9fd5b372d3171364cf85839afa.jpg\n",
            "Moved: Strips-17-_bmp.rf.553e4be7ecfb57bae268c55f644b3aa3.jpg\n",
            "Moved: DaYuenJiao-2-_bmp.rf.f4e56774181b673eca6cd3bba146b323.jpg\n",
            "Moved: Triangular-24-_bmp.rf.461d8badfba7e886b7274f6dcdddcb56.jpg\n",
            "Moved: BrokenSmall-39-_bmp.rf.c831e95af472c74100ab5d8aad34c531.jpg\n",
            "Moved: White-16-_bmp.rf.7062b7d6596fc469481dbf2ff9eb5ce9.jpg\n",
            "Moved: SizeB-3-_bmp.rf.f2279232ad3c39b3c49d2c4075a875d1.jpg\n",
            "Moved: LightFeather-10-_bmp.rf.19abd838a337834330d71262e41923d6.jpg\n",
            "Moved: White-18-_bmp.rf.615fd2f7b7b62270d3a638213ba428a2.jpg\n",
            "Moved: BrokenSmall-14-_bmp.rf.a0d3a01c518df77e5babfb723b31d4e3.jpg\n",
            "Moved: Mossy-13-_bmp.rf.df5c3bc5042acc6c2497904cf203220a.jpg\n",
            "Moved: Shredded-2-_bmp.rf.d83a0d7ab27d55e6fe72f6d2fca74d0c.jpg\n",
            "Moved: SizeA-10-_bmp.rf.1e999815206c3611ddb0f8e3c6c30d4a.jpg\n",
            "Moved: ThickFlesh-12-_bmp.rf.7ede9ed0bd29b0d18404acec1d91b2b4.jpg\n",
            "Moved: BrokenSmall-18-_bmp.rf.55116d550eaad2fd278e141d7674b937.jpg\n",
            "Moved: Beige-3-_bmp.rf.5d9da0f3640c2131809716d44e96aa3e.jpg\n",
            "Moved: Grey-15-_bmp.rf.2f8d12368197f2477305e6b6a2f3c628.jpg\n",
            "Moved: Triangular-17-_bmp.rf.e77d6ca37fd0c1a862bb9c571f4fccbe.jpg\n",
            "Moved: Grey-21-_bmp.rf.a5f8ffde0fda098de4af98257de77399.jpg\n",
            "Moved: BrokenSmall-76-_bmp.rf.211639959325061785b2d294039cd791.jpg\n",
            "Moved: DoubleColour-12-_bmp.rf.e11a24eca307be5dc99584524a7295ed.jpg\n",
            "Moved: WhiteBeige-14-_bmp.rf.799b4972ce2981db201fd3ebfce70354.jpg\n",
            "Moved: HeavyFeather-17-_bmp.rf.690bb11162a2fb0bc9cd86f1e555fe6d.jpg\n",
            "Moved: BrokenSmall-41-_bmp.rf.7b24ceee539baea724beea0783135e16.jpg\n",
            "Moved: Mossy-9-_bmp.rf.28ae0715553d54212a3deee8c4870614.jpg\n",
            "Moved: Ping-15-_bmp.rf.dd0e33c9cc51db7eac9fcfe287d46775.jpg\n",
            "Moved: BrokenSmall-46-_bmp.rf.36020de4f7799023a3d9c027930ec621.jpg\n",
            "Moved: BrokenSmall-70-_bmp.rf.fb38d0f8915eff4926cc7d93fcbde095.jpg\n",
            "Moved: White-8-_bmp.rf.7495195c76f8b6a2b864c1b5baac0d63.jpg\n",
            "Moved: DoubleColour-12-_bmp.rf.efad00765a07cbe847fde5859032a340.jpg\n",
            "Moved: Bone-1-_bmp.rf.50b72a9dcd7ac6b26bb1e7a7ebc93592.jpg\n",
            "Moved: BrokenSmall-40-_bmp.rf.f461dd8c907e9ae888d8e66a97cc7653.jpg\n",
            "Moved: Grey-4-_bmp.rf.c2f2a00e2ca9438792967e37adf39d09.jpg\n",
            "Moved: Ping-9-_bmp.rf.e94ce59e03553db75eb0c91fe2f05524.jpg\n",
            "Moved: BrokenSmall-49-_bmp.rf.d26efc7f4b36fd47f9ac32bf555c2535.jpg\n",
            "Moved: BrokenSmall-62-_bmp.rf.061cfae31fef3bf47a0a619de511c7a9.jpg\n",
            "Moved: Ping-17-_bmp.rf.2ddaf18ee7c82398f550e077895e81b0.jpg\n",
            "Moved: SizeA-8-_bmp.rf.05440d48c2c9138da64c775aa95758a0.jpg\n",
            "Moved: SizeC-11-_bmp.rf.89201291c532d98cd9dae0609f85825e.jpg\n",
            "Moved: Ping-13-_bmp.rf.61dd7d5d25f855530c221a8762d95ba1.jpg\n",
            "Moved: Grey-15-_bmp.rf.a77290b97e2611d3c34080bfadfd8910.jpg\n",
            "Moved: Grey-6-_bmp.rf.625661992f0606c9297072ea95cc9e12.jpg\n",
            "Moved: SizeA-9-_bmp.rf.9ac6b27df0cbc2d0f08afe8650cc687c.jpg\n",
            "Moved: HeavyFeather-12-_bmp.rf.5b2d88bca06b1ee497d6e3ce24ad29e7.jpg\n",
            "Moved: LightFeather-8-_bmp.rf.b4cf20e94dc2a84f52f3cab9ccf74d3f.jpg\n",
            "Moved: BrokenSmall-14-_bmp.rf.b8da72425478cf6737d47b91aebca6ec.jpg\n",
            "Moved: DoubleColour-15-_bmp.rf.c035b615de7dc53db0703737012bf7e4.jpg\n",
            "Moved: Bone-7-_bmp.rf.4d7d3057dd40109df7c4418dabc98282.jpg\n",
            "Moved: SizeA-12-_bmp.rf.598f8e5c675163698a0674176401a95c.jpg\n",
            "Moved: LightFeather-7-_bmp.rf.bf6931daf864125216039b59bd123dbd.jpg\n",
            "Moved: BrokenSmall-24-_bmp.rf.db27d01e339c8ea32e17c70853bdba27.jpg\n",
            "Moved: SizeC-16-_bmp.rf.626955446bf7a7ac5d3716b7ebfad6ee.jpg\n",
            "Moved: Yellow-6-_bmp.rf.b514c261797660fc55166b378c96dddb.jpg\n",
            "Moved: Grey-21-_bmp.rf.626b39f5ffc068472a34e7a0d00f5037.jpg\n",
            "Moved: BrokenSmall-24-_bmp.rf.c3813b7906075bb0add786d66e20c728.jpg\n",
            "Moved: BrokenSmall-56-_bmp.rf.7cd6234f27024f8559a03b0fb3c4c3e7.jpg\n",
            "Moved: Bone-4-_bmp.rf.cc3087b5dae22f8b32a0a1a5e4d753ab.jpg\n",
            "Moved: SizeA-7-_bmp.rf.dabdab0aaa1f1b8e905b2e086b7de7f7.jpg\n",
            "Moved: BrokenBig-10-_bmp.rf.889d5780aa1c7e6ed1c837a23f7bd76a.jpg\n",
            "Moved: Yellow-10-_bmp.rf.41c0b571979a5fcd10082aaa70e496de.jpg\n",
            "Moved: BrokenBig-12-_bmp.rf.fa7bc654c4f6b70065d354c9cf75d520.jpg\n",
            "Moved: MedFeather-11-_bmp.rf.80ab10c5b966a2f20e0ad133decf0542.jpg\n",
            "Moved: SizeB-9-_bmp.rf.5633c87216420efb0875457b6bb0043b.jpg\n",
            "Moved: BrokenSmall-38-_bmp.rf.e57a6d6a9f74498908b7d3a9f8b476f0.jpg\n",
            "Moved: SizeA-1-_bmp.rf.57f5790d3b44c85616108efa4e1d2262.jpg\n",
            "Moved: Yellow-3-_bmp.rf.a1121774bb8d2c7cc8d82aad288a8758.jpg\n",
            "Moved: Yellow-1-_bmp.rf.eff6f029498417b195d3a4bea22fde1d.jpg\n",
            "Moved: Bone-3-_bmp.rf.7983bff7c47618fea90d07eff4e1611a.jpg\n",
            "Moved: HeavyFeather-2-_bmp.rf.142f1eb0cbd7ea0ca8b22a5f2db3d2a1.jpg\n",
            "Moved: Mossy-5-_bmp.rf.40cc137337e4f41982fcf87a1cc36c9f.jpg\n",
            "Moved: BrokenBig-16-_bmp.rf.79dfca8465cc8cdf9a0fc230a00d0bb0.jpg\n",
            "Moved: WhiteBeige-10-_bmp.rf.8611e8ba2319c50bb55ec8764e4dd4a2.jpg\n",
            "Moved: _annotations.csv\n",
            "Moved: BrokenSmall-20-_bmp.rf.c2363d6c8476c335b58d10ee189c6504.jpg\n",
            "Moved: MedFeather-14-_bmp.rf.c339265f149b50738256a4d54ab552ab.jpg\n",
            "Moved: Ping-16-_bmp.rf.b1f9a2373811bca31681597b81b0bb11.jpg\n",
            "Moved: Grey-3-_bmp.rf.c1e43e526115f04c1b0a1e7928767564.jpg\n",
            "Moved: White-9-_bmp.rf.a7bb5a60bdb7fe6a6760b4cffe86efe5.jpg\n",
            "Moved: BrokenSmall-13-_bmp.rf.35a49bcab3e58c23e648b37590cdc1df.jpg\n",
            "Moved: BrokenSmall-13-_bmp.rf.8742ca2bcb74e6ac12d06d95e654b7c5.jpg\n",
            "Moved: MedFeather-20-_bmp.rf.946351f1097c7266e15acfe9bd469116.jpg\n",
            "Moved: DoubleColour-14-_bmp.rf.54b8dd785bff6b2335924137a140b834.jpg\n",
            "Moved: Bone-10-_bmp.rf.c4b38aca82f9ae37f25ffb9f15bacdc7.jpg\n",
            "Moved: BrokenBig-10-_bmp.rf.ef88d525190b8628c0f529730854975d.jpg\n",
            "Moved: BrokenSmall-69-_bmp.rf.8d2e44307819869be04b241dd33d93a8.jpg\n",
            "Moved: Yellow-3-_bmp.rf.7de88a91ce4a89dec08fa028dc126319.jpg\n",
            "Moved: Triangular-10-_bmp.rf.1d94064fce46d64bf1547d8096ae5eff.jpg\n",
            "Moved: Beige-2-_bmp.rf.78cf247cba98e943f6c3c89220777952.jpg\n",
            "Moved: ThickFlesh-9-_bmp.rf.718060badaafeb1d5a141ecc15d938a2.jpg\n",
            "Moved: BrokenBig-5-_bmp.rf.cf771decc90320877077d4f9dee8a683.jpg\n",
            "Moved: SizeC-1-_bmp.rf.ccda21d031ac72cbe5281dc5b1c0053d.jpg\n",
            "Moved: Yellow-3-_bmp.rf.12c3d17a504af3920addb79bc81452ba.jpg\n",
            "Moved: BrokenSmall-64-_bmp.rf.ca5c24075c5e328f83fde23b3b1999ef.jpg\n",
            "Moved: SizeC-2-_bmp.rf.144f66381a4534e25aeafd6c683d36f4.jpg\n",
            "Moved: Grey-9-_bmp.rf.9a956ad8aedda1d74f2c97991fa57334.jpg\n",
            "Moved: BrokenSmall-52-_bmp.rf.e547fdf252e04beee4034e17571be2db.jpg\n",
            "Moved: BrokenSmall-62-_bmp.rf.074fb85e1f7fea790c44ee30384cb877.jpg\n",
            "Moved: ThickFlesh-15-_bmp.rf.b59d610aadf94c52e20bf3989d3d3f66.jpg\n",
            "Moved: DaYuenJiao-15-_bmp.rf.b59d17de9d3fb9e3a00045d35a7687a9.jpg\n",
            "Moved: White-11-_bmp.rf.e9e6753d819a326b8e1f5ad8a79cfa41.jpg\n",
            "Moved: SizeA-13-_bmp.rf.baa8652d4e8b955c0862148626dcb1f1.jpg\n",
            "Moved: Triangular-16-_bmp.rf.e18bfc1886c00f27e08073b3e037712e.jpg\n",
            "Moved: LightFeather-9-_bmp.rf.0958a18cc98c2c3202b718b5310f7d3b.jpg\n",
            "Moved: SizeA-2-_bmp.rf.53222d9d648d1666f6ddbd99756c6f09.jpg\n",
            "Moved: LightFeather-18-_bmp.rf.f31b04b822ebf86fda6a6eab0e27cbaf.jpg\n",
            "Moved: Mossy-6-_bmp.rf.b248fc680c17c703cb3d1b69f1bde7eb.jpg\n",
            "Moved: DoubleColour-4-_bmp.rf.5eadf0f2c409b11498d207bc833f6fd6.jpg\n",
            "Moved: DaYuenJiao-1-_bmp.rf.00f123e81d90e4ad70f1f46ac8684a29.jpg\n",
            "Moved: Beige-10-_bmp.rf.febc64c0354f5205ea73287dcdec74f1.jpg\n",
            "Moved: Ping-13-_bmp.rf.3964c376da9fbfc507ceb0126dc1ce0d.jpg\n",
            "Moved: Triangular-20-_bmp.rf.6ca0d11c334b34a18e12ad2c7c4392f6.jpg\n",
            "Moved: Ping-13-_bmp.rf.2efc6ace75f7e92a8b8b241d0da43e48.jpg\n",
            "Moved: WhiteBeige-9-_bmp.rf.bfab449a7c50385fe74c4f732323a4ee.jpg\n",
            "Moved: BrokenBig-15-_bmp.rf.cbbf83afead45b1ff81f2629801be5b7.jpg\n",
            "Moved: MedFeather-11-_bmp.rf.3d3fb269e0369cb03d0f376d8925ab04.jpg\n",
            "Moved: BrokenSmall-11-_bmp.rf.4c346727bd427c5e4b9cdaf53e85bca4.jpg\n",
            "Moved: BrokenSmall-69-_bmp.rf.7c6fa49695293faa202be8c73ef7327b.jpg\n",
            "Moved: WhiteBeige-5-_bmp.rf.56f7b40b93cee11a05be06670a07c40f.jpg\n",
            "Moved: BrokenSmall-62-_bmp.rf.cfe2df6eb85a28e0244f979f71d508c2.jpg\n",
            "Moved: Grey-12-_bmp.rf.8ea0c7c9d5601e41a76d80088ef30641.jpg\n",
            "Moved: DaYuenJiao-3-_bmp.rf.89848a6382edcc41d6697139b1a5b0b3.jpg\n",
            "Moved: DaYuenJiao-9-_bmp.rf.7e8eee272e43c0d428c19c813b57e7a9.jpg\n",
            "Moved: Mossy-8-_bmp.rf.2ae982d733dce3869fb55b6248d5285e.jpg\n",
            "Moved: BrokenBig-1-_bmp.rf.8f12b0d781ebf39341b7800f5381a486.jpg\n",
            "Moved: BrokenSmall-9-_bmp.rf.797ce768bfc0ec84cd1e2191343492b3.jpg\n",
            "Moved: SizeA-1-_bmp.rf.35e7210fc3640a9349cc33e4e06ff438.jpg\n",
            "Moved: BrokenSmall-44-_bmp.rf.9beb31083862fad4e181f67a92fee54e.jpg\n",
            "Moved: HeavyFeather-17-_bmp.rf.1a1613e8b99b69d87c663f9630f3746b.jpg\n",
            "Moved: DoubleColour-3-_bmp.rf.3f341efc80910e4b6353a3335600abf2.jpg\n",
            "Moved: DaYuenJiao-9-_bmp.rf.b7ae75d90034773245d196b25769412d.jpg\n",
            "Moved: Strips-8-_bmp.rf.85f23fb5a81c2ec8d4c92aadfff31436.jpg\n",
            "Moved: ThickFlesh-4-_bmp.rf.4d2fae5a383b88eb68764389e738aab0.jpg\n",
            "Moved: HeavyFeather-8-_bmp.rf.a8d2e86d73e0ee868d79c7270c74bdf9.jpg\n",
            "Moved: HeavyFeather-4-_bmp.rf.bd79a740ccdd48f2afb3812ebba9a5a6.jpg\n",
            "Moved: HeavyFeather-6-_bmp.rf.7db2bde374b4a811fbc309a3e51aca28.jpg\n",
            "Moved: BrokenSmall-76-_bmp.rf.f797148609c8961cc9a2f739a9b37b38.jpg\n",
            "Moved: BrokenSmall-22-_bmp.rf.89f4c91e22f22134f402ba22fd44b581.jpg\n",
            "Moved: Grey-18-_bmp.rf.3ca6c515a814910725b179f28c60b9cd.jpg\n",
            "Moved: BrokenSmall-66-_bmp.rf.2aa6d7a3a8a1681adc2a01bf4b3f8107.jpg\n",
            "Moved: Beige-1-_bmp.rf.1df5c1329ccc1afe51ba1c345dff8535.jpg\n",
            "Moved: BrokenSmall-21-_bmp.rf.5ae86e2ec944185add9c3453a73e0bf4.jpg\n",
            "Moved: ThickFlesh-8-_bmp.rf.11417557aaac4e9c7d0039d3fe2450c6.jpg\n",
            "Moved: BrokenBig-15-_bmp.rf.74477f9b9b1e3c1dad8c082f4f8134df.jpg\n",
            "Moved: Grey-2-_bmp.rf.75643819a80357d10b500e7551861345.jpg\n",
            "Moved: BrokenSmall-9-_bmp.rf.040ff164f83bf8e84f07ef1755240869.jpg\n",
            "Moved: Yellow-17-_bmp.rf.b732b98b326ca27593da12a595c7341c.jpg\n",
            "Moved: SizeC-13-_bmp.rf.af4b43e37ae7aff3ef6d402466ca0fda.jpg\n",
            "Moved: DoubleColour-15-_bmp.rf.e29d0a5c9f006773a85dedd60f9751c9.jpg\n",
            "Moved: MedFeather-11-_bmp.rf.3b42fd83d2f200db44464f95899e7f54.jpg\n",
            "Moved: BrokenSmall-54-_bmp.rf.349c731e3ca3d81d3d019c17a9b8e324.jpg\n",
            "Moved: Mossy-9-_bmp.rf.c072433e681279ededeb3a3349fa3906.jpg\n",
            "Moved: BrokenBig-10-_bmp.rf.ed872c62e99bf3826348038ffad51db2.jpg\n",
            "Moved: BrokenBig-17-_bmp.rf.3bc118de1cf70c93d06b8843b2baf935.jpg\n",
            "Moved: MedFeather-9-_bmp.rf.d1ea8146c9c0ff1fc6995374ccd99118.jpg\n",
            "Moved: Strips-10-_bmp.rf.271a17e83c8a6434d08c2f51e3887043.jpg\n",
            "Moved: LightFeather-17-_bmp.rf.a4ea1082e45c64fcb905a286f56422c1.jpg\n",
            "Moved: BrokenSmall-51-_bmp.rf.3f1839a973d0268ab6b9b501a0354da2.jpg\n",
            "Moved: BrokenSmall-45-_bmp.rf.b718e3a70db2ea6497ebe8194a3b2832.jpg\n",
            "Moved: Grey-11-_bmp.rf.13af4068813b23a166ced9dd216a51e9.jpg\n",
            "Moved: BrokenSmall-63-_bmp.rf.c97977d5d382ae7ade1a39fa6c91e738.jpg\n",
            "Moved: BrokenBig-2-_bmp.rf.ba401d75a052926a924117ef83f04bed.jpg\n",
            "Moved: BrokenBig-16-_bmp.rf.1c8d6483267f4751dc6b3ada8316a9f0.jpg\n",
            "Moved: BrokenSmall-29-_bmp.rf.ccb24b71182ced51971baa15d271c9a3.jpg\n",
            "Moved: Beige-2-_bmp.rf.65e48d8cdb31455d5ee2bbef095787d6.jpg\n",
            "Moved: LightFeather-14-_bmp.rf.9c47f918200f36559c67357dd83fdc59.jpg\n",
            "Moved: HeavyFeather-14-_bmp.rf.e45834beac05c75b6004b9d0f686a90f.jpg\n",
            "Moved: BrokenSmall-61-_bmp.rf.1377c5797e979c9b3e8ce1b98da06abb.jpg\n",
            "Moved: Beige-1-_bmp.rf.1c9dfe94b2a5830d3f025aa1669712c1.jpg\n",
            "Moved: WhiteBeige-7-_bmp.rf.919be83f62dd8232fbf8a6a09b892d2b.jpg\n",
            "Moved: SizeB-2-_bmp.rf.f0038a0c3f7b6aea3cb7ce1beee03772.jpg\n",
            "Moved: LightFeather-5-_bmp.rf.a2571fa273c7e6b8611b5b929a7a722f.jpg\n",
            "Moved: White-4-_bmp.rf.d95cef27ab932954772e341a02aafa18.jpg\n",
            "Moved: DaYuenJiao-15-_bmp.rf.e41ec60432ea1cad8b47a3aac00c64fd.jpg\n",
            "Moved: BrokenSmall-43-_bmp.rf.3cb359d2a3d7e400d425b8ce07d83cfd.jpg\n",
            "Moved: Bone-9-_bmp.rf.49f73525853783c55dd87bbaa946afe2.jpg\n",
            "Moved: SizeA-13-_bmp.rf.236c74c3f8f34835cbc96cce915805eb.jpg\n",
            "Moved: SizeA-2-_bmp.rf.7f6839f4e7dbacb4d6affd0ad62acaf5.jpg\n",
            "Moved: DaYuenJiao-7-_bmp.rf.418954f33481e94bf4ac7312fee07be4.jpg\n",
            "Moved: Strips-7-_bmp.rf.6b8321504c3a6b6fe8c355fb091b0e35.jpg\n",
            "Moved: WhiteBeige-14-_bmp.rf.895d9753b3858582efa2c5681d46e6fc.jpg\n",
            "Moved: MedFeather-13-_bmp.rf.e4ecf158cc62b3170ccf775f4fc4f673.jpg\n",
            "Moved: Strips-18-_bmp.rf.42a5b59fce95cf6ff422c0df27001e45.jpg\n",
            "Moved: WhiteBeige-3-_bmp.rf.95fec40884332e4a93f07c341aca38e0.jpg\n",
            "Moved: BrokenSmall-73-_bmp.rf.667c80708546f933b8172283206af3a6.jpg\n",
            "Moved: Mossy-2-_bmp.rf.9ff03b0dd244531d612f83818f685436.jpg\n",
            "Moved: White-1-_bmp.rf.c422f088d38088def97730da3d5b3ba3.jpg\n",
            "Moved: BrokenSmall-14-_bmp.rf.fc33447748b4cfa20dd3896a155c535a.jpg\n",
            "Moved: BrokenSmall-32-_bmp.rf.4ed23c96aed3e2e9a1f35f812304d82c.jpg\n",
            "Moved: Grey-1-_bmp.rf.9d5c63d485d5ffe6a2e7bb69fae02fe5.jpg\n",
            "Moved: BrokenBig-9-_bmp.rf.115d08742dc865261bfdabb59d721f3a.jpg\n",
            "Moved: MedFeather-19-_bmp.rf.5ab1621207a8334269660bd5b6360855.jpg\n",
            "Moved: Ping-10-_bmp.rf.709d9f3c62cf031f18bec4b74af60568.jpg\n",
            "Moved: DaYuenJiao-12-_bmp.rf.a1f07f54433484cc4a056206ce2c8e73.jpg\n",
            "Moved: LightFeather-17-_bmp.rf.a60facb004e480d55ad2e51eafeb2e6d.jpg\n",
            "Moved: White-7-_bmp.rf.dc211d3b87864fc734848e83635d52bc.jpg\n",
            "Moved: Grey-11-_bmp.rf.ccdbd54d2c74bf7169235efdd81ca42d.jpg\n",
            "Moved: BrokenBig-11-_bmp.rf.460189919dc15bab7cc8b7113804abc4.jpg\n",
            "Moved: SizeB-12-_bmp.rf.d16adc7524e3d1fd2b625d5a40d03628.jpg\n",
            "Moved: BrokenSmall-31-_bmp.rf.b05fe0737e459b3d2a7a4eb3d24b2d5b.jpg\n",
            "Moved: BrokenBig-19-_bmp.rf.44ed167b17d284b6d34c3cab7245a3bd.jpg\n",
            "Moved: BrokenSmall-2-_bmp.rf.900ded07f8b4f25a4b4166ce2a4b4a8c.jpg\n",
            "Moved: Bone-13-_bmp.rf.4bc5c374ee617b20187a9bc334603e1c.jpg\n",
            "Moved: SizeB-14-_bmp.rf.4ce62d9b2da145a11102252dd20e9487.jpg\n",
            "Moved: MedFeather-20-_bmp.rf.51e20f6e5d33c27acb91e5402a490d9e.jpg\n",
            "Moved: SizeB-8-_bmp.rf.3a00ea556d6e8fada4f7759a3492d16e.jpg\n",
            "Moved: WhiteBeige-17-_bmp.rf.9cc26d3cde20416e6ac77c7655dce256.jpg\n",
            "Moved: MedFeather-15-_bmp.rf.a8a889c017dd43caf6bad15d06d15313.jpg\n",
            "Moved: Bone-10-_bmp.rf.5af4528e1f40b547c2ef966ad84a8459.jpg\n",
            "Moved: Grey-5-_bmp.rf.dab520764cb0852c1b4707394a6d0d5c.jpg\n",
            "Moved: HeavyFeather-10-_bmp.rf.cbf8637afae1a60b9bd839e158bb96df.jpg\n",
            "Moved: BrokenSmall-29-_bmp.rf.a1c141cb9b4764ae03a7041186d94df5.jpg\n",
            "Moved: LightFeather-3-_bmp.rf.0d54974e8c3f3016d9255cd16de09a93.jpg\n",
            "Moved: MedFeather-13-_bmp.rf.52b3e56501d1f66d1881bb0f4143c60c.jpg\n",
            "Moved: Beige-5-_bmp.rf.9b00dadff0fe40da39d94923b5878270.jpg\n",
            "Moved: SizeC-7-_bmp.rf.4147477962a251ca20261d670d90cea5.jpg\n",
            "Moved: Triangular-1-_bmp.rf.2f7357fbf1812027bb941533a6eb55b2.jpg\n",
            "Moved: SizeB-13-_bmp.rf.007032ebf1cc61452d9c00bc37be10b6.jpg\n",
            "Moved: Ping-11-_bmp.rf.ec26edef673628b7c43312115223c780.jpg\n",
            "Moved: Triangular-15-_bmp.rf.c65206fbacecdf86dd46d31e61d4c853.jpg\n",
            "Moved: DoubleColour-6-_bmp.rf.d919bd7b628d2e4c52bed2ca4ef77666.jpg\n",
            "Moved: White-2-_bmp.rf.0d20a698aad4a8a6628e817c333b0901.jpg\n",
            "Moved: Mossy-8-_bmp.rf.136d342498facb5acedeadcdd4c4a7b1.jpg\n",
            "Moved: BrokenSmall-75-_bmp.rf.50c181f7a3ff7810423813c3cc7d4704.jpg\n",
            "Moved: White-8-_bmp.rf.b4232502467caa2d0dd616b6b8e58327.jpg\n",
            "Moved: WhiteBeige-7-_bmp.rf.6bfaceff7a2908cbedacaaa5d581676a.jpg\n",
            "Moved: Mossy-4-_bmp.rf.6f200202f615a015655b79e9cba5e523.jpg\n",
            "Moved: DaYuenJiao-11-_bmp.rf.679cb8e19ab4e04e0231cba6215479de.jpg\n",
            "Moved: WhiteBeige-4-_bmp.rf.dc7caa4cbfced55f5c7a8ed957e8cdc3.jpg\n",
            "Moved: SizeB-9-_bmp.rf.02d90c2e8a0debcd3b98d139b993ba2d.jpg\n",
            "Moved: LightFeather-17-_bmp.rf.e56d9c56f4d56021fbfacb993c50c5d1.jpg\n",
            "Moved: White-1-_bmp.rf.87b863c547bfd34c15214815f7972924.jpg\n",
            "Moved: BrokenSmall-74-_bmp.rf.321cf4fae4033d7a3d514ddc32620e6d.jpg\n",
            "Moved: SizeC-13-_bmp.rf.4542bf6a7664afe35a0fc1ed01274ed8.jpg\n",
            "Moved: BrokenSmall-73-_bmp.rf.bcab3d955ff9081ec859534e2031c841.jpg\n",
            "Moved: Mossy-7-_bmp.rf.678e7ccbd085d9120f80f2eefdf31634.jpg\n",
            "Moved: SizeC-7-_bmp.rf.be274bc197c4d218ed9a3543bdf52ab3.jpg\n",
            "Moved: SizeC-8-_bmp.rf.59a6aae264c0dccf8bf2a18b75c93b04.jpg\n",
            "Moved: Strips-3-_bmp.rf.b10b85b6e68349061c15a10d0a1a2b14.jpg\n",
            "Moved: BrokenSmall-39-_bmp.rf.3cff656215685bd169643c531b54835d.jpg\n",
            "Moved: BrokenSmall-58-_bmp.rf.dec8d5bab59b867672a127851733ed6d.jpg\n",
            "Moved: BrokenSmall-2-_bmp.rf.4d168262b154acf8e095fa19597dc316.jpg\n",
            "Moved: BrokenBig-19-_bmp.rf.48d869fc03833c015c02ae7d26f16a06.jpg\n",
            "Moved: DoubleColour-6-_bmp.rf.a1b3e64f4beb625b3893d460a2794493.jpg\n",
            "Moved: Strips-8-_bmp.rf.b28ba11bf8b419757f432d0ee8d1edbd.jpg\n",
            "Moved: WhiteBeige-13-_bmp.rf.d6c0fb74f4749b1ea326daba9c754ed4.jpg\n",
            "Moved: LightFeather-7-_bmp.rf.3512f8cab82865192212da8167947277.jpg\n",
            "Moved: BrokenBig-13-_bmp.rf.9c5183059ff9693180e528f459490ede.jpg\n",
            "Moved: SizeA-15-_bmp.rf.2ba4d5478097aefff83c19ad6d0ada3a.jpg\n",
            "Moved: Bone-13-_bmp.rf.4938a31bdf66ddffff25821492b9a150.jpg\n",
            "Moved: Grey-6-_bmp.rf.41c971c80766be3165932432912621ce.jpg\n",
            "Moved: Beige-8-_bmp.rf.71ad9fcb2da2fded7dcad5a04c8db3d8.jpg\n",
            "Moved: SizeB-8-_bmp.rf.d04481ae2b66897273c23e66fea17560.jpg\n",
            "Moved: Yellow-20-_bmp.rf.5e88a8752252e224b80f26e13f486b6b.jpg\n",
            "Moved: HeavyFeather-9-_bmp.rf.cf0235fe710d8bb19726a76ba13a89ae.jpg\n",
            "Moved: SizeC-16-_bmp.rf.1af5c14f540be24edc64ff028027d365.jpg\n",
            "Moved: BrokenSmall-37-_bmp.rf.747c8ae96f276cf0fedb71a638f25ea1.jpg\n",
            "Moved: LightFeather-16-_bmp.rf.347b020d79981fa534c172c2c5d5d1f7.jpg\n",
            "Moved: Ping-17-_bmp.rf.3e0fa433feb4dc14d4c45006f1a9bbc2.jpg\n",
            "Moved: BrokenSmall-58-_bmp.rf.6989b399613323fd67dc788d750fbaa0.jpg\n",
            "Moved: BrokenBig-19-_bmp.rf.f056990ba4675d9d3430097ec8a82cdd.jpg\n",
            "Moved: BrokenSmall-59-_bmp.rf.86df86cfeebfbb3592784febc6761542.jpg\n",
            "Moved: SizeB-13-_bmp.rf.1cb5d5d32a5eb8a3439a409373d67b97.jpg\n",
            "Moved: Yellow-11-_bmp.rf.06a3168781624fb9e604365191519cd7.jpg\n",
            "Moved: BrokenSmall-64-_bmp.rf.3be9042594a5da363fed2fb6303e6504.jpg\n",
            "Moved: BrokenBig-11-_bmp.rf.9e9000c0b0168903a940fcf852979540.jpg\n",
            "Moved: DoubleColour-14-_bmp.rf.22b2c662b003895b5ba2b359218dc9f2.jpg\n",
            "Moved: SizeB-6-_bmp.rf.53b69884e266a19ebfc4f784cb147262.jpg\n",
            "Moved: ThickFlesh-15-_bmp.rf.d6764ccc53875628b0e816e32c034d59.jpg\n",
            "Moved: White-2-_bmp.rf.017d2352e22e657a33af9ee436a5f6a2.jpg\n",
            "Moved: ThickFlesh-5-_bmp.rf.de68f5f1fd0940d5df1e6a1a6054afd2.jpg\n",
            "Moved: BrokenBig-6-_bmp.rf.285ff46af91e6d5b948a35fb872d5314.jpg\n",
            "Moved: Strips-11-_bmp.rf.de1dc59717d6f40679961ad3f2680061.jpg\n",
            "Moved: Grey-8-_bmp.rf.841872152b81da9cc925409a8736d112.jpg\n",
            "Moved: Ping-1-_bmp.rf.782a51d2a8502064d145c5b2f5de7f76.jpg\n",
            "Moved: Triangular-7-_bmp.rf.c5b15635b95fba587e54b1ca63d310ad.jpg\n",
            "Moved: BrokenSmall-10-_bmp.rf.1224908977b6880abc2fd1d97cc59bc5.jpg\n",
            "Moved: Bone-5-_bmp.rf.21de65f7270a3a0d919ac05b17b7e2e0.jpg\n",
            "Moved: DoubleColour-11-_bmp.rf.852effa251ac0d8c7e5306deaa620a4f.jpg\n",
            "Moved: MedFeather-8-_bmp.rf.33133482235f44fd3c2eb5ba13d6e324.jpg\n",
            "Moved: Triangular-12-_bmp.rf.c306f2b59eefafc9a91459b7fbd2e2d9.jpg\n",
            "Moved: MedFeather-2-_bmp.rf.bd9e62952ec4ae66247bb5a71f51babf.jpg\n",
            "Moved: BrokenSmall-19-_bmp.rf.233e1c185f4925b4a71db223eaa357eb.jpg\n",
            "Moved: ThickFlesh-3-_bmp.rf.83db9985077379b6cde42d03f0d2f785.jpg\n",
            "Moved: SizeA-5-_bmp.rf.c35a99ba3faa1b6b352b9b85de799fe3.jpg\n",
            "Moved: Beige-16-_bmp.rf.0560044c2c2223e6cbd356eb9a47cddf.jpg\n",
            "Moved: White-5-_bmp.rf.97b090d04802ad0bc9c8a0a139f52b40.jpg\n",
            "Moved: Mossy-12-_bmp.rf.eead3c8dec6d4c46cdc94e5b92a5efed.jpg\n",
            "Moved: Triangular-14-_bmp.rf.a2b09cc93c4fdeacc3f7efc2522224f1.jpg\n",
            "Moved: LightFeather-4-_bmp.rf.7e8141e30c1690e5ebd1704a85b16b7f.jpg\n",
            "Moved: ThickFlesh-17-_bmp.rf.11cbd75335d5cefd60d5db10bf5b0007.jpg\n",
            "Moved: Beige-15-_bmp.rf.7ed33d4dc16294dd265aa14d3ac323e7.jpg\n",
            "Moved: Strips-2-_bmp.rf.49191369d669495dea1806348ff99202.jpg\n",
            "Moved: Strips-6-_bmp.rf.49d3f77d5db9d83b681101240f56c39f.jpg\n",
            "Moved: SizeC-10-_bmp.rf.109df476d51793c4fbf52612a02f8ff9.jpg\n",
            "Moved: Beige-14-_bmp.rf.4918e39b4ecad96c96f44dcb353229e9.jpg\n",
            "Moved: LightFeather-6-_bmp.rf.d83e1f394386808004ff9718fa5c7365.jpg\n",
            "Moved: White-10-_bmp.rf.e913dff74747a0855d9af021369c5529.jpg\n",
            "Moved: Mossy-14-_bmp.rf.0a82ee171fca14e72119f43505be014a.jpg\n",
            "Moved: BrokenSmall-47-_bmp.rf.e2445454ef248b7e1d0a15c59b079ce3.jpg\n",
            "Moved: Yellow-9-_bmp.rf.c60708a40e29488dcfe4a89f970c125e.jpg\n",
            "Moved: Grey-14-_bmp.rf.d0aa59ef1b2082c27b62a8f97de56287.jpg\n",
            "Moved: BrokenSmall-23-_bmp.rf.b001115730b81d12c31a85031d4a5bd7.jpg\n",
            "Moved: ThickFlesh-13-_bmp.rf.b6413288813372b21283afa274262b23.jpg\n",
            "Moved: Yellow-2-_bmp.rf.e64e6029d06ba84ab840fe4848988ea3.jpg\n",
            "Moved: DoubleColour-1-_bmp.rf.2473f2434cc90e37f595762e30f1e602.jpg\n",
            "Moved: DaYuenJiao-13-_bmp.rf.6aeed37667841a4b4c0bd367b9781944.jpg\n",
            "Moved: _annotations.csv\n",
            "Moved: HeavyFeather-16-_bmp.rf.ba77cce185f71aae30662be29dc4c8cb.jpg\n",
            "Moved: ThickFlesh-14-_bmp.rf.be18231d9a5760026627a1d1ffb080b4.jpg\n",
            "Moved: BrokenSmall-42-_bmp.rf.42496c0cdabe0a9ba3d32d7ea4c076e1.jpg\n",
            "Moved: MedFeather-18-_bmp.rf.1a6c9eb65d7bfdf6b7035b30792eaa90.jpg\n",
            "Moved: DoubleColour-5-_bmp.rf.1f84d56e4124ff27e5691d0b32b8b850.jpg\n",
            "Moved: HeavyFeather-18-_bmp.rf.07e65a98a777e3de21a4d610611f31ce.jpg\n",
            "Moved: White-14-_bmp.rf.4a0a25eafe275f988cbc3ee1def22f9d.jpg\n",
            "Moved: Ping-4-_bmp.rf.c4709acff4557b57c00eb05ec53bf2f1.jpg\n",
            "Moved: MedFeather-10-_bmp.rf.af394eef82480a42c33a195c5178c37e.jpg\n",
            "Moved: BrokenSmall-3-_bmp.rf.1935744bb94aa98f8c32601e5add2d21.jpg\n",
            "Moved: LightFeather-13-_bmp.rf.c39e96d15542e6f06183c7c13674ff9b.jpg\n",
            "Moved: BrokenSmall-33-_bmp.rf.9b2588c367251b1a7782bcfe0fde93f2.jpg\n",
            "Moved: Grey-10-_bmp.rf.4a8556132f380755482146c6d83e7f1c.jpg\n",
            "Moved: Grey-16-_bmp.rf.0fca81bcaccfd46dacd413042b0a1a1a.jpg\n",
            "Moved: BrokenBig-4-_bmp.rf.13f0c976f7503a2b3f2b3c68ae6e8c0f.jpg\n",
            "Moved: LightFeather-1-_bmp.rf.702694255ff895ee93304bbb5b9cb69b.jpg\n",
            "Moved: Yellow-14-_bmp.rf.736f07aab520a0daa093d891e6e6ab81.jpg\n",
            "Moved: BrokenSmall-1-_bmp.rf.ab4bda0dc421e080d1e351acae64fc3c.jpg\n",
            "Moved: SizeB-4-_bmp.rf.93a855dc9e25ab78b0ef7e915c2e09b9.jpg\n",
            "Moved: MedFeather-12-_bmp.rf.4a7cc78d3c3f1877d5d5c1c898e1ecd0.jpg\n",
            "Moved: BrokenSmall-12-_bmp.rf.33120b12fd0ad878c017340b4270f16d.jpg\n",
            "Moved: BrokenBig-18-_bmp.rf.651c442730a0c71edafebf1868f5ab06.jpg\n",
            "Moved: WhiteBeige-6-_bmp.rf.d6117fbf124c0e711a75c0d7ee860360.jpg\n",
            "Moved: Mossy-3-_bmp.rf.5a099eaa34e151bf91a4331ef17f9b52.jpg\n",
            "Moved: ThickFlesh-6-_bmp.rf.ce872597a1f9cf764c5fd4ed89f2cf56.jpg\n",
            "Moved: ThickFlesh-7-_bmp.rf.7a791ec1219fd4039fe000304d1903e4.jpg\n",
            "Moved: LightFeather-12-_bmp.rf.2da7b0ce8359c9f79edca76f40a54182.jpg\n",
            "Moved: DaYuenJiao-17-_bmp.rf.100a6dbc3899ae283b66652bd274e25b.jpg\n",
            "Moved: BrokenSmall-60-_bmp.rf.3513e6eb6ff678be64ad73ad827ba2f6.jpg\n",
            "Moved: LightFeather-11-_bmp.rf.332e4d814ba9b935b183c9236726f27f.jpg\n",
            "Moved: Grey-17-_bmp.rf.93c9045763e8c761dcdd76b089b1f085.jpg\n",
            "Moved: Mossy-1-_bmp.rf.529555aeb644f15a8362a5bbb740ca82.jpg\n",
            "Moved: HeavyFeather-3-_bmp.rf.be632056c773518f494360020cdd8f50.jpg\n",
            "Moved: HeavyFeather-7-_bmp.rf.a121f4a5a702cc85087ad5cca99b7d47.jpg\n",
            "Moved: BrokenSmall-28-_bmp.rf.45ed9c7401450970bee299ddde16a764.jpg\n",
            "Moved: BrokenSmall-4-_bmp.rf.2aee3c5587b6fa4eb7f861e8c2dda0fd.jpg\n",
            "Moved: Beige-4-_bmp.rf.236ac3c150eb68adb1c1210c571b98ee.jpg\n",
            "Moved: Shredded-1-_bmp.rf.46ca11691db4474392e1b7f6e92ba99b.jpg\n",
            "Moved: WhiteBeige-12-_bmp.rf.9fa26d21ca8a4984fa9b841ecab59d9c.jpg\n",
            "Moved: Ping-7-_bmp.rf.e63ae3bdbff078fcb7755d3d3b78431f.jpg\n",
            "Moved: BrokenBig-14-_bmp.rf.4bf0500aaf849ab65a5fa65c47565bf5.jpg\n",
            "Moved: Grey-13-_bmp.rf.38679cc38e3cb18257573c0fb8c3cddc.jpg\n",
            "Moved: DaYuenJiao-14-_bmp.rf.5d96d053d9466787cbf65fadedcd1f4f.jpg\n",
            "Moved: _annotations.csv\n",
            "Moved: HeavyFeather-5-_bmp.rf.4669200c3311fd921513d246616fa361.jpg\n",
            "Moved: Ping-8-_bmp.rf.b1eb716fb5323dad269859667d717995.jpg\n",
            "Moved: ThickFlesh-1-_bmp.rf.ec86597ed402aa51d4b62d5c3bf434af.jpg\n",
            "Moved: WhiteBeige-1-_bmp.rf.d1807d471eb6f43f562207763a110e05.jpg\n",
            "Moved: BrokenSmall-15-_bmp.rf.b20a51f7f8fcca7cb3cfdb0ab16611cb.jpg\n",
            "Moved: Triangular-23-_bmp.rf.93063b713f94717f65fffb9c78ed823a.jpg\n",
            "Moved: HeavyFeather-1-_bmp.rf.6c87e6736ee20d495c8793afa836fac1.jpg\n",
            "Moved: BrokenSmall-72-_bmp.rf.4dc02ec999175386231df32c21c4d130.jpg\n",
            "Moved: BrokenSmall-16-_bmp.rf.8c4f96e867b599c796912451909517e0.jpg\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!rm -r Bird-Nest-7"
      ],
      "metadata": {
        "id": "VSk_vLqgk1Nj"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install roboflow\n",
        "\n",
        "from roboflow import Roboflow\n",
        "rf = Roboflow(api_key=\"1woWfE1q4RoyHytXmktz\")\n",
        "project = rf.workspace(\"ebn\").project(\"bird-nest-exr6l\")\n",
        "dataset = project.version(7).download(\"tfrecord\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yDVgk9NplDnZ",
        "outputId": "693d7c5c-4766-4f1e-e564-456be666e4d6"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: roboflow in /usr/local/lib/python3.10/dist-packages (1.1.7)\n",
            "Requirement already satisfied: certifi==2022.12.7 in /usr/local/lib/python3.10/dist-packages (from roboflow) (2022.12.7)\n",
            "Requirement already satisfied: chardet==4.0.0 in /usr/local/lib/python3.10/dist-packages (from roboflow) (4.0.0)\n",
            "Requirement already satisfied: cycler==0.10.0 in /usr/local/lib/python3.10/dist-packages (from roboflow) (0.10.0)\n",
            "Requirement already satisfied: idna==2.10 in /usr/local/lib/python3.10/dist-packages (from roboflow) (2.10)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.10/dist-packages (from roboflow) (1.4.5)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from roboflow) (3.7.1)\n",
            "Requirement already satisfied: numpy>=1.18.5 in /usr/local/lib/python3.10/dist-packages (from roboflow) (1.23.5)\n",
            "Requirement already satisfied: opencv-python-headless==4.8.0.74 in /usr/local/lib/python3.10/dist-packages (from roboflow) (4.8.0.74)\n",
            "Requirement already satisfied: Pillow>=7.1.2 in /usr/local/lib/python3.10/dist-packages (from roboflow) (9.4.0)\n",
            "Requirement already satisfied: pyparsing==2.4.7 in /usr/local/lib/python3.10/dist-packages (from roboflow) (2.4.7)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.10/dist-packages (from roboflow) (2.8.2)\n",
            "Requirement already satisfied: python-dotenv in /usr/local/lib/python3.10/dist-packages (from roboflow) (1.0.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from roboflow) (2.31.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from roboflow) (1.16.0)\n",
            "Requirement already satisfied: supervision in /usr/local/lib/python3.10/dist-packages (from roboflow) (0.14.0)\n",
            "Requirement already satisfied: urllib3>=1.26.6 in /usr/local/lib/python3.10/dist-packages (from roboflow) (2.0.4)\n",
            "Requirement already satisfied: tqdm>=4.41.0 in /usr/local/lib/python3.10/dist-packages (from roboflow) (4.66.1)\n",
            "Requirement already satisfied: PyYAML>=5.3.1 in /usr/local/lib/python3.10/dist-packages (from roboflow) (6.0.1)\n",
            "Requirement already satisfied: requests-toolbelt in /usr/local/lib/python3.10/dist-packages (from roboflow) (1.0.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->roboflow) (1.1.0)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->roboflow) (4.42.1)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->roboflow) (23.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->roboflow) (3.2.0)\n",
            "Requirement already satisfied: scipy<2.0.0,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from supervision->roboflow) (1.11.2)\n",
            "loading Roboflow workspace...\n",
            "loading Roboflow project...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading Dataset Version Zip in Bird-Nest-7 to tfrecord:: 100%|██████████| 128800/128800 [00:07<00:00, 18062.70it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Extracting Dataset Version Zip to Bird-Nest-7 in tfrecord:: 100%|██████████| 11/11 [00:00<00:00, 44.73it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import glob\n",
        "\n",
        "source_train = os.path.join(paths['ROBOFLOW_TRAIN_PATH'],'Bird-Nest.tfrecord')\n",
        "destination_train = os.path.join(paths['ANNOTATION_PATH'], 'train.record')\n",
        "\n",
        "source_test = os.path.join(paths['ROBOFLOW_TEST_PATH'],'Bird-Nest.tfrecord')\n",
        "destination_test = os.path.join(paths['ANNOTATION_PATH'], 'test.record')\n",
        "\n",
        "source_valid = os.path.join(paths['ROBOFLOW_VALIDATE_PATH'],'Bird-Nest.tfrecord')\n",
        "destination_valid = os.path.join(paths['ANNOTATION_PATH'], 'valid.record')\n",
        "\n",
        "os.rename(source_train, destination_train)\n",
        "os.rename(source_test, destination_test)\n",
        "os.rename(source_valid, destination_valid)"
      ],
      "metadata": {
        "id": "Siymrf2zrG8S"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!rm -r Bird-Nest-7"
      ],
      "metadata": {
        "id": "C9Xf_DuRTm_X"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qT4QU7pLpfDE"
      },
      "source": [
        "# 4. Copy Model Config to Training Folder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "cOjuTFbwpfDF"
      },
      "outputs": [],
      "source": [
        "if os.name =='posix':\n",
        "    !cp {os.path.join(paths['PRETRAINED_MODEL_PATH'], PRETRAINED_MODEL_NAME, 'pipeline.config')} {os.path.join(paths['CHECKPOINT_PATH'])}\n",
        "if os.name == 'nt':\n",
        "    !copy {os.path.join(paths['PRETRAINED_MODEL_PATH'], PRETRAINED_MODEL_NAME, 'pipeline.config')} {os.path.join(paths['CHECKPOINT_PATH'])}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ga8gpNslpfDF"
      },
      "source": [
        "# 5. Update Config For Transfer Learning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "Z9hRrO_ppfDF"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from object_detection.utils import config_util\n",
        "from object_detection.protos import pipeline_pb2\n",
        "from google.protobuf import text_format"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "c2A0mn4ipfDF"
      },
      "outputs": [],
      "source": [
        "config = config_util.get_configs_from_pipeline_file(files['PIPELINE_CONFIG'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uQA13-afpfDF"
      },
      "outputs": [],
      "source": [
        "config"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "9vK5lotDpfDF"
      },
      "outputs": [],
      "source": [
        "pipeline_config = pipeline_pb2.TrainEvalPipelineConfig()\n",
        "with tf.io.gfile.GFile(files['PIPELINE_CONFIG'], \"r\") as f:\n",
        "    proto_str = f.read()\n",
        "    text_format.Merge(proto_str, pipeline_config)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "rP43Ph0JpfDG"
      },
      "outputs": [],
      "source": [
        "pipeline_config.model.ssd.num_classes = len(labels)\n",
        "pipeline_config.train_config.batch_size = 4\n",
        "pipeline_config.train_config.fine_tune_checkpoint = os.path.join(paths['PRETRAINED_MODEL_PATH'], PRETRAINED_MODEL_NAME, 'checkpoint', 'ckpt-0')\n",
        "pipeline_config.train_config.fine_tune_checkpoint_type = \"detection\"\n",
        "pipeline_config.train_input_reader.label_map_path= files['LABELMAP']\n",
        "pipeline_config.train_input_reader.tf_record_input_reader.input_path[:] = [os.path.join(paths['ANNOTATION_PATH'], 'train.record')]\n",
        "pipeline_config.eval_input_reader[0].label_map_path = files['LABELMAP']\n",
        "pipeline_config.eval_input_reader[0].tf_record_input_reader.input_path[:] = [os.path.join(paths['ANNOTATION_PATH'], 'test.record')]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "oJvfgwWqpfDG"
      },
      "outputs": [],
      "source": [
        "config_text = text_format.MessageToString(pipeline_config)\n",
        "with tf.io.gfile.GFile(files['PIPELINE_CONFIG'], \"wb\") as f:\n",
        "    f.write(config_text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zr3ON7xMpfDG"
      },
      "source": [
        "# 6. Train the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "B-Y2UQmQpfDG"
      },
      "outputs": [],
      "source": [
        "TRAINING_SCRIPT = os.path.join(paths['APIMODEL_PATH'], 'research', 'object_detection', 'model_main_tf2.py')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "jMP2XDfQpfDH"
      },
      "outputs": [],
      "source": [
        "command = \"python {} --model_dir={} --pipeline_config_path={} --num_train_steps=5000\".format(TRAINING_SCRIPT, paths['CHECKPOINT_PATH'],files['PIPELINE_CONFIG'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A4OXXi-ApfDH"
      },
      "outputs": [],
      "source": [
        "print(command)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "i3ZsJR-qpfDH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f1afdd28-0436-4bfc-fabb-0f12d3338f43"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-09-24 15:50:48.511331: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "2023-09-24 15:50:54.708700: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:47] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0',)\n",
            "I0924 15:50:54.713843 132668006404096 mirrored_strategy.py:419] Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0',)\n",
            "INFO:tensorflow:Maybe overwriting train_steps: 5000\n",
            "I0924 15:50:54.774321 132668006404096 config_util.py:552] Maybe overwriting train_steps: 5000\n",
            "INFO:tensorflow:Maybe overwriting use_bfloat16: False\n",
            "I0924 15:50:54.774482 132668006404096 config_util.py:552] Maybe overwriting use_bfloat16: False\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.10/dist-packages/object_detection/model_lib_v2.py:563: StrategyBase.experimental_distribute_datasets_from_function (from tensorflow.python.distribute.distribute_lib) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "rename to distribute_datasets_from_function\n",
            "W0924 15:50:54.955971 132668006404096 deprecation.py:364] From /usr/local/lib/python3.10/dist-packages/object_detection/model_lib_v2.py:563: StrategyBase.experimental_distribute_datasets_from_function (from tensorflow.python.distribute.distribute_lib) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "rename to distribute_datasets_from_function\n",
            "INFO:tensorflow:Reading unweighted datasets: ['Tensorflow/workspace/annotations/train.record']\n",
            "I0924 15:50:54.966159 132668006404096 dataset_builder.py:162] Reading unweighted datasets: ['Tensorflow/workspace/annotations/train.record']\n",
            "INFO:tensorflow:Reading record datasets for input file: ['Tensorflow/workspace/annotations/train.record']\n",
            "I0924 15:50:54.966331 132668006404096 dataset_builder.py:79] Reading record datasets for input file: ['Tensorflow/workspace/annotations/train.record']\n",
            "INFO:tensorflow:Number of filenames to read: 1\n",
            "I0924 15:50:54.966391 132668006404096 dataset_builder.py:80] Number of filenames to read: 1\n",
            "WARNING:tensorflow:num_readers has been reduced to 1 to match input file shards.\n",
            "W0924 15:50:54.966438 132668006404096 dataset_builder.py:86] num_readers has been reduced to 1 to match input file shards.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.10/dist-packages/object_detection/builders/dataset_builder.py:100: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.deterministic`.\n",
            "W0924 15:50:54.983096 132668006404096 deprecation.py:364] From /usr/local/lib/python3.10/dist-packages/object_detection/builders/dataset_builder.py:100: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.deterministic`.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.10/dist-packages/object_detection/builders/dataset_builder.py:235: DatasetV1.map_with_legacy_function (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.map()\n",
            "W0924 15:50:55.010481 132668006404096 deprecation.py:364] From /usr/local/lib/python3.10/dist-packages/object_detection/builders/dataset_builder.py:235: DatasetV1.map_with_legacy_function (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.map()\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.10/dist-packages/tensorflow/python/util/dispatch.py:1176: sparse_to_dense (from tensorflow.python.ops.sparse_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Create a `tf.sparse.SparseTensor` and use `tf.sparse.to_dense` instead.\n",
            "W0924 15:51:01.599584 132668006404096 deprecation.py:364] From /usr/local/lib/python3.10/dist-packages/tensorflow/python/util/dispatch.py:1176: sparse_to_dense (from tensorflow.python.ops.sparse_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Create a `tf.sparse.SparseTensor` and use `tf.sparse.to_dense` instead.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.10/dist-packages/tensorflow/python/util/dispatch.py:1176: sample_distorted_bounding_box (from tensorflow.python.ops.image_ops_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "`seed2` arg is deprecated.Use sample_distorted_bounding_box_v2 instead.\n",
            "W0924 15:51:04.171178 132668006404096 deprecation.py:364] From /usr/local/lib/python3.10/dist-packages/tensorflow/python/util/dispatch.py:1176: sample_distorted_bounding_box (from tensorflow.python.ops.image_ops_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "`seed2` arg is deprecated.Use sample_distorted_bounding_box_v2 instead.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.10/dist-packages/tensorflow/python/util/dispatch.py:1176: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.cast` instead.\n",
            "W0924 15:51:05.742864 132668006404096 deprecation.py:364] From /usr/local/lib/python3.10/dist-packages/tensorflow/python/util/dispatch.py:1176: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.cast` instead.\n",
            "/usr/local/lib/python3.10/dist-packages/keras/src/backend.py:452: UserWarning: `tf.keras.backend.set_learning_phase` is deprecated and will be removed after 2020-10-11. To update it, simply pass a True/False value to the `training` argument of the `__call__` method of your layer or model.\n",
            "  warnings.warn(\n",
            "I0924 15:51:13.653672 132660668134976 api.py:460] feature_map_spatial_dims: [(80, 80), (40, 40), (20, 20), (10, 10), (5, 5)]\n",
            "I0924 15:51:21.201799 132660668134976 api.py:460] feature_map_spatial_dims: [(80, 80), (40, 40), (20, 20), (10, 10), (5, 5)]\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "I0924 15:51:33.005828 132668006404096 cross_device_ops.py:617] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "I0924 15:51:33.008623 132668006404096 cross_device_ops.py:617] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "I0924 15:51:33.009679 132668006404096 cross_device_ops.py:617] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "I0924 15:51:33.010591 132668006404096 cross_device_ops.py:617] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "I0924 15:51:33.013987 132668006404096 cross_device_ops.py:617] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "I0924 15:51:33.014992 132668006404096 cross_device_ops.py:617] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "I0924 15:51:33.015990 132668006404096 cross_device_ops.py:617] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "I0924 15:51:33.016881 132668006404096 cross_device_ops.py:617] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "I0924 15:51:33.021368 132668006404096 cross_device_ops.py:617] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "I0924 15:51:33.022328 132668006404096 cross_device_ops.py:617] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.10/dist-packages/tensorflow/python/util/deprecation.py:648: calling map_fn_v2 (from tensorflow.python.ops.map_fn) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use fn_output_signature instead\n",
            "W0924 15:51:34.129278 132661654545984 deprecation.py:569] From /usr/local/lib/python3.10/dist-packages/tensorflow/python/util/deprecation.py:648: calling map_fn_v2 (from tensorflow.python.ops.map_fn) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use fn_output_signature instead\n",
            "I0924 15:51:35.400947 132661654545984 api.py:460] feature_map_spatial_dims: [(80, 80), (40, 40), (20, 20), (10, 10), (5, 5)]\n",
            "I0924 15:51:40.455625 132661654545984 api.py:460] feature_map_spatial_dims: [(80, 80), (40, 40), (20, 20), (10, 10), (5, 5)]\n",
            "I0924 15:51:45.176280 132661654545984 api.py:460] feature_map_spatial_dims: [(80, 80), (40, 40), (20, 20), (10, 10), (5, 5)]\n",
            "I0924 15:51:50.380143 132661654545984 api.py:460] feature_map_spatial_dims: [(80, 80), (40, 40), (20, 20), (10, 10), (5, 5)]\n",
            "INFO:tensorflow:Step 100 per-step time 0.391s\n",
            "I0924 15:52:12.872284 132668006404096 model_lib_v2.py:705] Step 100 per-step time 0.391s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.50010544,\n",
            " 'Loss/localization_loss': 0.22890685,\n",
            " 'Loss/regularization_loss': 0.15172915,\n",
            " 'Loss/total_loss': 0.8807415,\n",
            " 'learning_rate': 0.0319994}\n",
            "I0924 15:52:12.872582 132668006404096 model_lib_v2.py:708] {'Loss/classification_loss': 0.50010544,\n",
            " 'Loss/localization_loss': 0.22890685,\n",
            " 'Loss/regularization_loss': 0.15172915,\n",
            " 'Loss/total_loss': 0.8807415,\n",
            " 'learning_rate': 0.0319994}\n",
            "INFO:tensorflow:Step 200 per-step time 0.102s\n",
            "I0924 15:52:23.072985 132668006404096 model_lib_v2.py:705] Step 200 per-step time 0.102s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.4351206,\n",
            " 'Loss/localization_loss': 0.11482617,\n",
            " 'Loss/regularization_loss': 0.15163569,\n",
            " 'Loss/total_loss': 0.7015825,\n",
            " 'learning_rate': 0.0373328}\n",
            "I0924 15:52:23.073271 132668006404096 model_lib_v2.py:708] {'Loss/classification_loss': 0.4351206,\n",
            " 'Loss/localization_loss': 0.11482617,\n",
            " 'Loss/regularization_loss': 0.15163569,\n",
            " 'Loss/total_loss': 0.7015825,\n",
            " 'learning_rate': 0.0373328}\n",
            "INFO:tensorflow:Step 300 per-step time 0.102s\n",
            "I0924 15:52:33.279368 132668006404096 model_lib_v2.py:705] Step 300 per-step time 0.102s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.25866246,\n",
            " 'Loss/localization_loss': 0.068347625,\n",
            " 'Loss/regularization_loss': 0.15134482,\n",
            " 'Loss/total_loss': 0.47835493,\n",
            " 'learning_rate': 0.0426662}\n",
            "I0924 15:52:33.279686 132668006404096 model_lib_v2.py:708] {'Loss/classification_loss': 0.25866246,\n",
            " 'Loss/localization_loss': 0.068347625,\n",
            " 'Loss/regularization_loss': 0.15134482,\n",
            " 'Loss/total_loss': 0.47835493,\n",
            " 'learning_rate': 0.0426662}\n",
            "INFO:tensorflow:Step 400 per-step time 0.101s\n",
            "I0924 15:52:43.396258 132668006404096 model_lib_v2.py:705] Step 400 per-step time 0.101s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.20375371,\n",
            " 'Loss/localization_loss': 0.12237801,\n",
            " 'Loss/regularization_loss': 0.15101714,\n",
            " 'Loss/total_loss': 0.47714883,\n",
            " 'learning_rate': 0.047999598}\n",
            "I0924 15:52:43.396525 132668006404096 model_lib_v2.py:708] {'Loss/classification_loss': 0.20375371,\n",
            " 'Loss/localization_loss': 0.12237801,\n",
            " 'Loss/regularization_loss': 0.15101714,\n",
            " 'Loss/total_loss': 0.47714883,\n",
            " 'learning_rate': 0.047999598}\n",
            "INFO:tensorflow:Step 500 per-step time 0.103s\n",
            "I0924 15:52:53.651772 132668006404096 model_lib_v2.py:705] Step 500 per-step time 0.103s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.24828614,\n",
            " 'Loss/localization_loss': 0.06000926,\n",
            " 'Loss/regularization_loss': 0.1506116,\n",
            " 'Loss/total_loss': 0.458907,\n",
            " 'learning_rate': 0.053333}\n",
            "I0924 15:52:53.652138 132668006404096 model_lib_v2.py:708] {'Loss/classification_loss': 0.24828614,\n",
            " 'Loss/localization_loss': 0.06000926,\n",
            " 'Loss/regularization_loss': 0.1506116,\n",
            " 'Loss/total_loss': 0.458907,\n",
            " 'learning_rate': 0.053333}\n",
            "INFO:tensorflow:Step 600 per-step time 0.101s\n",
            "I0924 15:53:03.753092 132668006404096 model_lib_v2.py:705] Step 600 per-step time 0.101s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.279358,\n",
            " 'Loss/localization_loss': 0.08101415,\n",
            " 'Loss/regularization_loss': 0.1501304,\n",
            " 'Loss/total_loss': 0.5105026,\n",
            " 'learning_rate': 0.0586664}\n",
            "I0924 15:53:03.753370 132668006404096 model_lib_v2.py:708] {'Loss/classification_loss': 0.279358,\n",
            " 'Loss/localization_loss': 0.08101415,\n",
            " 'Loss/regularization_loss': 0.1501304,\n",
            " 'Loss/total_loss': 0.5105026,\n",
            " 'learning_rate': 0.0586664}\n",
            "INFO:tensorflow:Step 700 per-step time 0.102s\n",
            "I0924 15:53:13.993859 132668006404096 model_lib_v2.py:705] Step 700 per-step time 0.102s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.31134164,\n",
            " 'Loss/localization_loss': 0.085355885,\n",
            " 'Loss/regularization_loss': 0.14959316,\n",
            " 'Loss/total_loss': 0.5462907,\n",
            " 'learning_rate': 0.0639998}\n",
            "I0924 15:53:13.994139 132668006404096 model_lib_v2.py:708] {'Loss/classification_loss': 0.31134164,\n",
            " 'Loss/localization_loss': 0.085355885,\n",
            " 'Loss/regularization_loss': 0.14959316,\n",
            " 'Loss/total_loss': 0.5462907,\n",
            " 'learning_rate': 0.0639998}\n",
            "INFO:tensorflow:Step 800 per-step time 0.102s\n",
            "I0924 15:53:24.154932 132668006404096 model_lib_v2.py:705] Step 800 per-step time 0.102s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.22011064,\n",
            " 'Loss/localization_loss': 0.07280192,\n",
            " 'Loss/regularization_loss': 0.14898609,\n",
            " 'Loss/total_loss': 0.44189864,\n",
            " 'learning_rate': 0.069333196}\n",
            "I0924 15:53:24.155210 132668006404096 model_lib_v2.py:708] {'Loss/classification_loss': 0.22011064,\n",
            " 'Loss/localization_loss': 0.07280192,\n",
            " 'Loss/regularization_loss': 0.14898609,\n",
            " 'Loss/total_loss': 0.44189864,\n",
            " 'learning_rate': 0.069333196}\n",
            "INFO:tensorflow:Step 900 per-step time 0.101s\n",
            "I0924 15:53:34.274774 132668006404096 model_lib_v2.py:705] Step 900 per-step time 0.101s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.3031973,\n",
            " 'Loss/localization_loss': 0.07929272,\n",
            " 'Loss/regularization_loss': 0.14842318,\n",
            " 'Loss/total_loss': 0.5309132,\n",
            " 'learning_rate': 0.074666604}\n",
            "I0924 15:53:34.275111 132668006404096 model_lib_v2.py:708] {'Loss/classification_loss': 0.3031973,\n",
            " 'Loss/localization_loss': 0.07929272,\n",
            " 'Loss/regularization_loss': 0.14842318,\n",
            " 'Loss/total_loss': 0.5309132,\n",
            " 'learning_rate': 0.074666604}\n",
            "INFO:tensorflow:Step 1000 per-step time 0.101s\n",
            "I0924 15:53:44.394673 132668006404096 model_lib_v2.py:705] Step 1000 per-step time 0.101s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.28131434,\n",
            " 'Loss/localization_loss': 0.06569558,\n",
            " 'Loss/regularization_loss': 0.14775258,\n",
            " 'Loss/total_loss': 0.4947625,\n",
            " 'learning_rate': 0.08}\n",
            "I0924 15:53:44.394929 132668006404096 model_lib_v2.py:708] {'Loss/classification_loss': 0.28131434,\n",
            " 'Loss/localization_loss': 0.06569558,\n",
            " 'Loss/regularization_loss': 0.14775258,\n",
            " 'Loss/total_loss': 0.4947625,\n",
            " 'learning_rate': 0.08}\n",
            "INFO:tensorflow:Step 1100 per-step time 0.112s\n",
            "I0924 15:53:55.608385 132668006404096 model_lib_v2.py:705] Step 1100 per-step time 0.112s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.24354589,\n",
            " 'Loss/localization_loss': 0.022571921,\n",
            " 'Loss/regularization_loss': 0.1470536,\n",
            " 'Loss/total_loss': 0.4131714,\n",
            " 'learning_rate': 0.07999918}\n",
            "I0924 15:53:55.608675 132668006404096 model_lib_v2.py:708] {'Loss/classification_loss': 0.24354589,\n",
            " 'Loss/localization_loss': 0.022571921,\n",
            " 'Loss/regularization_loss': 0.1470536,\n",
            " 'Loss/total_loss': 0.4131714,\n",
            " 'learning_rate': 0.07999918}\n",
            "INFO:tensorflow:Step 1200 per-step time 0.101s\n",
            "I0924 15:54:05.728709 132668006404096 model_lib_v2.py:705] Step 1200 per-step time 0.101s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.26118588,\n",
            " 'Loss/localization_loss': 0.026760649,\n",
            " 'Loss/regularization_loss': 0.14634743,\n",
            " 'Loss/total_loss': 0.43429396,\n",
            " 'learning_rate': 0.079996705}\n",
            "I0924 15:54:05.728964 132668006404096 model_lib_v2.py:708] {'Loss/classification_loss': 0.26118588,\n",
            " 'Loss/localization_loss': 0.026760649,\n",
            " 'Loss/regularization_loss': 0.14634743,\n",
            " 'Loss/total_loss': 0.43429396,\n",
            " 'learning_rate': 0.079996705}\n",
            "INFO:tensorflow:Step 1300 per-step time 0.101s\n",
            "I0924 15:54:15.876864 132668006404096 model_lib_v2.py:705] Step 1300 per-step time 0.101s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.2547381,\n",
            " 'Loss/localization_loss': 0.011837809,\n",
            " 'Loss/regularization_loss': 0.14560543,\n",
            " 'Loss/total_loss': 0.41218132,\n",
            " 'learning_rate': 0.0799926}\n",
            "I0924 15:54:15.877171 132668006404096 model_lib_v2.py:708] {'Loss/classification_loss': 0.2547381,\n",
            " 'Loss/localization_loss': 0.011837809,\n",
            " 'Loss/regularization_loss': 0.14560543,\n",
            " 'Loss/total_loss': 0.41218132,\n",
            " 'learning_rate': 0.0799926}\n",
            "INFO:tensorflow:Step 1400 per-step time 0.101s\n",
            "I0924 15:54:25.939806 132668006404096 model_lib_v2.py:705] Step 1400 per-step time 0.101s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.20281595,\n",
            " 'Loss/localization_loss': 0.029261524,\n",
            " 'Loss/regularization_loss': 0.14493601,\n",
            " 'Loss/total_loss': 0.3770135,\n",
            " 'learning_rate': 0.07998685}\n",
            "I0924 15:54:25.940142 132668006404096 model_lib_v2.py:708] {'Loss/classification_loss': 0.20281595,\n",
            " 'Loss/localization_loss': 0.029261524,\n",
            " 'Loss/regularization_loss': 0.14493601,\n",
            " 'Loss/total_loss': 0.3770135,\n",
            " 'learning_rate': 0.07998685}\n",
            "INFO:tensorflow:Step 1500 per-step time 0.102s\n",
            "I0924 15:54:36.164564 132668006404096 model_lib_v2.py:705] Step 1500 per-step time 0.102s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.14750545,\n",
            " 'Loss/localization_loss': 0.027644452,\n",
            " 'Loss/regularization_loss': 0.14423074,\n",
            " 'Loss/total_loss': 0.31938064,\n",
            " 'learning_rate': 0.07997945}\n",
            "I0924 15:54:36.164833 132668006404096 model_lib_v2.py:708] {'Loss/classification_loss': 0.14750545,\n",
            " 'Loss/localization_loss': 0.027644452,\n",
            " 'Loss/regularization_loss': 0.14423074,\n",
            " 'Loss/total_loss': 0.31938064,\n",
            " 'learning_rate': 0.07997945}\n",
            "INFO:tensorflow:Step 1600 per-step time 0.101s\n",
            "I0924 15:54:46.272584 132668006404096 model_lib_v2.py:705] Step 1600 per-step time 0.101s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.16186725,\n",
            " 'Loss/localization_loss': 0.027209861,\n",
            " 'Loss/regularization_loss': 0.14350331,\n",
            " 'Loss/total_loss': 0.33258042,\n",
            " 'learning_rate': 0.079970405}\n",
            "I0924 15:54:46.272898 132668006404096 model_lib_v2.py:708] {'Loss/classification_loss': 0.16186725,\n",
            " 'Loss/localization_loss': 0.027209861,\n",
            " 'Loss/regularization_loss': 0.14350331,\n",
            " 'Loss/total_loss': 0.33258042,\n",
            " 'learning_rate': 0.079970405}\n",
            "INFO:tensorflow:Step 1700 per-step time 0.101s\n",
            "I0924 15:54:56.419953 132668006404096 model_lib_v2.py:705] Step 1700 per-step time 0.101s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.15283638,\n",
            " 'Loss/localization_loss': 0.06998802,\n",
            " 'Loss/regularization_loss': 0.14284746,\n",
            " 'Loss/total_loss': 0.36567187,\n",
            " 'learning_rate': 0.07995972}\n",
            "I0924 15:54:56.420238 132668006404096 model_lib_v2.py:708] {'Loss/classification_loss': 0.15283638,\n",
            " 'Loss/localization_loss': 0.06998802,\n",
            " 'Loss/regularization_loss': 0.14284746,\n",
            " 'Loss/total_loss': 0.36567187,\n",
            " 'learning_rate': 0.07995972}\n",
            "INFO:tensorflow:Step 1800 per-step time 0.101s\n",
            "I0924 15:55:06.529132 132668006404096 model_lib_v2.py:705] Step 1800 per-step time 0.101s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.24914889,\n",
            " 'Loss/localization_loss': 0.014464679,\n",
            " 'Loss/regularization_loss': 0.14216548,\n",
            " 'Loss/total_loss': 0.40577906,\n",
            " 'learning_rate': 0.0799474}\n",
            "I0924 15:55:06.529387 132668006404096 model_lib_v2.py:708] {'Loss/classification_loss': 0.24914889,\n",
            " 'Loss/localization_loss': 0.014464679,\n",
            " 'Loss/regularization_loss': 0.14216548,\n",
            " 'Loss/total_loss': 0.40577906,\n",
            " 'learning_rate': 0.0799474}\n",
            "INFO:tensorflow:Step 1900 per-step time 0.102s\n",
            "I0924 15:55:16.697849 132668006404096 model_lib_v2.py:705] Step 1900 per-step time 0.102s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.25303218,\n",
            " 'Loss/localization_loss': 0.011101937,\n",
            " 'Loss/regularization_loss': 0.14148663,\n",
            " 'Loss/total_loss': 0.40562075,\n",
            " 'learning_rate': 0.07993342}\n",
            "I0924 15:55:16.698114 132668006404096 model_lib_v2.py:708] {'Loss/classification_loss': 0.25303218,\n",
            " 'Loss/localization_loss': 0.011101937,\n",
            " 'Loss/regularization_loss': 0.14148663,\n",
            " 'Loss/total_loss': 0.40562075,\n",
            " 'learning_rate': 0.07993342}\n",
            "INFO:tensorflow:Step 2000 per-step time 0.101s\n",
            "I0924 15:55:26.833517 132668006404096 model_lib_v2.py:705] Step 2000 per-step time 0.101s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.17924619,\n",
            " 'Loss/localization_loss': 0.024037473,\n",
            " 'Loss/regularization_loss': 0.14081757,\n",
            " 'Loss/total_loss': 0.34410125,\n",
            " 'learning_rate': 0.07991781}\n",
            "I0924 15:55:26.833820 132668006404096 model_lib_v2.py:708] {'Loss/classification_loss': 0.17924619,\n",
            " 'Loss/localization_loss': 0.024037473,\n",
            " 'Loss/regularization_loss': 0.14081757,\n",
            " 'Loss/total_loss': 0.34410125,\n",
            " 'learning_rate': 0.07991781}\n",
            "INFO:tensorflow:Step 2100 per-step time 0.112s\n",
            "I0924 15:55:38.001348 132668006404096 model_lib_v2.py:705] Step 2100 per-step time 0.112s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.21419282,\n",
            " 'Loss/localization_loss': 0.03562589,\n",
            " 'Loss/regularization_loss': 0.14011776,\n",
            " 'Loss/total_loss': 0.38993648,\n",
            " 'learning_rate': 0.07990056}\n",
            "I0924 15:55:38.001624 132668006404096 model_lib_v2.py:708] {'Loss/classification_loss': 0.21419282,\n",
            " 'Loss/localization_loss': 0.03562589,\n",
            " 'Loss/regularization_loss': 0.14011776,\n",
            " 'Loss/total_loss': 0.38993648,\n",
            " 'learning_rate': 0.07990056}\n",
            "INFO:tensorflow:Step 2200 per-step time 0.102s\n",
            "I0924 15:55:48.171380 132668006404096 model_lib_v2.py:705] Step 2200 per-step time 0.102s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.2600583,\n",
            " 'Loss/localization_loss': 0.04321707,\n",
            " 'Loss/regularization_loss': 0.13942876,\n",
            " 'Loss/total_loss': 0.44270414,\n",
            " 'learning_rate': 0.07988167}\n",
            "I0924 15:55:48.171646 132668006404096 model_lib_v2.py:708] {'Loss/classification_loss': 0.2600583,\n",
            " 'Loss/localization_loss': 0.04321707,\n",
            " 'Loss/regularization_loss': 0.13942876,\n",
            " 'Loss/total_loss': 0.44270414,\n",
            " 'learning_rate': 0.07988167}\n",
            "INFO:tensorflow:Step 2300 per-step time 0.101s\n",
            "I0924 15:55:58.255095 132668006404096 model_lib_v2.py:705] Step 2300 per-step time 0.101s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.14779904,\n",
            " 'Loss/localization_loss': 0.020404221,\n",
            " 'Loss/regularization_loss': 0.13883768,\n",
            " 'Loss/total_loss': 0.30704093,\n",
            " 'learning_rate': 0.07986114}\n",
            "I0924 15:55:58.255375 132668006404096 model_lib_v2.py:708] {'Loss/classification_loss': 0.14779904,\n",
            " 'Loss/localization_loss': 0.020404221,\n",
            " 'Loss/regularization_loss': 0.13883768,\n",
            " 'Loss/total_loss': 0.30704093,\n",
            " 'learning_rate': 0.07986114}\n",
            "INFO:tensorflow:Step 2400 per-step time 0.101s\n",
            "I0924 15:56:08.368764 132668006404096 model_lib_v2.py:705] Step 2400 per-step time 0.101s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.13483053,\n",
            " 'Loss/localization_loss': 0.023525903,\n",
            " 'Loss/regularization_loss': 0.13815829,\n",
            " 'Loss/total_loss': 0.29651475,\n",
            " 'learning_rate': 0.07983897}\n",
            "I0924 15:56:08.369042 132668006404096 model_lib_v2.py:708] {'Loss/classification_loss': 0.13483053,\n",
            " 'Loss/localization_loss': 0.023525903,\n",
            " 'Loss/regularization_loss': 0.13815829,\n",
            " 'Loss/total_loss': 0.29651475,\n",
            " 'learning_rate': 0.07983897}\n",
            "INFO:tensorflow:Step 2500 per-step time 0.101s\n",
            "I0924 15:56:18.475398 132668006404096 model_lib_v2.py:705] Step 2500 per-step time 0.101s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.18547659,\n",
            " 'Loss/localization_loss': 0.026836528,\n",
            " 'Loss/regularization_loss': 0.13760054,\n",
            " 'Loss/total_loss': 0.34991366,\n",
            " 'learning_rate': 0.079815164}\n",
            "I0924 15:56:18.475721 132668006404096 model_lib_v2.py:708] {'Loss/classification_loss': 0.18547659,\n",
            " 'Loss/localization_loss': 0.026836528,\n",
            " 'Loss/regularization_loss': 0.13760054,\n",
            " 'Loss/total_loss': 0.34991366,\n",
            " 'learning_rate': 0.079815164}\n",
            "INFO:tensorflow:Step 2600 per-step time 0.101s\n",
            "I0924 15:56:28.609092 132668006404096 model_lib_v2.py:705] Step 2600 per-step time 0.101s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.16138707,\n",
            " 'Loss/localization_loss': 0.01779682,\n",
            " 'Loss/regularization_loss': 0.13699992,\n",
            " 'Loss/total_loss': 0.3161838,\n",
            " 'learning_rate': 0.07978972}\n",
            "I0924 15:56:28.609351 132668006404096 model_lib_v2.py:708] {'Loss/classification_loss': 0.16138707,\n",
            " 'Loss/localization_loss': 0.01779682,\n",
            " 'Loss/regularization_loss': 0.13699992,\n",
            " 'Loss/total_loss': 0.3161838,\n",
            " 'learning_rate': 0.07978972}\n",
            "INFO:tensorflow:Step 2700 per-step time 0.102s\n",
            "I0924 15:56:38.761330 132668006404096 model_lib_v2.py:705] Step 2700 per-step time 0.102s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.1315554,\n",
            " 'Loss/localization_loss': 0.013721809,\n",
            " 'Loss/regularization_loss': 0.13635384,\n",
            " 'Loss/total_loss': 0.28163105,\n",
            " 'learning_rate': 0.07976264}\n",
            "I0924 15:56:38.761595 132668006404096 model_lib_v2.py:708] {'Loss/classification_loss': 0.1315554,\n",
            " 'Loss/localization_loss': 0.013721809,\n",
            " 'Loss/regularization_loss': 0.13635384,\n",
            " 'Loss/total_loss': 0.28163105,\n",
            " 'learning_rate': 0.07976264}\n",
            "INFO:tensorflow:Step 2800 per-step time 0.101s\n",
            "I0924 15:56:48.900781 132668006404096 model_lib_v2.py:705] Step 2800 per-step time 0.101s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.15628254,\n",
            " 'Loss/localization_loss': 0.021934181,\n",
            " 'Loss/regularization_loss': 0.13575342,\n",
            " 'Loss/total_loss': 0.31397015,\n",
            " 'learning_rate': 0.07973392}\n",
            "I0924 15:56:48.901052 132668006404096 model_lib_v2.py:708] {'Loss/classification_loss': 0.15628254,\n",
            " 'Loss/localization_loss': 0.021934181,\n",
            " 'Loss/regularization_loss': 0.13575342,\n",
            " 'Loss/total_loss': 0.31397015,\n",
            " 'learning_rate': 0.07973392}\n",
            "INFO:tensorflow:Step 2900 per-step time 0.101s\n",
            "I0924 15:56:59.049769 132668006404096 model_lib_v2.py:705] Step 2900 per-step time 0.101s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.14400649,\n",
            " 'Loss/localization_loss': 0.031780105,\n",
            " 'Loss/regularization_loss': 0.13516293,\n",
            " 'Loss/total_loss': 0.31094953,\n",
            " 'learning_rate': 0.07970358}\n",
            "I0924 15:56:59.050058 132668006404096 model_lib_v2.py:708] {'Loss/classification_loss': 0.14400649,\n",
            " 'Loss/localization_loss': 0.031780105,\n",
            " 'Loss/regularization_loss': 0.13516293,\n",
            " 'Loss/total_loss': 0.31094953,\n",
            " 'learning_rate': 0.07970358}\n",
            "INFO:tensorflow:Step 3000 per-step time 0.102s\n",
            "I0924 15:57:09.264704 132668006404096 model_lib_v2.py:705] Step 3000 per-step time 0.102s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.15036215,\n",
            " 'Loss/localization_loss': 0.018138623,\n",
            " 'Loss/regularization_loss': 0.13453506,\n",
            " 'Loss/total_loss': 0.30303583,\n",
            " 'learning_rate': 0.0796716}\n",
            "I0924 15:57:09.265001 132668006404096 model_lib_v2.py:708] {'Loss/classification_loss': 0.15036215,\n",
            " 'Loss/localization_loss': 0.018138623,\n",
            " 'Loss/regularization_loss': 0.13453506,\n",
            " 'Loss/total_loss': 0.30303583,\n",
            " 'learning_rate': 0.0796716}\n",
            "INFO:tensorflow:Step 3100 per-step time 0.111s\n",
            "I0924 15:57:20.377722 132668006404096 model_lib_v2.py:705] Step 3100 per-step time 0.111s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.20264079,\n",
            " 'Loss/localization_loss': 0.01491311,\n",
            " 'Loss/regularization_loss': 0.13394402,\n",
            " 'Loss/total_loss': 0.35149792,\n",
            " 'learning_rate': 0.07963799}\n",
            "I0924 15:57:20.377988 132668006404096 model_lib_v2.py:708] {'Loss/classification_loss': 0.20264079,\n",
            " 'Loss/localization_loss': 0.01491311,\n",
            " 'Loss/regularization_loss': 0.13394402,\n",
            " 'Loss/total_loss': 0.35149792,\n",
            " 'learning_rate': 0.07963799}\n",
            "INFO:tensorflow:Step 3200 per-step time 0.101s\n",
            "I0924 15:57:30.473921 132668006404096 model_lib_v2.py:705] Step 3200 per-step time 0.101s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.22858462,\n",
            " 'Loss/localization_loss': 0.0431545,\n",
            " 'Loss/regularization_loss': 0.13332942,\n",
            " 'Loss/total_loss': 0.40506855,\n",
            " 'learning_rate': 0.07960275}\n",
            "I0924 15:57:30.474226 132668006404096 model_lib_v2.py:708] {'Loss/classification_loss': 0.22858462,\n",
            " 'Loss/localization_loss': 0.0431545,\n",
            " 'Loss/regularization_loss': 0.13332942,\n",
            " 'Loss/total_loss': 0.40506855,\n",
            " 'learning_rate': 0.07960275}\n",
            "INFO:tensorflow:Step 3300 per-step time 0.101s\n",
            "I0924 15:57:40.556206 132668006404096 model_lib_v2.py:705] Step 3300 per-step time 0.101s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.19183496,\n",
            " 'Loss/localization_loss': 0.01568552,\n",
            " 'Loss/regularization_loss': 0.13273495,\n",
            " 'Loss/total_loss': 0.34025544,\n",
            " 'learning_rate': 0.07956588}\n",
            "I0924 15:57:40.556461 132668006404096 model_lib_v2.py:708] {'Loss/classification_loss': 0.19183496,\n",
            " 'Loss/localization_loss': 0.01568552,\n",
            " 'Loss/regularization_loss': 0.13273495,\n",
            " 'Loss/total_loss': 0.34025544,\n",
            " 'learning_rate': 0.07956588}\n",
            "INFO:tensorflow:Step 3400 per-step time 0.101s\n",
            "I0924 15:57:50.643783 132668006404096 model_lib_v2.py:705] Step 3400 per-step time 0.101s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.13576695,\n",
            " 'Loss/localization_loss': 0.015021314,\n",
            " 'Loss/regularization_loss': 0.13221142,\n",
            " 'Loss/total_loss': 0.2829997,\n",
            " 'learning_rate': 0.079527386}\n",
            "I0924 15:57:50.644054 132668006404096 model_lib_v2.py:708] {'Loss/classification_loss': 0.13576695,\n",
            " 'Loss/localization_loss': 0.015021314,\n",
            " 'Loss/regularization_loss': 0.13221142,\n",
            " 'Loss/total_loss': 0.2829997,\n",
            " 'learning_rate': 0.079527386}\n",
            "INFO:tensorflow:Step 3500 per-step time 0.101s\n",
            "I0924 15:58:00.722131 132668006404096 model_lib_v2.py:705] Step 3500 per-step time 0.101s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.17766902,\n",
            " 'Loss/localization_loss': 0.014183876,\n",
            " 'Loss/regularization_loss': 0.13172476,\n",
            " 'Loss/total_loss': 0.32357764,\n",
            " 'learning_rate': 0.07948727}\n",
            "I0924 15:58:00.722393 132668006404096 model_lib_v2.py:708] {'Loss/classification_loss': 0.17766902,\n",
            " 'Loss/localization_loss': 0.014183876,\n",
            " 'Loss/regularization_loss': 0.13172476,\n",
            " 'Loss/total_loss': 0.32357764,\n",
            " 'learning_rate': 0.07948727}\n",
            "INFO:tensorflow:Step 3600 per-step time 0.101s\n",
            "I0924 15:58:10.863257 132668006404096 model_lib_v2.py:705] Step 3600 per-step time 0.101s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.15340525,\n",
            " 'Loss/localization_loss': 0.022181321,\n",
            " 'Loss/regularization_loss': 0.1311899,\n",
            " 'Loss/total_loss': 0.30677646,\n",
            " 'learning_rate': 0.079445526}\n",
            "I0924 15:58:10.863515 132668006404096 model_lib_v2.py:708] {'Loss/classification_loss': 0.15340525,\n",
            " 'Loss/localization_loss': 0.022181321,\n",
            " 'Loss/regularization_loss': 0.1311899,\n",
            " 'Loss/total_loss': 0.30677646,\n",
            " 'learning_rate': 0.079445526}\n",
            "INFO:tensorflow:Step 3700 per-step time 0.101s\n",
            "I0924 15:58:20.937314 132668006404096 model_lib_v2.py:705] Step 3700 per-step time 0.101s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.15822148,\n",
            " 'Loss/localization_loss': 0.016907979,\n",
            " 'Loss/regularization_loss': 0.13063502,\n",
            " 'Loss/total_loss': 0.3057645,\n",
            " 'learning_rate': 0.07940216}\n",
            "I0924 15:58:20.937600 132668006404096 model_lib_v2.py:708] {'Loss/classification_loss': 0.15822148,\n",
            " 'Loss/localization_loss': 0.016907979,\n",
            " 'Loss/regularization_loss': 0.13063502,\n",
            " 'Loss/total_loss': 0.3057645,\n",
            " 'learning_rate': 0.07940216}\n",
            "INFO:tensorflow:Step 3800 per-step time 0.102s\n",
            "I0924 15:58:31.093062 132668006404096 model_lib_v2.py:705] Step 3800 per-step time 0.102s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.109872885,\n",
            " 'Loss/localization_loss': 0.019479813,\n",
            " 'Loss/regularization_loss': 0.13010307,\n",
            " 'Loss/total_loss': 0.25945577,\n",
            " 'learning_rate': 0.079357184}\n",
            "I0924 15:58:31.093366 132668006404096 model_lib_v2.py:708] {'Loss/classification_loss': 0.109872885,\n",
            " 'Loss/localization_loss': 0.019479813,\n",
            " 'Loss/regularization_loss': 0.13010307,\n",
            " 'Loss/total_loss': 0.25945577,\n",
            " 'learning_rate': 0.079357184}\n",
            "INFO:tensorflow:Step 3900 per-step time 0.101s\n",
            "I0924 15:58:41.217324 132668006404096 model_lib_v2.py:705] Step 3900 per-step time 0.101s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.15182716,\n",
            " 'Loss/localization_loss': 0.030883634,\n",
            " 'Loss/regularization_loss': 0.12955713,\n",
            " 'Loss/total_loss': 0.31226793,\n",
            " 'learning_rate': 0.07931058}\n",
            "I0924 15:58:41.217643 132668006404096 model_lib_v2.py:708] {'Loss/classification_loss': 0.15182716,\n",
            " 'Loss/localization_loss': 0.030883634,\n",
            " 'Loss/regularization_loss': 0.12955713,\n",
            " 'Loss/total_loss': 0.31226793,\n",
            " 'learning_rate': 0.07931058}\n",
            "INFO:tensorflow:Step 4000 per-step time 0.102s\n",
            "I0924 15:58:51.373111 132668006404096 model_lib_v2.py:705] Step 4000 per-step time 0.102s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.3282867,\n",
            " 'Loss/localization_loss': 0.08168734,\n",
            " 'Loss/regularization_loss': 0.12910211,\n",
            " 'Loss/total_loss': 0.53907615,\n",
            " 'learning_rate': 0.07926236}\n",
            "I0924 15:58:51.373387 132668006404096 model_lib_v2.py:708] {'Loss/classification_loss': 0.3282867,\n",
            " 'Loss/localization_loss': 0.08168734,\n",
            " 'Loss/regularization_loss': 0.12910211,\n",
            " 'Loss/total_loss': 0.53907615,\n",
            " 'learning_rate': 0.07926236}\n",
            "INFO:tensorflow:Step 4100 per-step time 0.116s\n",
            "I0924 15:59:02.935058 132668006404096 model_lib_v2.py:705] Step 4100 per-step time 0.116s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.0837214,\n",
            " 'Loss/localization_loss': 0.026907554,\n",
            " 'Loss/regularization_loss': 0.12855397,\n",
            " 'Loss/total_loss': 0.23918292,\n",
            " 'learning_rate': 0.07921253}\n",
            "I0924 15:59:02.935371 132668006404096 model_lib_v2.py:708] {'Loss/classification_loss': 0.0837214,\n",
            " 'Loss/localization_loss': 0.026907554,\n",
            " 'Loss/regularization_loss': 0.12855397,\n",
            " 'Loss/total_loss': 0.23918292,\n",
            " 'learning_rate': 0.07921253}\n",
            "INFO:tensorflow:Step 4200 per-step time 0.101s\n",
            "I0924 15:59:13.020276 132668006404096 model_lib_v2.py:705] Step 4200 per-step time 0.101s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.13223551,\n",
            " 'Loss/localization_loss': 0.022467032,\n",
            " 'Loss/regularization_loss': 0.12811776,\n",
            " 'Loss/total_loss': 0.28282028,\n",
            " 'learning_rate': 0.07916109}\n",
            "I0924 15:59:13.020557 132668006404096 model_lib_v2.py:708] {'Loss/classification_loss': 0.13223551,\n",
            " 'Loss/localization_loss': 0.022467032,\n",
            " 'Loss/regularization_loss': 0.12811776,\n",
            " 'Loss/total_loss': 0.28282028,\n",
            " 'learning_rate': 0.07916109}\n",
            "INFO:tensorflow:Step 4300 per-step time 0.101s\n",
            "I0924 15:59:23.131055 132668006404096 model_lib_v2.py:705] Step 4300 per-step time 0.101s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.09790647,\n",
            " 'Loss/localization_loss': 0.021881724,\n",
            " 'Loss/regularization_loss': 0.12751547,\n",
            " 'Loss/total_loss': 0.24730366,\n",
            " 'learning_rate': 0.07910804}\n",
            "I0924 15:59:23.131373 132668006404096 model_lib_v2.py:708] {'Loss/classification_loss': 0.09790647,\n",
            " 'Loss/localization_loss': 0.021881724,\n",
            " 'Loss/regularization_loss': 0.12751547,\n",
            " 'Loss/total_loss': 0.24730366,\n",
            " 'learning_rate': 0.07910804}\n",
            "INFO:tensorflow:Step 4400 per-step time 0.101s\n",
            "I0924 15:59:33.235503 132668006404096 model_lib_v2.py:705] Step 4400 per-step time 0.101s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.09417289,\n",
            " 'Loss/localization_loss': 0.015419242,\n",
            " 'Loss/regularization_loss': 0.12697524,\n",
            " 'Loss/total_loss': 0.23656738,\n",
            " 'learning_rate': 0.07905338}\n",
            "I0924 15:59:33.235830 132668006404096 model_lib_v2.py:708] {'Loss/classification_loss': 0.09417289,\n",
            " 'Loss/localization_loss': 0.015419242,\n",
            " 'Loss/regularization_loss': 0.12697524,\n",
            " 'Loss/total_loss': 0.23656738,\n",
            " 'learning_rate': 0.07905338}\n",
            "INFO:tensorflow:Step 4500 per-step time 0.102s\n",
            "I0924 15:59:43.423773 132668006404096 model_lib_v2.py:705] Step 4500 per-step time 0.102s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.1536507,\n",
            " 'Loss/localization_loss': 0.01418276,\n",
            " 'Loss/regularization_loss': 0.1264743,\n",
            " 'Loss/total_loss': 0.29430777,\n",
            " 'learning_rate': 0.07899711}\n",
            "I0924 15:59:43.424084 132668006404096 model_lib_v2.py:708] {'Loss/classification_loss': 0.1536507,\n",
            " 'Loss/localization_loss': 0.01418276,\n",
            " 'Loss/regularization_loss': 0.1264743,\n",
            " 'Loss/total_loss': 0.29430777,\n",
            " 'learning_rate': 0.07899711}\n",
            "INFO:tensorflow:Step 4600 per-step time 0.101s\n",
            "I0924 15:59:53.537318 132668006404096 model_lib_v2.py:705] Step 4600 per-step time 0.101s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.11631124,\n",
            " 'Loss/localization_loss': 0.012281978,\n",
            " 'Loss/regularization_loss': 0.12603599,\n",
            " 'Loss/total_loss': 0.2546292,\n",
            " 'learning_rate': 0.078939244}\n",
            "I0924 15:59:53.537608 132668006404096 model_lib_v2.py:708] {'Loss/classification_loss': 0.11631124,\n",
            " 'Loss/localization_loss': 0.012281978,\n",
            " 'Loss/regularization_loss': 0.12603599,\n",
            " 'Loss/total_loss': 0.2546292,\n",
            " 'learning_rate': 0.078939244}\n",
            "INFO:tensorflow:Step 4700 per-step time 0.101s\n",
            "I0924 16:00:03.674024 132668006404096 model_lib_v2.py:705] Step 4700 per-step time 0.101s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.22034375,\n",
            " 'Loss/localization_loss': 0.01972238,\n",
            " 'Loss/regularization_loss': 0.1255671,\n",
            " 'Loss/total_loss': 0.36563325,\n",
            " 'learning_rate': 0.07887978}\n",
            "I0924 16:00:03.674289 132668006404096 model_lib_v2.py:708] {'Loss/classification_loss': 0.22034375,\n",
            " 'Loss/localization_loss': 0.01972238,\n",
            " 'Loss/regularization_loss': 0.1255671,\n",
            " 'Loss/total_loss': 0.36563325,\n",
            " 'learning_rate': 0.07887978}\n",
            "INFO:tensorflow:Step 4800 per-step time 0.102s\n",
            "I0924 16:00:13.850349 132668006404096 model_lib_v2.py:705] Step 4800 per-step time 0.102s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.15372542,\n",
            " 'Loss/localization_loss': 0.010622928,\n",
            " 'Loss/regularization_loss': 0.12514485,\n",
            " 'Loss/total_loss': 0.2894932,\n",
            " 'learning_rate': 0.07881871}\n",
            "I0924 16:00:13.850659 132668006404096 model_lib_v2.py:708] {'Loss/classification_loss': 0.15372542,\n",
            " 'Loss/localization_loss': 0.010622928,\n",
            " 'Loss/regularization_loss': 0.12514485,\n",
            " 'Loss/total_loss': 0.2894932,\n",
            " 'learning_rate': 0.07881871}\n",
            "INFO:tensorflow:Step 4900 per-step time 0.101s\n",
            "I0924 16:00:23.943695 132668006404096 model_lib_v2.py:705] Step 4900 per-step time 0.101s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.44919628,\n",
            " 'Loss/localization_loss': 0.01221176,\n",
            " 'Loss/regularization_loss': 0.124683104,\n",
            " 'Loss/total_loss': 0.58609116,\n",
            " 'learning_rate': 0.07875605}\n",
            "I0924 16:00:23.944014 132668006404096 model_lib_v2.py:708] {'Loss/classification_loss': 0.44919628,\n",
            " 'Loss/localization_loss': 0.01221176,\n",
            " 'Loss/regularization_loss': 0.124683104,\n",
            " 'Loss/total_loss': 0.58609116,\n",
            " 'learning_rate': 0.07875605}\n",
            "INFO:tensorflow:Step 5000 per-step time 0.102s\n",
            "I0924 16:00:34.145441 132668006404096 model_lib_v2.py:705] Step 5000 per-step time 0.102s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.20849621,\n",
            " 'Loss/localization_loss': 0.011969065,\n",
            " 'Loss/regularization_loss': 0.124153,\n",
            " 'Loss/total_loss': 0.34461826,\n",
            " 'learning_rate': 0.078691795}\n",
            "I0924 16:00:34.145725 132668006404096 model_lib_v2.py:708] {'Loss/classification_loss': 0.20849621,\n",
            " 'Loss/localization_loss': 0.011969065,\n",
            " 'Loss/regularization_loss': 0.124153,\n",
            " 'Loss/total_loss': 0.34461826,\n",
            " 'learning_rate': 0.078691795}\n"
          ]
        }
      ],
      "source": [
        "!{command}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4_YRZu7npfDH"
      },
      "source": [
        "# 7. Evaluate the Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "80L7-fdPpfDH"
      },
      "outputs": [],
      "source": [
        "command = \"python {} --model_dir={} --pipeline_config_path={} --checkpoint_dir={}\".format(TRAINING_SCRIPT, paths['CHECKPOINT_PATH'],files['PIPELINE_CONFIG'], paths['CHECKPOINT_PATH'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lYsgEPx9pfDH"
      },
      "outputs": [],
      "source": [
        "print(command)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lqTV2jGBpfDH",
        "outputId": "f91bff45-d66a-42ab-bf15-61d1cf6eb374",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-09-24 16:01:27.430422: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "WARNING:tensorflow:Forced number of epochs for all eval validations to be 1.\n",
            "W0924 16:01:29.880600 132762326507520 model_lib_v2.py:1089] Forced number of epochs for all eval validations to be 1.\n",
            "INFO:tensorflow:Maybe overwriting sample_1_of_n_eval_examples: None\n",
            "I0924 16:01:29.880804 132762326507520 config_util.py:552] Maybe overwriting sample_1_of_n_eval_examples: None\n",
            "INFO:tensorflow:Maybe overwriting use_bfloat16: False\n",
            "I0924 16:01:29.880864 132762326507520 config_util.py:552] Maybe overwriting use_bfloat16: False\n",
            "INFO:tensorflow:Maybe overwriting eval_num_epochs: 1\n",
            "I0924 16:01:29.880920 132762326507520 config_util.py:552] Maybe overwriting eval_num_epochs: 1\n",
            "WARNING:tensorflow:Expected number of evaluation epochs is 1, but instead encountered `eval_on_train_input_config.num_epochs` = 0. Overwriting `num_epochs` to 1.\n",
            "W0924 16:01:29.880994 132762326507520 model_lib_v2.py:1106] Expected number of evaluation epochs is 1, but instead encountered `eval_on_train_input_config.num_epochs` = 0. Overwriting `num_epochs` to 1.\n",
            "2023-09-24 16:01:30.887922: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:47] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "INFO:tensorflow:Reading unweighted datasets: ['Tensorflow/workspace/annotations/test.record']\n",
            "I0924 16:01:31.100347 132762326507520 dataset_builder.py:162] Reading unweighted datasets: ['Tensorflow/workspace/annotations/test.record']\n",
            "INFO:tensorflow:Reading record datasets for input file: ['Tensorflow/workspace/annotations/test.record']\n",
            "I0924 16:01:31.100558 132762326507520 dataset_builder.py:79] Reading record datasets for input file: ['Tensorflow/workspace/annotations/test.record']\n",
            "INFO:tensorflow:Number of filenames to read: 1\n",
            "I0924 16:01:31.100624 132762326507520 dataset_builder.py:80] Number of filenames to read: 1\n",
            "WARNING:tensorflow:num_readers has been reduced to 1 to match input file shards.\n",
            "W0924 16:01:31.100675 132762326507520 dataset_builder.py:86] num_readers has been reduced to 1 to match input file shards.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.10/dist-packages/object_detection/builders/dataset_builder.py:100: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.deterministic`.\n",
            "W0924 16:01:31.104366 132762326507520 deprecation.py:364] From /usr/local/lib/python3.10/dist-packages/object_detection/builders/dataset_builder.py:100: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.deterministic`.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.10/dist-packages/object_detection/builders/dataset_builder.py:235: DatasetV1.map_with_legacy_function (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.map()\n",
            "W0924 16:01:31.123369 132762326507520 deprecation.py:364] From /usr/local/lib/python3.10/dist-packages/object_detection/builders/dataset_builder.py:235: DatasetV1.map_with_legacy_function (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.map()\n"
          ]
        }
      ],
      "source": [
        "!{command}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "orvRk02UpfDI"
      },
      "source": [
        "# 8. Load Train Model From Checkpoint"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8TYk4_oIpfDI"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import tensorflow as tf\n",
        "from object_detection.utils import label_map_util\n",
        "from object_detection.builders import model_builder\n",
        "from object_detection.utils import config_util"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tDnQg-cYpfDI"
      },
      "outputs": [],
      "source": [
        "# Load pipeline config and build a detection model\n",
        "configs = config_util.get_configs_from_pipeline_file(files['PIPELINE_CONFIG'])\n",
        "detection_model = model_builder.build(model_config=configs['model'], is_training=False)\n",
        "\n",
        "# Restore checkpoint\n",
        "ckpt = tf.compat.v2.train.Checkpoint(model=detection_model)\n",
        "ckpt.restore(os.path.join(paths['CHECKPOINT_PATH'], 'ckpt-6')).expect_partial()\n",
        "\n",
        "@tf.function\n",
        "def detect_fn(image):\n",
        "    image, shapes = detection_model.preprocess(image)\n",
        "    prediction_dict = detection_model.predict(image, shapes)\n",
        "    detections = detection_model.postprocess(prediction_dict, shapes)\n",
        "    return detections"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0EmsmbBZpfDI"
      },
      "source": [
        "# 9. Detect from an Image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y_MKiuZ4pfDI"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "from matplotlib import pyplot as plt\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cBDbIhNapfDI"
      },
      "outputs": [],
      "source": [
        "category_index = label_map_util.create_category_index_from_labelmap(files['LABELMAP'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Lx3crOhOzITB"
      },
      "outputs": [],
      "source": [
        "IMAGE_PATH = os.path.join(paths['IMAGE_PATH'], 'train', 'BrokenBig-10-_bmp.rf.889d5780aa1c7e6ed1c837a23f7bd76a.jpg')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://freefontsdownload.net/download/160187/arial.zip\n",
        "!unzip arial.zip -d ."
      ],
      "metadata": {
        "id": "djJVE1r0f71y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Tpzn1SMry1yK"
      },
      "outputs": [],
      "source": [
        "from object_detection.utils import visualization_utils as viz_utils\n",
        "\n",
        "img = cv2.imread(IMAGE_PATH)\n",
        "\n",
        "image_np = np.array(img)\n",
        "\n",
        "input_tensor = tf.convert_to_tensor(np.expand_dims(image_np, 0), dtype=tf.float32)\n",
        "detections = detect_fn(input_tensor)\n",
        "\n",
        "num_detections = int(detections.pop('num_detections'))\n",
        "detections = {key: value[0, :num_detections].numpy()\n",
        "              for key, value in detections.items()}\n",
        "detections['num_detections'] = num_detections\n",
        "\n",
        "# detection_classes should be ints.\n",
        "detections['detection_classes'] = detections['detection_classes'].astype(np.int64)\n",
        "\n",
        "label_id_offset = 1\n",
        "image_np_with_detections = image_np.copy()\n",
        "\n",
        "viz_utils.visualize_boxes_and_labels_on_image_array(\n",
        "            image_np_with_detections,\n",
        "            detections['detection_boxes'],\n",
        "            detections['detection_classes']+label_id_offset,\n",
        "            detections['detection_scores'],\n",
        "            category_index,\n",
        "            use_normalized_coordinates=True,\n",
        "            max_boxes_to_draw=5,\n",
        "            agnostic_mode=False,\n",
        "            line_thickness=8,\n",
        "            min_score_thresh=0.4)\n",
        "\n",
        "plt.imshow(cv2.cvtColor(image_np_with_detections, cv2.COLOR_BGR2RGB))\n",
        "plt.show()\n",
        "\n",
        "print(f\"Detected class: {detections['detection_classes'][0]}\\nConfidence level: {detections['detection_scores'][0] * 100}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IsNAaYAo0WVL"
      },
      "source": [
        "# Real Time Detections from your Webcam"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fc-GpMbcajWa"
      },
      "outputs": [],
      "source": [
        "!pip uninstall opencv-python-headless -y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o_grs6OGpfDJ"
      },
      "outputs": [],
      "source": [
        "cap = cv2.VideoCapture(0)\n",
        "width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
        "height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "\n",
        "while cap.isOpened():\n",
        "    ret, frame = cap.read()\n",
        "    image_np = np.array(frame)\n",
        "\n",
        "    input_tensor = tf.convert_to_tensor(np.expand_dims(image_np, 0), dtype=tf.float32)\n",
        "    detections = detect_fn(input_tensor)\n",
        "\n",
        "    num_detections = int(detections.pop('num_detections'))\n",
        "    detections = {key: value[0, :num_detections].numpy()\n",
        "                  for key, value in detections.items()}\n",
        "    detections['num_detections'] = num_detections\n",
        "\n",
        "    # detection_classes should be ints.\n",
        "    detections['detection_classes'] = detections['detection_classes'].astype(np.int64)\n",
        "\n",
        "    label_id_offset = 1\n",
        "    image_np_with_detections = image_np.copy()\n",
        "\n",
        "    viz_utils.visualize_boxes_and_labels_on_image_array(\n",
        "                image_np_with_detections,\n",
        "                detections['detection_boxes'],\n",
        "                detections['detection_classes']+label_id_offset,\n",
        "                detections['detection_scores'],\n",
        "                category_index,\n",
        "                use_normalized_coordinates=True,\n",
        "                max_boxes_to_draw=5,\n",
        "                agnostic_mode=False)\n",
        "\n",
        "    cv2.imshow('object detection',  cv2.resize(image_np_with_detections, (800, 600)))\n",
        "\n",
        "    if cv2.waitKey(10) & 0xFF == ord('q'):\n",
        "        cap.release()\n",
        "        cv2.destroyAllWindows()\n",
        "        break"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rzlM4jt0pfDJ"
      },
      "source": [
        "# 10. Freezing the Graph"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n4olHB2npfDJ"
      },
      "outputs": [],
      "source": [
        "FREEZE_SCRIPT = os.path.join(paths['APIMODEL_PATH'], 'research', 'object_detection', 'exporter_main_v2.py ')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0AjO93QDpfDJ"
      },
      "outputs": [],
      "source": [
        "command = \"python {} --input_type=image_tensor --pipeline_config_path={} --trained_checkpoint_dir={} --output_directory={}\".format(FREEZE_SCRIPT ,files['PIPELINE_CONFIG'], paths['CHECKPOINT_PATH'], paths['OUTPUT_PATH'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F6Lsp3tCpfDJ"
      },
      "outputs": [],
      "source": [
        "print(command)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1Sw1ULgHpfDJ"
      },
      "outputs": [],
      "source": [
        "!{command}"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Confusion matrix"
      ],
      "metadata": {
        "id": "1nxowqRCbHet"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "INFERENCE_GRAPH_SCRIPT = os.path.join(paths['APIMODEL_PATH'], 'research', 'object_detection','export_inference_graph.py')"
      ],
      "metadata": {
        "id": "09PFfiH4TORw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "command = \"python {} --input_type=image_tensor --pipeline_config_path={} --trained_checkpoint_prefix={} --output_directory={}\".format(INFERENCE_GRAPH_SCRIPT, files['PIPELINE_CONFIG'], os.path.join(paths['CHECKPOINT_PATH'], 'ckpt-6'), paths['INFERENCE_PATH'])"
      ],
      "metadata": {
        "id": "9v5MeKUdTn8n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!{command}"
      ],
      "metadata": {
        "id": "bOEFpXYRVNgg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "INFERENCE_SCRIPT = os.path.join(paths['APIMODEL_PATH'], 'research', 'object_detection','inference', 'infer_detections.py ')"
      ],
      "metadata": {
        "id": "UI4iwgNda-jV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "command = \"python {} --input_tfrecord_paths={},{} --output_tfrecord_path={} --inference_graph={}\".format(INFERENCE_SCRIPT, os.path.join(paths['ANNOTATION_PATH'], 'train.record'), os.path.join(paths['ANNOTATION_PATH'], 'test.record'), os.path.join(paths['OUTPUT_PATH'], 'detections.tfrecord'), os.path.join(paths['OUTPUT_PATH'], 'saved_model', 'saved_model.pb'))"
      ],
      "metadata": {
        "id": "itoIb03abnjo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!{command}"
      ],
      "metadata": {
        "id": "6yGQ7-mUeYyJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wTPmdqaXpfDK"
      },
      "source": [
        "# 11. Conversion to TFJS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gZ6UzY_fpfDK",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "!pip install tensorflowjs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0oxbVynHpfDK"
      },
      "outputs": [],
      "source": [
        "command = \"tensorflowjs_converter --input_format=tf_saved_model --output_node_names='detection_boxes,detection_classes,detection_features,detection_multiclass_scores,detection_scores,num_detections,raw_detection_boxes,raw_detection_scores' --output_format=tfjs_graph_model --signature_name=serving_default {} {}\".format(os.path.join(paths['OUTPUT_PATH'], 'saved_model'), paths['TFJS_PATH'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DB2AGNmJpfDK"
      },
      "outputs": [],
      "source": [
        "print(command)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K7rfT4-hpfDK"
      },
      "outputs": [],
      "source": [
        "!{command}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o8_hm-itpfDK"
      },
      "outputs": [],
      "source": [
        "# Test Code: https://github.com/nicknochnack/RealTimeSignLanguageDetectionwithTFJS"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VtUw73FHpfDK"
      },
      "source": [
        "# 12. Conversion to TFLite"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XviMtewLpfDK"
      },
      "outputs": [],
      "source": [
        "TFLITE_SCRIPT = os.path.join(paths['APIMODEL_PATH'], 'research', 'object_detection', 'export_tflite_graph_tf2.py ')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "us86cjC4pfDL"
      },
      "outputs": [],
      "source": [
        "command = \"python {} --pipeline_config_path={} --trained_checkpoint_dir={} --output_directory={}\".format(TFLITE_SCRIPT ,files['PIPELINE_CONFIG'], paths['CHECKPOINT_PATH'], paths['TFLITE_PATH'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n1r5YO3rpfDL"
      },
      "outputs": [],
      "source": [
        "print(command)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I-xWpHN8pfDL"
      },
      "outputs": [],
      "source": [
        "!{command}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iJfYMbN6pfDL"
      },
      "outputs": [],
      "source": [
        "FROZEN_TFLITE_PATH = os.path.join(paths['TFLITE_PATH'], 'saved_model')\n",
        "TFLITE_MODEL = os.path.join(paths['TFLITE_PATH'], 'saved_model', 'detect.tflite')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vozaU-R7ajWb"
      },
      "outputs": [],
      "source": [
        "command = \"tflite_convert \\\n",
        "--saved_model_dir={} \\\n",
        "--output_file={} \\\n",
        "--input_shapes=1,300,300,3 \\\n",
        "--input_arrays=normalized_input_image_tensor \\\n",
        "--output_arrays='TFLite_Detection_PostProcess','TFLite_Detection_PostProcess:1','TFLite_Detection_PostProcess:2','TFLite_Detection_PostProcess:3' \\\n",
        "--inference_type=FLOAT \\\n",
        "--allow_custom_ops\".format(FROZEN_TFLITE_PATH, TFLITE_MODEL, )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E8GwUeoFpfDL"
      },
      "outputs": [],
      "source": [
        "print(command)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Nbd7gqHMpfDL"
      },
      "outputs": [],
      "source": [
        "!{command}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5NQqZRdA21Uc"
      },
      "source": [
        "# 13. Zip and Export Models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tTVTGCQp2ZJJ"
      },
      "outputs": [],
      "source": [
        "!tar -czf models.tar.gz {paths['CHECKPOINT_PATH']}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "whShhB0x3PYJ"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "V100"
    },
    "kernelspec": {
      "display_name": "tfod",
      "language": "python",
      "name": "tfod"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}